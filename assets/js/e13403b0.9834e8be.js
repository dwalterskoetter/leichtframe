"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[3037],{4458:(e,a,s)=>{s.r(a),s.d(a,{assets:()=>d,contentTitle:()=>c,default:()=>o,frontMatter:()=>i,metadata:()=>r,toc:()=>l});const r=JSON.parse('{"id":"LeichtFrame/IO/CsvReader","title":"CsvReader","description":"Namespace: LeichtFrame.IO","source":"@site/docs/LeichtFrame/IO/CsvReader.md","sourceDirName":"LeichtFrame/IO","slug":"/LeichtFrame/IO/CsvReader","permalink":"/leichtframe/docs/LeichtFrame/IO/CsvReader","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"sidebar_label":"CsvReader","title":"CsvReader"},"sidebar":"tutorialSidebar","previous":{"title":"CsvReadOptions","permalink":"/leichtframe/docs/LeichtFrame/IO/CsvReadOptions"},"next":{"title":"CsvWriteOptions","permalink":"/leichtframe/docs/LeichtFrame/IO/CsvWriteOptions"}}');var t=s(4848),n=s(8453);const i={sidebar_label:"CsvReader",title:"CsvReader"},c="CsvReader",d={},l=[{value:"Methods",id:"methods",level:2},{value:"InferSchema",id:"inferschema",level:3},{value:"Read",id:"read",level:3},{value:"Read",id:"read-1",level:3},{value:"Read",id:"read-2",level:3},{value:"Read",id:"read-3",level:3},{value:"Read",id:"read-4",level:3},{value:"ReadBatches",id:"readbatches",level:3},{value:"ReadBatches",id:"readbatches-1",level:3}];function h(e){const a={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",p:"p",pre:"pre",strong:"strong",...(0,n.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(a.header,{children:(0,t.jsx)(a.h1,{id:"csvreader",children:"CsvReader"})}),"\n",(0,t.jsxs)(a.p,{children:[(0,t.jsx)(a.strong,{children:"Namespace:"})," ",(0,t.jsx)(a.code,{children:"LeichtFrame.IO"})]}),"\n",(0,t.jsxs)(a.p,{children:["Provides high-performance methods to read CSV files into a ",(0,t.jsx)(a.code,{children:"DataFrame"}),".\nUses parallel processing for full loads and streaming for batched access."]}),"\n",(0,t.jsx)(a.h2,{id:"methods",children:"Methods"}),"\n",(0,t.jsx)(a.h3,{id:"inferschema",children:"InferSchema"}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{className:"language-csharp",children:"public static DataFrameSchema InferSchema(string path, CsvReadOptions options, int sampleRows)\n"})}),"\n",(0,t.jsx)(a.p,{children:"Scans the CSV file to infer the schema (column names and types)."}),"\n",(0,t.jsx)(a.h3,{id:"read",children:"Read"}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{className:"language-csharp",children:"public static DataFrame Read(string path, DataFrameSchema schema, CsvReadOptions options)\n"})}),"\n",(0,t.jsx)(a.p,{children:"Reads a CSV file into a DataFrame using parallel processing for maximum speed."}),"\n",(0,t.jsx)(a.h3,{id:"read-1",children:"Read"}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{className:"language-csharp",children:"public static DataFrame Read(Stream stream, DataFrameSchema schema, CsvReadOptions options)\n"})}),"\n",(0,t.jsx)(a.p,{children:"Reads a CSV from a stream.\nNote: Since streams might not be seekable, we copy this to a temp file or read fully if memory allows.\nFor this implementation, we simply delegate to the parallel logic if it's a FileStream,\nor fall back to a simpler approach if purely in-memory stream to avoid complexity."}),"\n",(0,t.jsx)(a.h3,{id:"read-2",children:"Read"}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{className:"language-csharp",children:"public static DataFrame Read(string path, CsvReadOptions options)\n"})}),"\n",(0,t.jsx)(a.p,{children:"Reads a CSV file, automatically inferring the schema."}),"\n",(0,t.jsx)(a.h3,{id:"read-3",children:"Read"}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{className:"language-csharp",children:"public static DataFrame Read(string path, CsvReadOptions options)\n"})}),"\n",(0,t.jsx)(a.p,{children:"Reads a CSV file using a POCO class schema."}),"\n",(0,t.jsx)(a.h3,{id:"read-4",children:"Read"}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{className:"language-csharp",children:"public static DataFrame Read(Stream stream, CsvReadOptions options)\n"})}),"\n",(0,t.jsx)(a.p,{children:"Reads a CSV from a stream using a POCO class schema."}),"\n",(0,t.jsx)(a.h3,{id:"readbatches",children:"ReadBatches"}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{className:"language-csharp",children:"public static IEnumerable<DataFrame> ReadBatches(string path, DataFrameSchema schema, int batchSize, CsvReadOptions options)\n"})}),"\n",(0,t.jsx)(a.p,{children:"Reads a CSV file in chunks (batches) to enable processing of files larger than memory."}),"\n",(0,t.jsx)(a.h3,{id:"readbatches-1",children:"ReadBatches"}),"\n",(0,t.jsx)(a.pre,{children:(0,t.jsx)(a.code,{className:"language-csharp",children:"public static IEnumerable<DataFrame> ReadBatches(Stream stream, DataFrameSchema schema, int batchSize, CsvReadOptions options)\n"})}),"\n",(0,t.jsx)(a.p,{children:"Reads CSV batches from a stream."})]})}function o(e={}){const{wrapper:a}={...(0,n.R)(),...e.components};return a?(0,t.jsx)(a,{...e,children:(0,t.jsx)(h,{...e})}):h(e)}},8453:(e,a,s)=>{s.d(a,{R:()=>i,x:()=>c});var r=s(6540);const t={},n=r.createContext(t);function i(e){const a=r.useContext(n);return r.useMemo(function(){return"function"==typeof e?e(a):{...a,...e}},[a,e])}function c(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:i(e.components),r.createElement(n.Provider,{value:a},e.children)}}}]);