===== FILE: .github/workflows/cd.yml =====
name: LeichtFrame CD (Release)

on:
  workflow_dispatch:
    inputs:
      version:
        description: "Version to publish (e.g. 0.1.0)"
        required: true
        default: "0.1.0-alpha"
  push:
    tags:
      - "v*"

permissions:
  contents: write

jobs:
  # JOB 1: NuGet Release
  nuget-release:
    name: Publish NuGet
    runs-on: ubuntu-latest
    env:
      VERSION: "0.0.0-ci"

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup .NET 8
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: 8.0.x

      # Find Version
      - name: Set Version (Manual)
        if: github.event_name == 'workflow_dispatch'
        run: echo "VERSION=${{ inputs.version }}" >> $GITHUB_ENV

      - name: Set Version (Tag)
        if: github.event_name == 'push'
        run: echo "VERSION=${GITHUB_REF#refs/tags/v}" >> $GITHUB_ENV

      # Build & Push
      - name: Restore
        run: dotnet restore

      - name: Build & Test
        run: |
          dotnet build --no-restore -c Release -p:Version=$VERSION
          dotnet test --no-build -c Release

      - name: Pack
        run: dotnet pack --no-build -c Release -o nupkgs -p:Version=$VERSION

      - name: Push to NuGet
        run: |
          dotnet nuget push nupkgs/*.nupkg \
            --api-key ${{ secrets.NUGET_API_KEY }} \
            --source https://api.nuget.org/v3/index.json \
            --skip-duplicate

    outputs:
      release_version: ${{ env.VERSION }}

  # JOB 2: Docusaurus Update
  update-docs:
    needs: nuget-release
    uses: ./.github/workflows/docs.yml
    with:
      version_tag: ${{ needs.nuget-release.outputs.release_version }}
    secrets: inherit

===== FILE: .github/workflows/ci.yml =====
name: LeichtFrame CI (Integration)

on:
  push:
    branches: ["main"]
  pull_request:
    branches: ["main"]
  workflow_dispatch:

jobs:
  build-and-test:
    name: Build & Test
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup .NET 8
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: 8.0.x
          cache: true
          cache-dependency-path: "**/*.csproj"

      - name: Restore Dependencies
        run: dotnet restore

      - name: Build
        run: dotnet build --no-restore -c Release

      - name: Test
        run: dotnet test --no-build -c Release --verbosity normal

      - name: Restore Local Tools
        run: dotnet tool restore

      - name: Verify Documentation Generation
        run: |
          chmod +x scripts/generate_docs.sh
          ./scripts/generate_docs.sh

      # We pack to ensure metadata is valid and code is packable.
      # This is a "Dry Run" - we do not publish this artifact to NuGet.org.
      - name: Pack (Dry Run)
        run: dotnet pack --no-build -c Release -o nupkgs

      - name: Upload Artifacts (Verification)
        uses: actions/upload-artifact@v4
        with:
          name: pre-release-packages
          path: nupkgs/*.nupkg
          retention-days: 1

===== FILE: .github/workflows/docs.yml =====
name: LeichtFrame Docs

on:
  # 1. Automatically on changes to docs or core code on main
  push:
    branches: ["main"]
    paths:
      - "website/**"
      - "src/LeichtFrame.Core/**" # Because XML docs need to be generated
      - "src/LeichtFrame.IO/**"
      - "docs/**"

  # 2. Manual trigger (only update docs)
  workflow_dispatch:

  # 3. Callable by other workflows (e.g. CD)
  workflow_call:
    inputs:
      version_tag:
        description: "Version context for the deployment message"
        required: false
        type: string
        default: "latest"

permissions:
  contents: write

jobs:
  deploy-docs:
    name: Build & Deploy Docs
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      # --- Step A: .NET Build for API Reference ---
      - name: Setup .NET 8
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: 8.0.x

      - name: Build for DocGen (Publish to include dependencies)
        run: dotnet publish -c Release

      - name: Generate API Docs (Markdown)
        run: |
          chmod +x scripts/generate_docs.sh
          ./scripts/generate_docs.sh

      # --- Step B: Docusaurus Build ---
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: "npm"
          cache-dependency-path: website/package-lock.json

      - name: Install & Build Website
        working-directory: website
        run: |
          npm ci
          npm run build

      # --- Step C: Deploy ---
      - name: Determine Commit Message
        id: msg
        run: |
          if [ "${{ inputs.version_tag }}" != "" ] && [ "${{ inputs.version_tag }}" != "latest" ]; then
             echo "content=Docs: Deploy release ${{ inputs.version_tag }}" >> $GITHUB_OUTPUT
          else
             echo "content=Docs: Update from main branch" >> $GITHUB_OUTPUT
          fi

      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./website/build
          user_name: "github-actions[bot]"
          user_email: "github-actions[bot]@users.noreply.github.com"
          commit_message: ${{ steps.msg.outputs.content }}

===== FILE: docs/PROFILING.md =====
# LeichtFrame Profiling Guide

This guide explains how to profile CPU usage, memory allocations, and GC behavior for LeichtFrame. It serves as a reference for maintaining the high-performance standards of the library.

## üéØ Performance Baselines (Acceptance Criteria)

Any change to the Core engine must respect these baselines to ensure the "high-performance" promise is kept.

| Metric              | Scenario                       | Limit / Goal                                 |
| :------------------ | :----------------------------- | :------------------------------------------- |
| **Allocation**      | `IntColumn` Creation (1M rows) | **~0 Bytes** (Zero-Allocation via ArrayPool) |
| **Slicing**         | `Slice(start, length)`         | **< 10 ns** (O(1) / Zero-Copy)               |
| **Memory Overhead** | Overhead per Column            | **< 100 Bytes** (Class wrapper only)         |
| **NullBitmap**      | Set/Get Speed                  | **< 2x** of native `bool[]` time             |
| **Throughput**      | Random Access (Get/Set)        | **< 10 ns** per op (hot cache)               |

## üõ† Tools (Linux/macOS/Windows)

We use standard .NET global tools. Ensure you have them installed:

```bash
dotnet tool install --global dotnet-trace
dotnet tool install --global dotnet-counters
dotnet tool install --global dotnet-gcdump
```

---

## CPU Profiling (dotnet-trace)

Use `dotnet-trace` to identify "hot paths" (methods that consume the most CPU time) or blocking calls.

**How to run**

Use the helper script to run the benchmarks with tracing enabled:

```bash
./scripts/profile_cpu.sh
```

**Analyze**

The output file (`traces/cpu_trace.nettrace`) can be analyzed in two ways:

- **Visual Studio (Windows):** Open the file directly.
- **Speedscope (Cross-platform):**

  1. Convert the trace:

```bash
dotnet-trace convert --format speedscope traces/cpu_trace.nettrace
```

2. Upload the resulting `.speedscope.json` to [https://speedscope.app](https://speedscope.app).

## Real-time GC Monitoring (dotnet-counters)

Use `dotnet-counters` to see Garbage Collection generations and heap size in real-time. This is crucial to verify "Zero-Allocation" claims.

**How to run**

1. Start your application or benchmark loop.
2. Find the Process ID (PID) using `dotnet-counters ps`.
3. Run the monitor script:

```bash
./scripts/monitor_gc.sh <PID>
```

**Key Metrics to watch**

- **GC Heap Size (MB):** Should remain stable. Continuous growth indicates a memory leak.
- **Gen 0 GC Count:** Should be low/zero during data processing phases (thanks to ArrayPool).
- **Allocation Rate:** Should be near zero for Core operations.

## Memory Heap Snapshots (dotnet-gcdump)

Use `dotnet-gcdump` to find memory leaks (objects that are not collected) or to inspect the object graph.

**How to run**

```bash
./scripts/capture_dump.sh <PID>
```

**Analyze**

Open the resulting `.gcdump` file in Visual Studio or VS Code (using the **.NET Install Tool** extension). You can compare two dumps to see which objects survived between snapshots.

## üöë Troubleshooting ‚Äî Common Issues

- **High Gen 2 Collections:** This usually means large objects (>85KB) are being allocated frequently without pooling, or objects are living too long. Check ArrayPool usage.

- **Rising Heap Size:** If the heap grows indefinitely, check for `IDisposable` objects (Columns) that are not being disposed, preventing the ArrayPool from reclaiming arrays.

- **Slow Slicing:** Ensure you are using `ReadOnlyMemory<T>` or `Span<T>` and not copying data to new arrays.

### Quick tips

- Prefer pooling (ArrayPool) for large buffers.
- Use `ValueTask`/`ref struct` patterns where appropriate to avoid allocations.
- Add focused microbenchmarks (BenchmarkDotNet) for suspicious hot paths.
- When in doubt, capture a short `dotnet-trace` and inspect flame graphs in speedscope.

---

_Saved: docs/PROFILING.md_

===== FILE: src/LeichtFrame.Benchmarks/AggregationBenchmarks.cs =====
using BenchmarkDotNet.Attributes;
using LeichtFrame.Core;

namespace LeichtFrame.Benchmarks
{
    public class AggregationBenchmarks : BenchmarkData
    {
        // =========================================================
        // SUM
        // =========================================================

        [Benchmark(Baseline = true, Description = "DuckDB Sum")]
        public double DuckDB_Sum()
        {
            using var cmd = _duckConnection.CreateCommand();
            cmd.CommandText = "SELECT SUM(Val) FROM BenchData";
            return (double)cmd.ExecuteScalar()!;
        }

        [Benchmark(Description = "LeichtFrame Sum")]
        public double LF_Sum()
        {
            return _lfFrame.Sum("Val");
        }

        // =========================================================
        // MEAN
        // =========================================================

        [Benchmark(Description = "DuckDB Mean")]
        public double DuckDB_Mean()
        {
            using var cmd = _duckConnection.CreateCommand();
            cmd.CommandText = "SELECT AVG(Val) FROM BenchData";
            return (double)cmd.ExecuteScalar()!;
        }

        [Benchmark(Description = "LeichtFrame Mean")]
        public double LF_Mean()
        {
            return _lfFrame.Mean("Val");
        }

        // =========================================================
        // MIN
        // =========================================================

        [Benchmark(Description = "DuckDB Min")]
        public double DuckDB_Min()
        {
            using var cmd = _duckConnection.CreateCommand();
            cmd.CommandText = "SELECT MIN(Val) FROM BenchData";
            return (double)cmd.ExecuteScalar()!;
        }

        [Benchmark(Description = "LeichtFrame Min")]
        public double LF_Min()
        {
            return _lfFrame.Min("Val");
        }

        // =========================================================
        // MAX
        // =========================================================

        [Benchmark(Description = "DuckDB Max")]
        public double DuckDB_Max()
        {
            using var cmd = _duckConnection.CreateCommand();
            cmd.CommandText = "SELECT MAX(Val) FROM BenchData";
            return (double)cmd.ExecuteScalar()!;
        }

        [Benchmark(Description = "LeichtFrame Max")]
        public double LF_Max()
        {
            return _lfFrame.Max("Val");
        }
    }
}
===== FILE: src/LeichtFrame.Benchmarks/BenchmarkData.cs =====
using BenchmarkDotNet.Attributes;
using BenchmarkDotNet.Order;
using LeichtFrame.Core;
using DuckDB.NET.Data;

namespace LeichtFrame.Benchmarks
{
    [MemoryDiagnoser]
    [Orderer(SummaryOrderPolicy.FastestToSlowest)]
    [RankColumn]
    public abstract class BenchmarkData
    {
        [Params(1_000_000)]
        public int N;

        protected LeichtFrame.Core.DataFrame _lfFrame = null!;
        protected DuckDBConnection _duckConnection = null!;

        protected List<TestPoco> _pocoList = null!;

        public record TestPoco(int Id, double Val, string Category, string UniqueId);

        [GlobalSetup]
        public virtual void GlobalSetup()
        {
            var rnd = new Random(42);
            _pocoList = new List<TestPoco>(N);
            var categories = new[] { "A", "B", "C", "D", "E" };

            for (int i = 0; i < N; i++)
            {
                int id = rnd.Next(0, 100_000);
                double val = rnd.NextDouble() * 1000.0;
                string cat = categories[rnd.Next(categories.Length)];
                string uid = Guid.NewGuid().ToString();

                _pocoList.Add(new TestPoco(id, val, cat, uid));
            }

            // --- 1. Setup LeichtFrame ---
            _lfFrame = DataFrame.FromObjects(_pocoList);

            // --- 2. Setup DuckDB ü¶Ü ---
            _duckConnection = new DuckDBConnection("DataSource=:memory:");
            _duckConnection.Open();

            using var cmd = _duckConnection.CreateCommand();

            cmd.CommandText = "CREATE TABLE BenchData (Id INTEGER, Val DOUBLE, Category VARCHAR, UniqueId VARCHAR)";
            cmd.ExecuteNonQuery();

            using (var appender = _duckConnection.CreateAppender("BenchData"))
            {
                foreach (var item in _pocoList)
                {
                    var row = appender.CreateRow();
                    row.AppendValue(item.Id);
                    row.AppendValue(item.Val);
                    row.AppendValue(item.Category);
                    row.AppendValue(item.UniqueId);
                    row.EndRow();
                }
            }
        }

        [GlobalCleanup]
        public virtual void GlobalCleanup()
        {
            _lfFrame?.Dispose();
            _duckConnection?.Dispose();
        }
    }
}
===== FILE: src/LeichtFrame.Benchmarks/CalculationBenchmarks.cs =====
using BenchmarkDotNet.Attributes;
using LeichtFrame.Core;

namespace LeichtFrame.Benchmarks
{
    public class CalculationBenchmarks : BenchmarkData
    {
        // =========================================================
        // VECTORIZED ARITHMETIC (SIMD)
        // =========================================================

        [Benchmark(Baseline = true, Description = "DuckDB Vec Add (Col + Col)")]
        public double DuckDB_Vec_Add()
        {
            using var cmd = _duckConnection.CreateCommand();
            cmd.CommandText = "SELECT Val + Val FROM BenchData";
            using var reader = cmd.ExecuteReader();

            double sum = 0;
            while (reader.Read())
            {
                sum += reader.GetDouble(0);
            }
            return sum;
        }

        [Benchmark(Description = "LeichtFrame Vec Add (Col + Col)")]
        public DoubleColumn LF_Vec_Add()
        {
            var col = (DoubleColumn)_lfFrame["Val"];
            // Uses SIMD instructions via Vector<T>
            return col + col;
        }

        [Benchmark(Description = "DuckDB Vec Scalar (Col * 1.5)")]
        public double DuckDB_Vec_Scalar()
        {
            using var cmd = _duckConnection.CreateCommand();
            cmd.CommandText = "SELECT Val * 1.5 FROM BenchData";
            using var reader = cmd.ExecuteReader();

            double sum = 0;
            while (reader.Read())
            {
                sum += reader.GetDouble(0);
            }
            return sum;
        }

        [Benchmark(Description = "LeichtFrame Vec Scalar (Col * 1.5)")]
        public DoubleColumn LF_Vec_Scalar()
        {
            var col = (DoubleColumn)_lfFrame["Val"];
            return col * 1.5;
        }

        // =========================================================
        // COMPUTED COLUMNS (Transformation)
        // =========================================================

        [Benchmark(Description = "DuckDB Computed (Val * Id)")]
        public void DuckDB_Computed()
        {
            using var cmd = _duckConnection.CreateCommand();
            // SQL handles mixed types (Double * Int) automatically
            cmd.CommandText = "SELECT Val * Id FROM BenchData";
            using var reader = cmd.ExecuteReader();

            while (reader.Read()) { }
        }

        [Benchmark(Description = "LeichtFrame AddColumn (Val * Id)")]
        public DataFrame LF_Computed()
        {
            // Creates a new column using a row-based delegate
            return _lfFrame.AddColumn("Computed", row =>
                row.Get<double>("Val") * row.Get<int>("Id")
            );
        }

        // =========================================================
        // STRING TRANSFORMATION
        // =========================================================

        [Benchmark(Description = "DuckDB String Concat")]
        public void DuckDB_String_Concat()
        {
            using var cmd = _duckConnection.CreateCommand();
            // SQL Concat operator
            cmd.CommandText = "SELECT Category || '_' || UniqueId FROM BenchData";
            using var reader = cmd.ExecuteReader();

            while (reader.Read()) { }
        }

        [Benchmark(Description = "LeichtFrame String Concat")]
        public DataFrame LF_String_Concat()
        {
            // This tests the overhead of string allocation per row
            return _lfFrame.AddColumn("Concat", row =>
                row.Get<string>("Category") + "_" + row.Get<string>("UniqueId")
            );
        }
    }
}
===== FILE: src/LeichtFrame.Benchmarks/CleaningBenchmarks.cs =====
using BenchmarkDotNet.Attributes;
using LeichtFrame.Core;

namespace LeichtFrame.Benchmarks
{
    public class CleaningBenchmarks : BenchmarkData
    {
        public override void GlobalSetup()
        {
            base.GlobalSetup();

            // 1. Inject Nulls into LeichtFrame
            // We set every 5th row of 'Category' to null (~20% null rate)
            var catCol = (StringColumn)_lfFrame["Category"];
            for (int i = 0; i < N; i += 5)
            {
                catCol.SetNull(i);
            }

            // 2. Inject Nulls into DuckDB to match the state
            using var cmd = _duckConnection.CreateCommand();
            cmd.CommandText = "UPDATE BenchData SET Category = NULL WHERE (Id % 5) = 0";
            cmd.ExecuteNonQuery();
        }

        // =========================================================
        // DISTINCT
        // =========================================================

        [Benchmark(Baseline = true, Description = "DuckDB Distinct")]
        public long DuckDB_Distinct()
        {
            using var cmd = _duckConnection.CreateCommand();
            cmd.CommandText = "SELECT DISTINCT Category FROM BenchData";
            using var reader = cmd.ExecuteReader();

            long count = 0;
            while (reader.Read()) count++;
            return count;
        }

        [Benchmark(Description = "LeichtFrame Distinct")]
        public DataFrame LF_Distinct()
        {
            return _lfFrame.Distinct("Category");
        }

        // =========================================================
        // DROP NULLS
        // =========================================================

        [Benchmark(Description = "DuckDB DropNulls (Filter)")]
        public long DuckDB_DropNulls()
        {
            using var cmd = _duckConnection.CreateCommand();
            cmd.CommandText = "SELECT * FROM BenchData WHERE Category IS NOT NULL";
            using var reader = cmd.ExecuteReader();

            long count = 0;
            while (reader.Read()) count++;
            return count;
        }

        [Benchmark(Description = "LeichtFrame DropNulls")]
        public DataFrame LF_DropNulls()
        {
            // Removes rows where ANY column is null (checks all columns)
            return _lfFrame.DropNulls();
        }

        // =========================================================
        // FILL NULL (Coalesce)
        // =========================================================

        [Benchmark(Description = "DuckDB FillNull (Coalesce)")]
        public long DuckDB_FillNull()
        {
            using var cmd = _duckConnection.CreateCommand();
            // Simulating creating a new projection with filled values
            cmd.CommandText = "SELECT COALESCE(Category, 'MISSING') FROM BenchData";
            using var reader = cmd.ExecuteReader();

            long count = 0;
            while (reader.Read()) count++;
            return count;
        }

        [Benchmark(Description = "LeichtFrame FillNull")]
        public DataFrame LF_FillNull()
        {
            return _lfFrame.FillNull("Category", "MISSING");
        }
    }
}
===== FILE: src/LeichtFrame.Benchmarks/FilterBenchmarks.cs =====
using BenchmarkDotNet.Attributes;
using LeichtFrame.Core;
using DuckDB.NET.Data;

namespace LeichtFrame.Benchmarks
{
    public class FilterBenchmarks : BenchmarkData
    {
        // =========================================================
        // INTEGER FILTER (Numeric)
        // =========================================================

        [Benchmark(Baseline = true, Description = "DuckDB Filter (Int)")]
        public long DuckDB_Filter_Int()
        {
            using var cmd = _duckConnection.CreateCommand();
            cmd.CommandText = "SELECT * FROM BenchData WHERE Id < 50000";
            using var reader = cmd.ExecuteReader();

            long count = 0;
            while (reader.Read()) count++;
            return count;
        }

        [Benchmark(Description = "LeichtFrame Where (Int - Delegate)")]
        public DataFrame LF_Where_Int()
        {
            return _lfFrame.Where(row => row.Get<int>("Id") < 50_000);
        }

        [Benchmark(Description = "LeichtFrame WhereView (Zero-Copy)")]
        public DataFrame LF_WhereView_Int()
        {
            return _lfFrame.WhereView(row => row.Get<int>("Id") < 50_000);
        }

        [Benchmark(Description = "LeichtFrame WhereVec (Int - SIMD)")]
        public DataFrame LF_WhereVec_Int()
        {
            // Hardware accelerated filtering
            return _lfFrame.WhereVec("Id", CompareOp.LessThan, 50_000);
        }

        // =========================================================
        // STRING FILTER (Text comparison)
        // =========================================================

        [Benchmark(Description = "DuckDB Filter (String)")]
        public long DuckDB_Filter_String()
        {
            using var cmd = _duckConnection.CreateCommand();
            // Category has values "A", "B", "C", "D", "E"
            cmd.CommandText = "SELECT * FROM BenchData WHERE Category = 'A'";
            using var reader = cmd.ExecuteReader();

            long count = 0;
            while (reader.Read()) count++;
            return count;
        }

        [Benchmark(Description = "LeichtFrame Where (String)")]
        public DataFrame LF_Where_String()
        {
            // Vectorized string filtering is not yet implemented, so we use the delegate approach
            return _lfFrame.Where(row => row.Get<string>("Category") == "A");
        }

        // =========================================================
        // COMPOUND FILTER (Multi-Column)
        // =========================================================

        [Benchmark(Description = "DuckDB Filter (Compound)")]
        public long DuckDB_Filter_Compound()
        {
            using var cmd = _duckConnection.CreateCommand();
            cmd.CommandText = "SELECT * FROM BenchData WHERE Id < 10000 AND Category = 'A'";
            using var reader = cmd.ExecuteReader();

            long count = 0;
            while (reader.Read()) count++;
            return count;
        }

        [Benchmark(Description = "LeichtFrame Where (Compound)")]
        public DataFrame LF_Where_Compound()
        {
            // Accessing multiple columns per row increases overhead
            return _lfFrame.Where(row =>
                row.Get<int>("Id") < 10_000 &&
                row.Get<string>("Category") == "A"
            );
        }
    }
}
===== FILE: src/LeichtFrame.Benchmarks/GroupByBenchmarks.cs =====
using BenchmarkDotNet.Attributes;
using LeichtFrame.Core;
using DuckDB.NET.Data;

namespace LeichtFrame.Benchmarks
{
    public class GroupByBenchmarks : BenchmarkData
    {
        // =========================================================
        // COUNT (Low & High Cardinality)
        // =========================================================

        [Benchmark(Baseline = true, Description = "DuckDB GroupBy Count (LowCard)")]
        public long DuckDB_Group_Count_Low()
        {
            using var cmd = _duckConnection.CreateCommand();
            cmd.CommandText = "SELECT Category, COUNT(*) FROM BenchData GROUP BY Category";
            using var reader = cmd.ExecuteReader();

            long count = 0;
            while (reader.Read()) count++;
            return count;
        }

        [Benchmark(Description = "LeichtFrame GroupBy Count (LowCard)")]
        public DataFrame LF_Group_Count_Low()
        {
            return _lfFrame.GroupBy("Category").Count();
        }

        [Benchmark(Description = "DuckDB GroupBy Count (HighCard)")]
        public long DuckDB_Group_Count_High()
        {
            using var cmd = _duckConnection.CreateCommand();
            cmd.CommandText = "SELECT UniqueId, COUNT(*) FROM BenchData GROUP BY UniqueId";
            using var reader = cmd.ExecuteReader();

            long count = 0;
            while (reader.Read()) count++;
            return count;
        }

        [Benchmark(Description = "LeichtFrame GroupBy Count (HighCard)")]
        public DataFrame LF_Group_Count_High()
        {
            return _lfFrame.GroupBy("UniqueId").Count();
        }

        // =========================================================
        // SUM
        // =========================================================

        [Benchmark(Description = "DuckDB GroupBy Sum")]
        public double DuckDB_Group_Sum()
        {
            using var cmd = _duckConnection.CreateCommand();
            cmd.CommandText = "SELECT Category, SUM(Val) FROM BenchData GROUP BY Category";
            using var reader = cmd.ExecuteReader();

            double sumCheck = 0;
            while (reader.Read()) sumCheck += reader.GetDouble(1);
            return sumCheck;
        }

        [Benchmark(Description = "LeichtFrame GroupBy Sum")]
        public DataFrame LF_Group_Sum()
        {
            return _lfFrame.GroupBy("Category").Sum("Val");
        }

        // =========================================================
        // MEAN
        // =========================================================

        [Benchmark(Description = "DuckDB GroupBy Mean")]
        public double DuckDB_Group_Mean()
        {
            using var cmd = _duckConnection.CreateCommand();
            cmd.CommandText = "SELECT Category, AVG(Val) FROM BenchData GROUP BY Category";
            using var reader = cmd.ExecuteReader();

            double check = 0;
            while (reader.Read()) check += reader.GetDouble(1);
            return check;
        }

        [Benchmark(Description = "LeichtFrame GroupBy Mean")]
        public DataFrame LF_Group_Mean()
        {
            return _lfFrame.GroupBy("Category").Mean("Val");
        }

        // =========================================================
        // MIN
        // =========================================================

        [Benchmark(Description = "DuckDB GroupBy Min")]
        public double DuckDB_Group_Min()
        {
            using var cmd = _duckConnection.CreateCommand();
            cmd.CommandText = "SELECT Category, MIN(Val) FROM BenchData GROUP BY Category";
            using var reader = cmd.ExecuteReader();

            double check = 0;
            while (reader.Read()) check += reader.GetDouble(1);
            return check;
        }

        [Benchmark(Description = "LeichtFrame GroupBy Min")]
        public DataFrame LF_Group_Min()
        {
            return _lfFrame.GroupBy("Category").Min("Val");
        }

        // =========================================================
        // MAX
        // =========================================================

        [Benchmark(Description = "DuckDB GroupBy Max")]
        public double DuckDB_Group_Max()
        {
            using var cmd = _duckConnection.CreateCommand();
            cmd.CommandText = "SELECT Category, MAX(Val) FROM BenchData GROUP BY Category";
            using var reader = cmd.ExecuteReader();

            double check = 0;
            while (reader.Read()) check += reader.GetDouble(1);
            return check;
        }

        [Benchmark(Description = "LeichtFrame GroupBy Max")]
        public DataFrame LF_Group_Max()
        {
            return _lfFrame.GroupBy("Category").Max("Val");
        }
    }
}
===== FILE: src/LeichtFrame.Benchmarks/IOBenchmarks.cs =====
using BenchmarkDotNet.Attributes;
using BenchmarkDotNet.Order;
using DuckDB.NET.Data;
using LeichtFrame.Core;
using LeichtFrame.IO;

namespace LeichtFrame.Benchmarks
{
    [MemoryDiagnoser]
    [Orderer(SummaryOrderPolicy.FastestToSlowest)]
    [RankColumn]
    public class IOBenchmarks
    {
        [Params(100_000)]
        public int N;

        private string _tempDir = null!;
        private string _sourceCsvPath = null!;
        private string _sourceParquetPath = null!;
        private string _destCsvPath = null!;
        private string _destParquetPath = null!;

        private DataFrame _lfDataFrame = null!;
        private DuckDBConnection _duckConnection = null!;
        private DataFrameSchema _schema = null!;

        [GlobalSetup]
        public void Setup()
        {
            // 1. Prepare Temp Directory
            _tempDir = Path.Combine(Path.GetTempPath(), "LeichtFrame_IO_Bench");
            if (!Directory.Exists(_tempDir)) Directory.CreateDirectory(_tempDir);

            _sourceCsvPath = Path.Combine(_tempDir, "source.csv");
            _sourceParquetPath = Path.Combine(_tempDir, "source.parquet");
            _destCsvPath = Path.Combine(_tempDir, "dest.csv");
            _destParquetPath = Path.Combine(_tempDir, "dest.parquet");

            // 2. Generate Test Data
            var data = new List<BenchmarkData.TestPoco>(N);
            var rnd = new Random(42);
            var categories = new[] { "A", "B", "C", "D", "E" };

            for (int i = 0; i < N; i++)
            {
                data.Add(new BenchmarkData.TestPoco(
                    i,
                    rnd.NextDouble() * 1000.0,
                    categories[rnd.Next(categories.Length)],
                    Guid.NewGuid().ToString()
                ));
            }

            _lfDataFrame = DataFrame.FromObjects(data);
            _schema = _lfDataFrame.Schema;

            // 3. Write Source Files on disk
            _lfDataFrame.WriteCsv(_sourceCsvPath, new CsvWriteOptions { WriteHeader = true });
            _lfDataFrame.WriteParquet(_sourceParquetPath);

            // 4. DuckDB Setup
            _duckConnection = new DuckDBConnection("DataSource=:memory:");
            _duckConnection.Open();

            using var cmd = _duckConnection.CreateCommand();
            cmd.CommandText = "CREATE TABLE BenchData (Id INTEGER, Val DOUBLE, Category VARCHAR, UniqueId VARCHAR)";
            cmd.ExecuteNonQuery();

            using (var appender = _duckConnection.CreateAppender("BenchData"))
            {
                foreach (var item in data)
                {
                    var row = appender.CreateRow();
                    row.AppendValue(item.Id);
                    row.AppendValue(item.Val);
                    row.AppendValue(item.Category);
                    row.AppendValue(item.UniqueId);
                    row.EndRow();
                }
            }
        }

        [GlobalCleanup]
        public void Cleanup()
        {
            _lfDataFrame?.Dispose();
            _duckConnection?.Dispose();

            if (Directory.Exists(_tempDir)) Directory.Delete(_tempDir, true);
        }

        // =========================================================
        // CSV READ
        // =========================================================

        [Benchmark(Description = "DuckDB Read CSV")]
        public long DuckDB_Read_CSV()
        {
            using var cmd = _duckConnection.CreateCommand();
            cmd.CommandText = $"SELECT * FROM read_csv_auto('{_sourceCsvPath}')";
            using var reader = cmd.ExecuteReader();

            long count = 0;
            while (reader.Read())
            {
                count++;
                var id = reader.GetValue(0);
            }
            return count;
        }

        [Benchmark(Description = "LeichtFrame Read CSV")]
        public DataFrame LF_Read_CSV()
        {
            return CsvReader.Read(_sourceCsvPath, _schema, new CsvReadOptions { HasHeader = true });
        }

        // =========================================================
        // PARQUET READ
        // =========================================================

        [Benchmark(Description = "DuckDB Read Parquet")]
        public long DuckDB_Read_Parquet()
        {
            using var cmd = _duckConnection.CreateCommand();
            cmd.CommandText = $"SELECT * FROM read_parquet('{_sourceParquetPath}')";
            using var reader = cmd.ExecuteReader();

            long count = 0;
            while (reader.Read())
            {
                count++;
                var id = reader.GetValue(0);
            }
            return count;
        }

        [Benchmark(Description = "LeichtFrame Read Parquet")]
        public DataFrame LF_Read_Parquet()
        {
            // Nutzt intern Parquet.Net
            return ParquetReader.Read(_sourceParquetPath);
        }

        // =========================================================
        // CSV WRITE
        // =========================================================

        [Benchmark(Description = "DuckDB Write CSV")]
        public void DuckDB_Write_CSV()
        {
            using var cmd = _duckConnection.CreateCommand();
            // COPY (SELECT ...) TO ...
            cmd.CommandText = $"COPY BenchData TO '{_destCsvPath}' (FORMAT CSV, HEADER)";
            cmd.ExecuteNonQuery();
        }

        [Benchmark(Description = "LeichtFrame Write CSV")]
        public void LF_Write_CSV()
        {
            _lfDataFrame.WriteCsv(_destCsvPath);
        }

        // =========================================================
        // PARQUET WRITE
        // =========================================================

        [Benchmark(Description = "DuckDB Write Parquet")]
        public void DuckDB_Write_Parquet()
        {
            using var cmd = _duckConnection.CreateCommand();
            cmd.CommandText = $"COPY BenchData TO '{_destParquetPath}' (FORMAT PARQUET)";
            cmd.ExecuteNonQuery();
        }

        [Benchmark(Description = "LeichtFrame Write Parquet")]
        public void LF_Write_Parquet()
        {
            _lfDataFrame.WriteParquet(_destParquetPath);
        }
    }
}
===== FILE: src/LeichtFrame.Benchmarks/InteropBenchmarks.cs =====
using Apache.Arrow;
using BenchmarkDotNet.Attributes;
using BenchmarkDotNet.Order;
using LeichtFrame.Core;
using LeichtFrame.IO;

namespace LeichtFrame.Benchmarks
{
    [MemoryDiagnoser]
    [Orderer(SummaryOrderPolicy.FastestToSlowest)]
    public class InteropBenchmarks : BenchmarkData
    {
        private RecordBatch _arrowBatch = null!;

        public override void GlobalSetup()
        {
            base.GlobalSetup();
            // Pre-calculate an Arrow Batch to measure Import speed
            _arrowBatch = _lfFrame.ToArrow();
        }

        // =========================================================
        // EXPORT TO ARROW
        // =========================================================

        [Benchmark(Description = "LeichtFrame ToArrow (Export)")]
        public RecordBatch LF_ToArrow()
        {
            // Measures how fast we can map internal columns to Arrow arrays
            return _lfFrame.ToArrow();
        }

        // =========================================================
        // IMPORT FROM ARROW
        // =========================================================

        [Benchmark(Description = "LeichtFrame FromArrow (Import)")]
        public DataFrame LF_FromArrow()
        {
            // Measures how fast we can ingest Arrow data into LeichtFrame columns
            return _arrowBatch.ToDataFrame();
        }
    }
}
===== FILE: src/LeichtFrame.Benchmarks/JoinBenchmarks.cs =====
using BenchmarkDotNet.Attributes;
using LeichtFrame.Core;

namespace LeichtFrame.Benchmarks
{
    public class JoinBenchmarks : BenchmarkData
    {
        private LeichtFrame.Core.DataFrame _lfRight = null!;

        public override void GlobalSetup()
        {
            base.GlobalSetup();

            // ---------------------------------------------------------
            // SETUP LEICHTFRAME RIGHT SIDE
            // ---------------------------------------------------------
            var schemaRight = new DataFrameSchema(new[] {
                new ColumnDefinition("UniqueId", typeof(string)),
                new ColumnDefinition("RightVal", typeof(double))
            });

            // We purposefully create a smaller right dataset (50% of Left)
            // to ensure Left Join produces Nulls and Inner Join filters rows.
            int rightCount = N / 2;
            _lfRight = DataFrame.Create(schemaRight, rightCount);

            var colKey = (StringColumn)_lfRight["UniqueId"];
            var colVal = (DoubleColumn)_lfRight["RightVal"];

            // Insert every 2nd item -> 50% match rate
            for (int i = 0; i < N; i += 2)
            {
                colKey.Append(_pocoList[i].UniqueId);
                colVal.Append(_pocoList[i].Val * 2);
            }

            // ---------------------------------------------------------
            // SETUP DUCKDB RIGHT SIDE ü¶Ü
            // ---------------------------------------------------------
            using var cmd = _duckConnection.CreateCommand();
            cmd.CommandText = "CREATE TABLE BenchDataRight (UniqueId VARCHAR, RightVal DOUBLE)";
            cmd.ExecuteNonQuery();

            using (var appender = _duckConnection.CreateAppender("BenchDataRight"))
            {
                for (int i = 0; i < N; i += 2)
                {
                    var row = appender.CreateRow();
                    row.AppendValue(_pocoList[i].UniqueId);
                    row.AppendValue(_pocoList[i].Val * 2);
                    row.EndRow();
                }
            }
        }

        public override void GlobalCleanup()
        {
            _lfRight?.Dispose();
            base.GlobalCleanup();
        }

        // =========================================================
        // INNER JOIN
        // =========================================================

        [Benchmark(Baseline = true, Description = "DuckDB Inner Join")]
        public long DuckDB_InnerJoin()
        {
            using var cmd = _duckConnection.CreateCommand();
            cmd.CommandText = @"
                SELECT COUNT(*) 
                FROM BenchData 
                INNER JOIN BenchDataRight ON BenchData.UniqueId = BenchDataRight.UniqueId";

            return (long)cmd.ExecuteScalar()!;
        }

        [Benchmark(Description = "LeichtFrame Inner Join")]
        public DataFrame LF_InnerJoin()
        {
            return _lfFrame.Join(_lfRight, "UniqueId", JoinType.Inner);
        }

        // =========================================================
        // LEFT JOIN
        // =========================================================

        [Benchmark(Description = "DuckDB Left Join")]
        public long DuckDB_LeftJoin()
        {
            using var cmd = _duckConnection.CreateCommand();
            cmd.CommandText = @"
                SELECT COUNT(*) 
                FROM BenchData 
                LEFT JOIN BenchDataRight ON BenchData.UniqueId = BenchDataRight.UniqueId";

            return (long)cmd.ExecuteScalar()!;
        }

        [Benchmark(Description = "LeichtFrame Left Join")]
        public DataFrame LF_LeftJoin()
        {
            return _lfFrame.Join(_lfRight, "UniqueId", JoinType.Left);
        }
    }
}
===== FILE: src/LeichtFrame.Benchmarks/LeichtFrame.Benchmarks.csproj =====
Ôªø<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <OutputType>Exe</OutputType>
    <TargetFramework>net8.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <IsPackable>false</IsPackable>

    <GenerateDocumentationFile>false</GenerateDocumentationFile>
    <NoWarn>$(NoWarn);CS1591</NoWarn>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="BenchmarkDotNet" Version="0.15.8" />
    <PackageReference Include="DuckDB.NET.Data.Full" Version="1.4.3" />
    <PackageReference Include="Microsoft.Data.Analysis" Version="0.23.0" />
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\LeichtFrame.Core\LeichtFrame.Core.csproj" />
    <ProjectReference Include="..\LeichtFrame.IO\LeichtFrame.IO.csproj" />
  </ItemGroup>

</Project>

===== FILE: src/LeichtFrame.Benchmarks/Program.cs =====
using BenchmarkDotNet.Columns;
using BenchmarkDotNet.Configs;
using BenchmarkDotNet.Environments;
using BenchmarkDotNet.Exporters;
using BenchmarkDotNet.Jobs;
using BenchmarkDotNet.Loggers;
using BenchmarkDotNet.Running;
using BenchmarkDotNet.Toolchains.CsProj;

namespace LeichtFrame.Benchmarks
{
    public class Program
    {
        public static void Main(string[] args)
        {
            // --- 1. Custom Arguments Parsing ---           
            bool isFastMode = args.Any(a => a.Equals("fast", StringComparison.OrdinalIgnoreCase) ||
                                            a.Equals("short", StringComparison.OrdinalIgnoreCase));

            // Clean BDN Arguments
            var bdnArgs = args.Where(a => !a.Equals("fast", StringComparison.OrdinalIgnoreCase) &&
                                          !a.Equals("short", StringComparison.OrdinalIgnoreCase)).ToList();

            // "Magic" Argument: "all" -> "--filter *"
            if (bdnArgs.Count > 0 && bdnArgs[0].Equals("all", StringComparison.OrdinalIgnoreCase))
            {
                bdnArgs.Clear();
                bdnArgs.Add("--filter");
                bdnArgs.Add("*");
            }

            // --- 2. Job Configuration ---

            // Basic-Job (always .NET 8 / x64)
            var job = Job.Default
                .WithRuntime(CoreRuntime.Core80)
                .WithPlatform(Platform.X64)
                .WithToolchain(CsProjCoreToolchain.NetCoreApp80);

            if (isFastMode)
            {
                // Turbo-Mode for Development (less precision, but much faster)
                job = job
                    .WithWarmupCount(1)
                    .WithIterationCount(3)
                    .WithLaunchCount(1)
                    .WithInvocationCount(16);
            }

            var config = ManualConfig.Create(DefaultConfig.Instance)
                .AddJob(job)
                .AddExporter(MarkdownExporter.GitHub)
                .WithOptions(ConfigOptions.JoinSummary)
                .AddLogger(ConsoleLogger.Default)
                .AddColumnProvider(DefaultColumnProviders.Instance);

            // --- 3. Header ---
            Console.ForegroundColor = ConsoleColor.Cyan;
            Console.WriteLine("=================================================");
            Console.WriteLine("   üöÄ LeichtFrame Benchmark Suite");
            Console.WriteLine("=================================================");
            Console.ResetColor();

            Console.WriteLine($"Mode:    {(isFastMode ? "‚ö° FAST / DEV (Low Precision)" : "üê¢ NORMAL (High Precision)")}");
            Console.WriteLine("Target:  Comparison against DuckDB.NET");
            Console.WriteLine("Dataset: 1,000,000 Rows (configured via Params)");
            Console.WriteLine();

            // --- 4. Help-Text ---
            if (bdnArgs.Count == 0)
            {
                Console.ForegroundColor = ConsoleColor.Yellow;
                Console.WriteLine("Usage Examples:");
                Console.WriteLine("  1. Interactive Menu:   dotnet run -c Release");
                Console.WriteLine("  2. Run All (Normal):   dotnet run -c Release -- all");
                Console.WriteLine("  3. Run All (Fast):     dotnet run -c Release -- all fast");
                Console.WriteLine("  4. Filter (Fast):      dotnet run -c Release -- fast --filter *Join*");
                Console.ResetColor();
                Console.WriteLine();
                Console.WriteLine("Select benchmarks from the list below:");
            }

            // --- 5. Start ---
            BenchmarkSwitcher.FromAssembly(typeof(Program).Assembly).Run(bdnArgs.ToArray(), config);
        }
    }
}
===== FILE: src/LeichtFrame.Benchmarks/Sorting Benchmarks.cs =====
using BenchmarkDotNet.Attributes;
using LeichtFrame.Core;

namespace LeichtFrame.Benchmarks
{
    public class SortingBenchmarks : BenchmarkData
    {
        // =========================================================
        // FULL SORTING (OrderBy)
        // =========================================================

        [Benchmark(Baseline = true, Description = "DuckDB Sort (Int)")]
        public void DuckDB_Sort_Int()
        {
            using var cmd = _duckConnection.CreateCommand();
            cmd.CommandText = "SELECT * FROM BenchData ORDER BY Id";
            using var reader = cmd.ExecuteReader();

            // Iterate to ensure sorting is actually executed and materialized
            while (reader.Read()) { }
        }

        [Benchmark(Description = "LeichtFrame Sort (Int)")]
        public DataFrame LF_Sort_Int()
        {
            return _lfFrame.OrderBy("Id");
        }

        [Benchmark(Description = "DuckDB Sort (String)")]
        public void DuckDB_Sort_String()
        {
            using var cmd = _duckConnection.CreateCommand();
            cmd.CommandText = "SELECT * FROM BenchData ORDER BY UniqueId";
            using var reader = cmd.ExecuteReader();

            while (reader.Read()) { }
        }

        [Benchmark(Description = "LeichtFrame Sort (String)")]
        public DataFrame LF_Sort_String()
        {
            return _lfFrame.OrderBy("UniqueId");
        }

        // =========================================================
        // TOP-N (Smallest/Largest vs LIMIT)
        // =========================================================

        [Benchmark(Description = "DuckDB Top 10 (Int)")]
        public void DuckDB_TopN_Int()
        {
            using var cmd = _duckConnection.CreateCommand();
            cmd.CommandText = "SELECT * FROM BenchData ORDER BY Id ASC LIMIT 10";
            using var reader = cmd.ExecuteReader();

            while (reader.Read()) { }
        }

        [Benchmark(Description = "LeichtFrame Top 10 (Int)")]
        public DataFrame LF_TopN_Int()
        {
            // Uses optimized PriorityQueue implementation
            return _lfFrame.Smallest(10, "Id");
        }

        [Benchmark(Description = "DuckDB Top 10 (String)")]
        public void DuckDB_TopN_String()
        {
            using var cmd = _duckConnection.CreateCommand();
            cmd.CommandText = "SELECT * FROM BenchData ORDER BY UniqueId DESC LIMIT 10";
            using var reader = cmd.ExecuteReader();

            while (reader.Read()) { }
        }

        [Benchmark(Description = "LeichtFrame Top 10 (String)")]
        public DataFrame LF_TopN_String()
        {
            return _lfFrame.Largest(10, "UniqueId");
        }
    }
}
===== FILE: src/LeichtFrame.Core/Columns/BoolColumn.cs =====
using System.Buffers;
using System.Runtime.CompilerServices;

namespace LeichtFrame.Core
{
    /// <summary>
    /// A high-performance column for storing boolean values.
    /// Uses internal bit-packing (1 bit per boolean) to reduce memory usage by 87.5% compared to bool[].
    /// </summary>
    public class BoolColumn : Column<bool>, IDisposable
    {
        private byte[] _data; // 8 bools per byte
        private NullBitmap? _nulls;
        private int _length;

        /// <summary>
        /// Initializes a new instance of the <see cref="BoolColumn"/> class.
        /// </summary>
        /// <param name="name">The name of the column.</param>
        /// <param name="capacity">The initial capacity (number of rows).</param>
        /// <param name="isNullable">Whether the column supports null values.</param>
        public BoolColumn(string name, int capacity = 16, bool isNullable = false)
            : base(name, isNullable)
        {
            _length = 0;
            // Calculate required bytes: (capacity + 7) / 8
            int byteCount = (capacity + 7) >> 3;
            _data = ArrayPool<byte>.Shared.Rent(byteCount);
            Array.Clear(_data, 0, byteCount);

            if (isNullable)
            {
                _nulls = new NullBitmap(capacity);
            }
        }

        /// <inheritdoc />
        public override int Length => _length;

        /// <summary>
        /// Gets the raw values as memory.             
        /// <para>
        /// **Not Supported for BoolColumn:** Because booleans are bit-packed, they cannot be represented as a contiguous <see cref="ReadOnlyMemory{Boolean}"/>.
        /// Use <see cref="Get(int)"/> or specialized bulk operations instead.
        /// </para>
        /// </summary>
        /// <exception cref="NotSupportedException">Always thrown.</exception>
        public override ReadOnlyMemory<bool> Values => throw new NotSupportedException(
            "BoolColumn uses bit-packed storage. Cannot return ReadOnlyMemory<bool>. Use GetValue or dedicated bulk methods.");

        // --- Core Data Access ---

        /// <inheritdoc />
        public override bool Get(int index)
        {
            CheckBounds(index);
            return (_data[index >> 3] & (1 << (index & 7))) != 0;
        }

        /// <inheritdoc />
        public override void SetValue(int index, bool value)
        {
            CheckBounds(index);
            SetBit(index, value);
            _nulls?.SetNotNull(index);
        }

        [MethodImpl(MethodImplOptions.AggressiveInlining)]
        private void SetBit(int index, bool value)
        {
            int byteIndex = index >> 3;
            int bitMask = 1 << (index & 7);

            if (value)
                _data[byteIndex] |= (byte)bitMask;
            else
                _data[byteIndex] &= (byte)~bitMask;
        }

        /// <inheritdoc />
        public override void Append(bool value)
        {
            EnsureCapacity(_length + 1);
            SetBit(_length, value);
            _nulls?.SetNotNull(_length);
            _length++;
        }

        /// <summary>
        /// Appends a nullable boolean to the column.
        /// </summary>
        /// <param name="value">The value to append, or null.</param>
        public void Append(bool? value)
        {
            EnsureCapacity(_length + 1);
            if (value.HasValue)
            {
                SetBit(_length, value.Value);
                _nulls?.SetNotNull(_length);
            }
            else
            {
                if (_nulls == null) throw new InvalidOperationException("Cannot append null to non-nullable column.");
                SetBit(_length, false);
                _nulls.SetNull(_length);
            }
            _length++;
        }

        // --- Null Handling ---

        /// <inheritdoc />
        public override bool IsNull(int index)
        {
            CheckBounds(index);
            return _nulls != null && _nulls.IsNull(index);
        }

        /// <inheritdoc />
        public override void SetNull(int index)
        {
            CheckBounds(index);
            if (_nulls == null) throw new InvalidOperationException("Cannot set null on non-nullable column.");
            SetBit(index, false);
            _nulls.SetNull(index);
        }

        /// <summary>
        /// Marks the value at the specified index as not null.
        /// </summary>
        public override void SetNotNull(int index)
        {
            CheckBounds(index);
            _nulls?.SetNotNull(index);
        }

        // --- Bulk Operations ---

        /// <summary>
        /// Checks if any value in the column is true (optimized bit-scan).
        /// </summary>
        public bool AnyTrue()
        {
            if (_nulls == null)
            {
                int fullBytes = _length >> 3;
                for (int i = 0; i < fullBytes; i++)
                {
                    if (_data[i] != 0) return true;
                }
                for (int i = fullBytes * 8; i < _length; i++)
                {
                    if (Get(i)) return true;
                }
                return false;
            }
            else
            {
                for (int i = 0; i < _length; i++)
                {
                    if (!IsNull(i) && Get(i)) return true;
                }
                return false;
            }
        }

        /// <summary>
        /// Checks if all values in the column are true (optimized bit-scan).
        /// </summary>
        public bool AllTrue()
        {
            if (_length == 0) return true;

            if (_nulls == null)
            {
                int fullBytes = _length >> 3;
                for (int i = 0; i < fullBytes; i++)
                {
                    if (_data[i] != 0xFF) return false;
                }
                for (int i = fullBytes * 8; i < _length; i++)
                {
                    if (!Get(i)) return false;
                }
                return true;
            }
            else
            {
                for (int i = 0; i < _length; i++)
                {
                    if (!IsNull(i) && !Get(i)) return false;
                }
                return true;
            }
        }

        // --- Memory ---

        /// <inheritdoc />
        public override void EnsureCapacity(int minCapacity)
        {
            int currentByteCap = _data.Length;
            int requiredByteCap = (minCapacity + 7) >> 3;

            if (currentByteCap >= requiredByteCap) return;

            int newByteCap = Math.Max(currentByteCap * 2, requiredByteCap);

            var newBuffer = ArrayPool<byte>.Shared.Rent(newByteCap);

            Array.Copy(_data, newBuffer, (Length + 7) >> 3);
            Array.Clear(newBuffer, (Length + 7) >> 3, newByteCap - ((Length + 7) >> 3));

            ArrayPool<byte>.Shared.Return(_data);
            _data = newBuffer;

            _nulls?.Resize(minCapacity);
        }

        private void CheckBounds(int index)
        {
            if ((uint)index >= (uint)_length) throw new IndexOutOfRangeException();
        }

        /// <inheritdoc />
        public override IColumn CloneSubset(IReadOnlyList<int> indices)
        {
            var newCol = new BoolColumn(Name, indices.Count, IsNullable);

            for (int i = 0; i < indices.Count; i++)
            {
                int sourceIndex = indices[i];
                if (IsNullable && IsNull(sourceIndex))
                {
                    newCol.Append(null);
                }
                else
                {
                    newCol.Append(Get(sourceIndex));
                }
            }
            return newCol;
        }

        /// <inheritdoc />
        public void Dispose()
        {
            if (_data != null)
            {
                ArrayPool<byte>.Shared.Return(_data);
                _data = null!;
            }
            _nulls?.Dispose();
            _nulls = null;
        }
    }
}
===== FILE: src/LeichtFrame.Core/Columns/Column.cs =====
Ôªønamespace LeichtFrame.Core;

/// <summary>
/// Non-generic base class for all columns. 
/// Allows storing columns of different types in a single collection.
/// </summary>
public abstract class Column : IColumn
{
    /// <inheritdoc />
    public string Name { get; }

    /// <inheritdoc />
    public Type DataType { get; }

    /// <inheritdoc />
    public bool IsNullable { get; }

    /// <summary>
    /// Initializes a new instance of the <see cref="Column"/> class.
    /// </summary>
    /// <param name="name">The unique name of the column.</param>
    /// <param name="dataType">The CLR type of the data stored.</param>
    /// <param name="isNullable">Whether the column allows null values.</param>
    /// <exception cref="ArgumentException">Thrown if name is null or whitespace.</exception>
    /// <exception cref="ArgumentNullException">Thrown if dataType is null.</exception>
    protected Column(string name, Type dataType, bool isNullable)
    {
        if (string.IsNullOrWhiteSpace(name))
            throw new ArgumentException("Column name cannot be null or empty.", nameof(name));

        Name = name;
        DataType = dataType ?? throw new ArgumentNullException(nameof(dataType));
        IsNullable = isNullable;
    }

    /// <inheritdoc />
    public abstract int Length { get; }

    /// <inheritdoc />
    public abstract void EnsureCapacity(int capacity);

    /// <inheritdoc />
    public abstract object? GetValue(int index);

    /// <inheritdoc />
    public abstract void AppendObject(object? value);

    /// <inheritdoc />
    public abstract IColumn CloneSubset(IReadOnlyList<int> indices);

    /// <inheritdoc />
    public abstract bool IsNull(int index);

    /// <inheritdoc />
    public abstract void SetNull(int index);
}
===== FILE: src/LeichtFrame.Core/Columns/ColumnFactory.cs =====
namespace LeichtFrame.Core
{
    /// <summary>
    /// Factory class to create concrete column instances based on runtime types.
    /// Acts as the central registry for supported column types.
    /// </summary>
    public static class ColumnFactory
    {
        /// <summary>
        /// Creates a concrete column instance (e.g. <see cref="IntColumn"/>) based on the provided CLR type.
        /// </summary>
        /// <param name="name">The name of the column.</param>
        /// <param name="type">The data type (e.g. typeof(int)). Supported: int, double, bool, string, DateTime.</param>
        /// <param name="capacity">The initial capacity (number of rows) to allocate.</param>
        /// <param name="isNullable">Whether the column should support null values.</param>
        /// <returns>An <see cref="IColumn"/> instance containing the specific implementation.</returns>
        /// <exception cref="NotSupportedException">Thrown if the provided type is not supported by LeichtFrame.</exception>
        public static IColumn Create(string name, Type type, int capacity = 16, bool isNullable = false)
        {
            // WICHTIG: Nullable Typen auspacken (z.B. int? -> int)
            Type underlyingType = Nullable.GetUnderlyingType(type) ?? type;

            if (underlyingType == typeof(int))
                return new IntColumn(name, capacity, isNullable);

            if (underlyingType == typeof(double))
                return new DoubleColumn(name, capacity, isNullable);

            if (underlyingType == typeof(bool))
                return new BoolColumn(name, capacity, isNullable);

            if (underlyingType == typeof(string))
                return new StringColumn(name, capacity, isNullable);

            if (underlyingType == typeof(DateTime))
                return new DateTimeColumn(name, capacity, isNullable);

            throw new NotSupportedException($"Type {type.Name} is not supported yet.");
        }

        /// <summary>
        /// Generic convenience overload to create a strongly-typed column.
        /// </summary>
        /// <typeparam name="T">The data type of the column.</typeparam>
        /// <param name="name">The name of the column.</param>
        /// <param name="capacity">The initial capacity to allocate.</param>
        /// <param name="isNullable">Whether the column should support null values.</param>
        /// <returns>A typed <see cref="IColumn{T}"/> instance.</returns>
        public static IColumn<T> Create<T>(string name, int capacity = 16, bool isNullable = false)
        {
            return (IColumn<T>)Create(name, typeof(T), capacity, isNullable);
        }
    }
}
===== FILE: src/LeichtFrame.Core/Columns/ColumnT.cs =====
using System.Globalization;

namespace LeichtFrame.Core;

/// <summary>
/// Typed base class for columns storing specific data types (int, double, string, etc.).
/// </summary>
/// <typeparam name="T">The type of data stored in this column.</typeparam>
public abstract class Column<T> : Column, IColumn<T>
{
    /// <summary>
    /// Initializes a new instance of the <see cref="Column{T}"/> class.
    /// </summary>
    /// <param name="name">The name of the column.</param>
    /// <param name="isNullable">Whether the column supports null values.</param>
    protected Column(string name, bool isNullable = false) : base(name, typeof(T), isNullable)
    {
    }

    /// <summary>
    /// Gets the underlying memory storage of the column.
    /// </summary>
    public abstract ReadOnlyMemory<T> Values { get; }

    /// <summary>
    /// Gets the strongly-typed value at the specified index.
    /// </summary>
    /// <param name="index">The zero-based row index.</param>
    /// <returns>The value of type T.</returns>
    public abstract T Get(int index);

    /// <inheritdoc />
    public abstract void SetValue(int index, T value);

    // --- Interface Implementations ---

    /// <exclude />
    T IColumn<T>.GetValue(int index) => Get(index);

    /// <inheritdoc />
    public override object? GetValue(int index)
    {
        if (IsNullable && IsNull(index)) return null;
        return Get(index);
    }

    // --- Appending ---

    /// <inheritdoc />
    public abstract void Append(T value);

    // WICHTIG: Hier muss 'override' stehen, da es in 'Column' abstract ist.
    /// <inheritdoc />
    public override void AppendObject(object? value)
    {
        if (value is T typedVal)
        {
            Append(typedVal);
        }
        else if (value is null)
        {
            if (!IsNullable)
                throw new ArgumentException($"Cannot append null to non-nullable column '{Name}'.");

            Append(default!);
            SetNull(Length - 1);
        }
        else
        {
            try
            {
                var converted = (T)Convert.ChangeType(value, typeof(T), CultureInfo.InvariantCulture);
                Append(converted);
            }
            catch
            {
                throw new ArgumentException($"Cannot convert '{value}' to {typeof(T).Name}");
            }
        }
    }

    // --- Null Handling ---

    /// <inheritdoc />
    public abstract override bool IsNull(int index);

    /// <inheritdoc />
    public abstract override void SetNull(int index);

    /// <summary>
    /// Marks the value at the specified index as not null.
    /// </summary>
    /// <param name="index">The zero-based row index.</param>
    public abstract void SetNotNull(int index);

    // --- Slicing ---

    /// <inheritdoc />
    public virtual ReadOnlyMemory<T> Slice(int start, int length)
    {
        if ((uint)start > (uint)Length || (uint)length > (uint)(Length - start))
        {
            throw new ArgumentOutOfRangeException(nameof(start),
                $"Slice range {start}..{start + length} is out of bounds (Length: {Length}).");
        }

        return Values.Slice(start, length);
    }

    /// <inheritdoc />
    public virtual ReadOnlySpan<T> AsSpan() => Values.Span;
}
===== FILE: src/LeichtFrame.Core/Columns/DateTimeColumn.cs =====
using System.Buffers;

namespace LeichtFrame.Core
{
    /// <summary>
    /// A high-performance column for storing <see cref="DateTime"/> values.
    /// Uses pooled arrays for zero-allocation data management.
    /// </summary>
    public class DateTimeColumn : Column<DateTime>, IDisposable
    {
        private DateTime[] _data;
        private NullBitmap? _nulls;
        private int _length;

        /// <summary>
        /// Initializes a new instance of the <see cref="DateTimeColumn"/> class.
        /// </summary>
        /// <param name="name">The name of the column.</param>
        /// <param name="capacity">The initial capacity (number of rows).</param>
        /// <param name="isNullable">Whether the column supports null values.</param>
        public DateTimeColumn(string name, int capacity = 16, bool isNullable = false)
            : base(name, isNullable)
        {
            _length = 0;
            _data = ArrayPool<DateTime>.Shared.Rent(capacity);

            if (isNullable)
            {
                _nulls = new NullBitmap(capacity);
            }
        }

        /// <inheritdoc />
        public override int Length => _length;

        /// <inheritdoc />
        public override ReadOnlyMemory<DateTime> Values => new ReadOnlyMemory<DateTime>(_data, 0, _length);

        // --- Core Access ---

        /// <inheritdoc />
        public override DateTime Get(int index)
        {
            CheckBounds(index);
            return _data[index];
        }

        /// <inheritdoc />
        public override void SetValue(int index, DateTime value)
        {
            CheckBounds(index);
            _data[index] = value;
            _nulls?.SetNotNull(index);
        }

        /// <inheritdoc />
        public override void Append(DateTime value)
        {
            EnsureCapacity(_length + 1);
            _data[_length] = value;
            _nulls?.SetNotNull(_length);
            _length++;
        }

        /// <summary>
        /// Appends a nullable DateTime value.
        /// </summary>
        /// <param name="value">The value to append, or null.</param>
        /// <exception cref="InvalidOperationException">Thrown if null is passed to a non-nullable column.</exception>
        public void Append(DateTime? value)
        {
            EnsureCapacity(_length + 1);
            if (value.HasValue)
            {
                _data[_length] = value.Value;
                _nulls?.SetNotNull(_length);
            }
            else
            {
                if (_nulls == null)
                    throw new InvalidOperationException("Cannot append null to non-nullable column.");

                _data[_length] = default;
                _nulls.SetNull(_length);
            }
            _length++;
        }

        // --- Null Handling ---

        /// <inheritdoc />
        public override bool IsNull(int index)
        {
            CheckBounds(index);
            return _nulls != null && _nulls.IsNull(index);
        }

        /// <inheritdoc />
        public override void SetNull(int index)
        {
            CheckBounds(index);
            if (_nulls == null)
                throw new InvalidOperationException("Cannot set null on non-nullable column.");

            _data[index] = default;
            _nulls.SetNull(index);
        }

        /// <inheritdoc />
        public override void SetNotNull(int index)
        {
            CheckBounds(index);
            _nulls?.SetNotNull(index);
        }

        // --- Memory Management ---

        /// <inheritdoc />
        public override void EnsureCapacity(int minCapacity)
        {
            if (_data.Length >= minCapacity) return;

            int newCapacity = Math.Max(_data.Length * 2, minCapacity);

            var newBuffer = ArrayPool<DateTime>.Shared.Rent(newCapacity);
            Array.Copy(_data, newBuffer, _length);

            ArrayPool<DateTime>.Shared.Return(_data);
            _data = newBuffer;

            _nulls?.Resize(newCapacity);
        }

        private void CheckBounds(int index)
        {
            if ((uint)index >= (uint)_length)
                throw new IndexOutOfRangeException($"Index {index} is out of range.");
        }

        /// <inheritdoc />
        public override IColumn CloneSubset(IReadOnlyList<int> indices)
        {
            var newCol = new DateTimeColumn(Name, indices.Count, IsNullable);

            for (int i = 0; i < indices.Count; i++)
            {
                int sourceIndex = indices[i];
                if (IsNullable && IsNull(sourceIndex))
                {
                    newCol.Append(null);
                }
                else
                {
                    newCol.Append(Get(sourceIndex));
                }
            }
            return newCol;
        }

        /// <inheritdoc />
        public void Dispose()
        {
            if (_data != null)
            {
                ArrayPool<DateTime>.Shared.Return(_data);
                _data = null!;
            }
            _nulls?.Dispose();
            _nulls = null;
        }
    }
}
===== FILE: src/LeichtFrame.Core/Columns/DoubleColumn.cs =====
using System.Buffers;
using System.Numerics;
using System.Runtime.InteropServices;
using System.Runtime.CompilerServices;

namespace LeichtFrame.Core
{
    /// <summary>
    /// A high-performance column for storing <see cref="double"/> values.
    /// Supports optimized statistical operations like Sum, Min, and Max using contiguous memory and SIMD.
    /// </summary>
    public class DoubleColumn : Column<double>, IDisposable
    {
        private double[] _data;
        private NullBitmap? _nulls;
        private int _length;

        /// <summary>
        /// Initializes a new instance of the <see cref="DoubleColumn"/> class.
        /// </summary>
        /// <param name="name">The name of the column.</param>
        /// <param name="capacity">The initial capacity (number of rows).</param>
        /// <param name="isNullable">Whether the column supports null values.</param>
        public DoubleColumn(string name, int capacity = 16, bool isNullable = false)
            : base(name, isNullable)
        {
            _length = 0;
            _data = ArrayPool<double>.Shared.Rent(capacity);
            if (isNullable) _nulls = new NullBitmap(capacity);
        }

        /// <inheritdoc />
        public override int Length => _length;

        /// <inheritdoc />
        public override ReadOnlyMemory<double> Values => new ReadOnlyMemory<double>(_data, 0, _length);

        // --- Core Data Access ---

        /// <inheritdoc />
        public override double Get(int index)
        {
            CheckBounds(index);
            return _data[index];
        }

        /// <inheritdoc />
        public override void SetValue(int index, double value)
        {
            CheckBounds(index);
            _data[index] = value;
            _nulls?.SetNotNull(index);
        }

        /// <inheritdoc />
        public override void Append(double value)
        {
            EnsureCapacity(_length + 1);
            _data[_length] = value;
            _nulls?.SetNotNull(_length);
            _length++;
        }

        /// <summary>
        /// Appends a nullable double value to the column.
        /// </summary>
        /// <param name="value">The value to append, or null.</param>
        /// <exception cref="InvalidOperationException">Thrown if null is passed to a non-nullable column.</exception>
        public void Append(double? value)
        {
            EnsureCapacity(_length + 1);
            if (value.HasValue)
            {
                _data[_length] = value.Value;
                _nulls?.SetNotNull(_length);
            }
            else
            {
                if (_nulls == null) throw new InvalidOperationException("Cannot append null to non-nullable column.");
                _data[_length] = double.NaN;
                _nulls.SetNull(_length);
            }
            _length++;
        }

        // --- Null Handling ---

        /// <inheritdoc />
        public override bool IsNull(int index)
        {
            CheckBounds(index);
            return _nulls != null && _nulls.IsNull(index);
        }

        /// <inheritdoc />
        public override void SetNull(int index)
        {
            CheckBounds(index);
            if (_nulls == null) throw new InvalidOperationException("Cannot set null on non-nullable column.");
            _data[index] = double.NaN;
            _nulls.SetNull(index);
        }

        /// <inheritdoc />
        public override void SetNotNull(int index)
        {
            CheckBounds(index);
            _nulls?.SetNotNull(index);
        }

        // --- Statistical Helpers (SIMD Optimized) ---

        /// <summary>
        /// Calculates the sum of the column. Uses SIMD for non-nullable columns.
        /// </summary>
        [MethodImpl(MethodImplOptions.AggressiveInlining)]
        public double Sum()
        {
            // Optimization: If non-nullable, we can use SIMD and ignore null checks.
            // If nullable, we cannot blindly use SIMD because NaN + Value = NaN.
            if (IsNullable)
            {
                return SumNullable();
            }

            var span = Values.Span;
            double sum = 0;

            if (Vector.IsHardwareAccelerated && span.Length >= Vector<double>.Count)
            {
                var vectors = MemoryMarshal.Cast<double, Vector<double>>(span);
                var accVector = Vector<double>.Zero;

                foreach (var v in vectors)
                {
                    accVector += v;
                }

                sum += Vector.Sum(accVector);

                int processed = vectors.Length * Vector<double>.Count;
                span = span.Slice(processed);
            }

            // Tail loop
            foreach (var val in span)
            {
                sum += val;
            }

            return sum;
        }

        private double SumNullable()
        {
            double sum = 0;
            for (int i = 0; i < _length; i++)
            {
                if (!IsNull(i)) sum += _data[i];
            }
            return sum;
        }

        /// <summary>
        /// Finds the minimum value. Optimized for non-nullable.
        /// </summary>
        public double Min()
        {
            if (_length == 0) return 0;
            if (IsNullable) return MinNullable();

            // Non-Nullable Scalar Optimization (Fastest for Doubles due to NaN checks in SIMD being complex)
            var span = Values.Span;
            double min = double.MaxValue;
            foreach (var val in span)
            {
                if (val < min) min = val;
            }
            return min;
        }

        private double MinNullable()
        {
            double min = double.MaxValue;
            bool hasValue = false;
            for (int i = 0; i < _length; i++)
            {
                if (!IsNull(i))
                {
                    double val = _data[i];
                    if (val < min) min = val;
                    hasValue = true;
                }
            }
            return hasValue ? min : 0;
        }

        /// <summary>
        /// Finds the maximum value. Optimized for non-nullable.
        /// </summary>
        public double Max()
        {
            if (_length == 0) return 0;
            if (IsNullable) return MaxNullable();

            // Non-Nullable Scalar Optimization
            var span = Values.Span;
            double max = double.MinValue;
            foreach (var val in span)
            {
                if (val > max) max = val;
            }
            return max;
        }

        private double MaxNullable()
        {
            double max = double.MinValue;
            bool hasValue = false;
            for (int i = 0; i < _length; i++)
            {
                if (!IsNull(i))
                {
                    double val = _data[i];
                    if (val > max) max = val;
                    hasValue = true;
                }
            }
            return hasValue ? max : 0;
        }

        // --- Memory ---

        /// <inheritdoc />
        public override void EnsureCapacity(int minCapacity)
        {
            if (_data.Length >= minCapacity) return;
            int newCapacity = Math.Max(_data.Length * 2, minCapacity);

            var newBuffer = ArrayPool<double>.Shared.Rent(newCapacity);
            Array.Copy(_data, newBuffer, _length);
            ArrayPool<double>.Shared.Return(_data);
            _data = newBuffer;

            _nulls?.Resize(newCapacity);
        }

        private void CheckBounds(int index)
        {
            if ((uint)index >= (uint)_length) throw new IndexOutOfRangeException();
        }

        /// <inheritdoc />
        public override IColumn CloneSubset(IReadOnlyList<int> indices)
        {
            var newCol = new DoubleColumn(Name, indices.Count, IsNullable);

            for (int i = 0; i < indices.Count; i++)
            {
                int sourceIndex = indices[i];
                if (IsNullable && IsNull(sourceIndex))
                {
                    newCol.Append(null);
                }
                else
                {
                    newCol.Append(Get(sourceIndex));
                }
            }
            return newCol;
        }

        /// <inheritdoc />
        public void Dispose()
        {
            if (_data != null)
            {
                ArrayPool<double>.Shared.Return(_data);
                _data = null!;
            }
            _nulls?.Dispose();
            _nulls = null;
        }

        // --- Arithmetic Operators ---

        /// <summary>
        /// Adds two double columns element-wise.
        /// </summary>
        public static DoubleColumn operator +(DoubleColumn a, DoubleColumn b) => ExecuteOp(a, b, VectorizedMathOps.MathOp.Add);

        /// <summary>
        /// Subtracts the second double column from the first element-wise.
        /// </summary>
        public static DoubleColumn operator -(DoubleColumn a, DoubleColumn b) => ExecuteOp(a, b, VectorizedMathOps.MathOp.Subtract);

        /// <summary>
        /// Multiplies two double columns element-wise.
        /// </summary>
        public static DoubleColumn operator *(DoubleColumn a, DoubleColumn b) => ExecuteOp(a, b, VectorizedMathOps.MathOp.Multiply);

        /// <summary>
        /// Divides the first double column by the second element-wise.
        /// </summary>
        public static DoubleColumn operator /(DoubleColumn a, DoubleColumn b) => ExecuteOp(a, b, VectorizedMathOps.MathOp.Divide);

        /// <summary>
        /// Adds a scalar value to every element in the column.
        /// </summary>
        public static DoubleColumn operator +(DoubleColumn a, double b) => ExecuteOpScalar(a, b, VectorizedMathOps.MathOp.Add);

        /// <summary>
        /// Subtracts a scalar value from every element in the column.
        /// </summary>
        public static DoubleColumn operator -(DoubleColumn a, double b) => ExecuteOpScalar(a, b, VectorizedMathOps.MathOp.Subtract);

        /// <summary>
        /// Multiplies every element in the column by a scalar value.
        /// </summary>
        public static DoubleColumn operator *(DoubleColumn a, double b) => ExecuteOpScalar(a, b, VectorizedMathOps.MathOp.Multiply);

        /// <summary>
        /// Divides every element in the column by a scalar value.
        /// </summary>
        public static DoubleColumn operator /(DoubleColumn a, double b) => ExecuteOpScalar(a, b, VectorizedMathOps.MathOp.Divide);

        private static DoubleColumn ExecuteOp(DoubleColumn a, DoubleColumn b, VectorizedMathOps.MathOp op)
        {
            if (a.Length != b.Length) throw new ArgumentException("Column lengths mismatch");

            bool resultNullable = a.IsNullable || b.IsNullable;
            var result = new DoubleColumn($"{a.Name}_op_{b.Name}", a.Length, resultNullable);

            result._length = a.Length;
            VectorizedMathOps.Calculate<double>(a._data.AsSpan(0, a.Length), b._data.AsSpan(0, b.Length), result._data.AsSpan(0, a.Length), op);

            if (resultNullable)
            {
                result._nulls?.Dispose();
                result._nulls = NullBitmap.MergeOr(a._nulls, b._nulls, a.Length);
            }
            return result;
        }

        private static DoubleColumn ExecuteOpScalar(DoubleColumn a, double scalar, VectorizedMathOps.MathOp op)
        {
            var result = new DoubleColumn($"{a.Name}_op_scalar", a.Length, a.IsNullable);
            result._length = a.Length;

            VectorizedMathOps.CalculateScalar<double>(a._data.AsSpan(0, a.Length), scalar, result._data.AsSpan(0, a.Length), op);

            if (a.IsNullable && a._nulls != null)
            {
                result._nulls?.Dispose();
                result._nulls = NullBitmap.MergeOr(a._nulls, null, a.Length);
            }
            return result;
        }
    }
}
===== FILE: src/LeichtFrame.Core/Columns/IColumn.cs =====
namespace LeichtFrame.Core
{
    /// <summary>
    /// Represents a generic column in a DataFrame containing metadata and operations.
    /// </summary>
    public interface IColumn
    {
        /// <summary>
        /// Gets the unique name of the column.
        /// </summary>
        string Name { get; }

        /// <summary>
        /// Gets the CLR type of the data stored in this column.
        /// </summary>
        Type DataType { get; }

        /// <summary>
        /// Gets the number of rows in this column.
        /// </summary>
        int Length { get; }

        /// <summary>
        /// Indicates whether the column supports null values.
        /// </summary>
        bool IsNullable { get; }

        /// <summary>
        /// Ensures the column has space for at least the specified number of elements.
        /// If the capacity is increased, the underlying buffer is swapped.           
        /// <para>
        /// **SAFETY WARNING:** Because this library uses array pooling, 
        /// calling this method may return the old buffer to the pool.  
        /// Existing Spans pointing to the old buffer will become invalid.
        /// </para>
        /// </summary>
        /// <param name="capacity">The minimum required capacity.</param>
        void EnsureCapacity(int capacity);

        /// <summary>
        /// Gets the value at the specified index as an object (boxed).
        /// For high performance, use the typed interface <see cref="IColumn{T}"/>.
        /// </summary>
        /// <param name="index">The zero-based row index.</param>
        /// <returns>The value at the index, or null.</returns>
        object? GetValue(int index);

        /// <summary>
        /// Checks if the value at the specified index is null.
        /// </summary>
        bool IsNull(int index);

        /// <summary>
        /// Sets the value at the specified index to null.
        /// </summary>
        void SetNull(int index);

        /// <summary>
        /// Appends an untyped value to the end of the column.
        /// </summary>
        void AppendObject(object? value);

        /// <summary>
        /// Creates a deep copy of the column containing only the rows at the specified indices.
        /// </summary>
        /// <param name="indices">The list of row indices to copy.</param>
        /// <returns>A new column containing the subset of data.</returns>
        IColumn CloneSubset(IReadOnlyList<int> indices);
    }

    /// <summary>
    /// Typed interface for high-performance, zero-boxing data access.
    /// </summary>
    /// <typeparam name="T">The type of data stored in the column.</typeparam>
    public interface IColumn<T> : IColumn
    {
        /// <summary>
        /// Gets the strongly-typed value at the specified index.
        /// </summary>
        new T GetValue(int index);

        /// <summary>
        /// Sets the strongly-typed value at the specified index.
        /// </summary>
        void SetValue(int index, T value);


        /// <summary>
        /// Appends a strongly-typed value to the end of the column.
        /// </summary>
        void Append(T value);

        /// <summary>
        /// Returns a zero-copy view of the column data as a Memory region.
        /// </summary>
        ReadOnlyMemory<T> Slice(int start, int length);

        /// <summary>
        /// Returns the underlying data as a ReadOnlySpan for high-performance processing.
        /// </summary>
        ReadOnlySpan<T> AsSpan();
    }
}
===== FILE: src/LeichtFrame.Core/Columns/IndirectColumn.cs =====
namespace LeichtFrame.Core
{
    /// <summary>
    /// A zero-copy view over specific rows of another column.
    /// Uses an index map (indirection array) to point to the original data.
    /// <para>
    /// ‚ö†Ô∏è Limitations: 
    /// 1. Access is slightly slower due to double lookup.
    /// 2. Does NOT support contiguous Span/Memory access (.Values throws).
    /// </para>
    /// </summary>
    /// <typeparam name="T">The type of data stored in the column.</typeparam>
    public class IndirectColumn<T> : IColumn<T>, IDisposable
    {
        private readonly IColumn<T> _source;
        private readonly int[] _indices;

        /// <summary>
        /// Initializes a new instance of the <see cref="IndirectColumn{T}"/> class.
        /// </summary>
        /// <param name="source">The underlying source column.</param>
        /// <param name="indices">The indices map representing the view.</param>
        public IndirectColumn(IColumn<T> source, int[] indices)
        {
            _source = source ?? throw new ArgumentNullException(nameof(source));
            _indices = indices ?? throw new ArgumentNullException(nameof(indices));
        }

        /// <inheritdoc />
        public string Name => _source.Name;

        /// <inheritdoc />
        public Type DataType => _source.DataType;

        /// <inheritdoc />
        public int Length => _indices.Length;

        /// <inheritdoc />
        public bool IsNullable => _source.IsNullable;

        /// <summary>
        /// Not supported for IndirectColumn as data is scattered.
        /// </summary>
        public ReadOnlyMemory<T> Values => throw new NotSupportedException(
            "IndirectColumn does not support contiguous memory access. Materialize this column first.");

        /// <inheritdoc />
        public ReadOnlySpan<T> AsSpan() => throw new NotSupportedException(
            "IndirectColumn does not support Span access.");

        // --- Data Access ---

        /// <summary>
        /// Gets the strongly-typed value at the specified view index.
        /// </summary>
        public T Get(int index)
        {
            int realIndex = _indices[index];
            return _source.GetValue(realIndex);
        }

        // Explicit Interface Implementation to satisfy IColumn<T>
        T IColumn<T>.GetValue(int index) => Get(index);

        /// <inheritdoc />
        public object? GetValue(int index)
        {
            int realIndex = _indices[index];
            return _source.GetValue(realIndex);
        }

        /// <inheritdoc />
        public void SetValue(int index, T value)
        {
            int realIndex = _indices[index];
            _source.SetValue(realIndex, value);
        }

        // --- Null Handling ---

        /// <inheritdoc />
        public bool IsNull(int index)
        {
            int realIndex = _indices[index];
            return _source.IsNull(realIndex);
        }

        /// <inheritdoc />
        public void SetNull(int index)
        {
            int realIndex = _indices[index];
            _source.SetNull(realIndex);
        }

        // --- Mutation (Not Supported) ---

        /// <summary>
        /// Not supported for Indirect View.
        /// </summary>
        public void Append(T value) => throw new NotSupportedException("Cannot append to an Indirect View.");

        /// <summary>
        /// Not supported for Indirect View.
        /// </summary>
        public void AppendObject(object? value) => throw new NotSupportedException("Cannot append to an Indirect View.");

        /// <summary>
        /// Not supported for Indirect View.
        /// </summary>
        public void EnsureCapacity(int capacity) => throw new NotSupportedException("Cannot resize an Indirect View.");

        // --- Slicing & Cloning ---

        /// <inheritdoc />
        public ReadOnlyMemory<T> Slice(int start, int length)
        {
            throw new NotSupportedException("Cannot slice an IndirectColumn safely to Memory.");
        }

        /// <inheritdoc />
        public IColumn CloneSubset(IReadOnlyList<int> indices)
        {
            // Deep Clone: Materialize the subset
            var newCol = ColumnFactory.Create<T>(Name, indices.Count, IsNullable);

            for (int i = 0; i < indices.Count; i++)
            {
                int viewIndex = indices[i];
                if (viewIndex < 0 || viewIndex >= _indices.Length) throw new IndexOutOfRangeException();

                int realIndex = _indices[viewIndex];

                if (IsNullable && _source.IsNull(realIndex))
                {
                    newCol.Append(default!);
                    newCol.SetNull(i);
                }
                else
                {
                    newCol.Append(_source.GetValue(realIndex));
                }
            }
            return newCol;
        }

        /// <inheritdoc />
        public void Dispose()
        {
            // We do not own the source, so we do NOT dispose it.
        }
    }
}
===== FILE: src/LeichtFrame.Core/Columns/IntColumn.cs =====
using System.Buffers;
using System.Numerics;
using System.Runtime.InteropServices;
using System.Runtime.CompilerServices;

namespace LeichtFrame.Core
{
    /// <summary>
    /// A high-performance column for storing <see cref="int"/> values.
    /// Uses pooled arrays for zero-allocation data management.
    /// </summary>
    public class IntColumn : Column<int>, IDisposable
    {
        private int[] _data;
        private NullBitmap? _nulls;
        private int _length;

        /// <summary>
        /// Initializes a new instance of the <see cref="IntColumn"/> class.
        /// </summary>
        /// <param name="name">The name of the column.</param>
        /// <param name="capacity">The initial capacity (number of rows).</param>
        /// <param name="isNullable">Whether the column supports null values.</param>
        public IntColumn(string name, int capacity = 16, bool isNullable = false)
            : base(name, isNullable)
        {
            _length = 0;
            _data = ArrayPool<int>.Shared.Rent(capacity);

            if (isNullable)
            {
                _nulls = new NullBitmap(capacity);
            }
        }

        /// <inheritdoc />
        public override int Length => _length;

        /// <inheritdoc />
        public override ReadOnlyMemory<int> Values => new ReadOnlyMemory<int>(_data, 0, _length);

        // --- Core Get/Set ---

        /// <inheritdoc />
        public override int Get(int index)
        {
            CheckBounds(index);
            return _data[index];
        }

        /// <inheritdoc />
        public override void SetValue(int index, int value)
        {
            CheckBounds(index);
            _data[index] = value;
            _nulls?.SetNotNull(index);
        }

        // --- Append ---

        /// <inheritdoc />
        public override void Append(int value)
        {
            EnsureCapacity(_length + 1);
            _data[_length] = value;
            _nulls?.SetNotNull(_length);
            _length++;
        }

        /// <summary>
        /// Appends a nullable integer value to the column.
        /// </summary>
        /// <param name="value">The value to append, or null.</param>
        /// <exception cref="InvalidOperationException">Thrown if null is passed to a non-nullable column.</exception>
        public void Append(int? value)
        {
            EnsureCapacity(_length + 1);

            if (value.HasValue)
            {
                _data[_length] = value.Value;
                _nulls?.SetNotNull(_length);
            }
            else
            {
                if (_nulls == null)
                    throw new InvalidOperationException("Cannot append null to a non-nullable column.");

                _data[_length] = default;
                _nulls.SetNull(_length);
            }
            _length++;
        }

        // --- Null Handling ---

        /// <inheritdoc />
        public override bool IsNull(int index)
        {
            CheckBounds(index);
            return _nulls != null && _nulls.IsNull(index);
        }

        /// <inheritdoc />
        public override void SetNull(int index)
        {
            CheckBounds(index);
            if (_nulls == null)
                throw new InvalidOperationException("Cannot set null on a non-nullable column.");

            _data[index] = default;
            _nulls.SetNull(index);
        }

        /// <inheritdoc />
        public override void SetNotNull(int index)
        {
            CheckBounds(index);
            _nulls?.SetNotNull(index);
        }

        // --- SIMD Aggregations ---

        /// <summary>
        /// Calculates the sum of the column using SIMD with overflow protection (extends to long).
        /// </summary>
        [MethodImpl(MethodImplOptions.AggressiveInlining)]
        public long Sum()
        {
            var span = Values.Span;
            long sum = 0;

            if (Vector.IsHardwareAccelerated && span.Length >= Vector<int>.Count)
            {
                var vectors = MemoryMarshal.Cast<int, Vector<int>>(span);

                // We utilize Vector<long> to accumulate sums to prevent 32-bit overflow.
                var accVectorLow = Vector<long>.Zero;
                var accVectorHigh = Vector<long>.Zero;

                foreach (var v in vectors)
                {
                    // Widen: Split Vector<int> into two Vector<long>
                    Vector.Widen(v, out var low, out var high);
                    accVectorLow += low;
                    accVectorHigh += high;
                }

                // Sum up the lanes of the long accumulators
                sum += Vector.Sum(accVectorLow);
                sum += Vector.Sum(accVectorHigh);

                // Handle remaining elements (Tail)
                int processed = vectors.Length * Vector<int>.Count;
                span = span.Slice(processed);
            }

            // Scalar fallback / Tail loop
            foreach (var val in span)
            {
                sum += val;
            }

            return sum;
        }

        /// <summary>
        /// Calculates the minimum value using SIMD (only for non-nullable).
        /// </summary>
        public int Min()
        {
            if (_length == 0) return 0;

            // SIMD is only safe for non-nullable columns because '0' (null representation) 
            // would falsify the Min calculation.
            if (IsNullable)
            {
                return MinNullable();
            }

            var span = Values.Span;
            int min = int.MaxValue;

            if (Vector.IsHardwareAccelerated && span.Length >= Vector<int>.Count)
            {
                var vectors = MemoryMarshal.Cast<int, Vector<int>>(span);
                var minVector = new Vector<int>(int.MaxValue);

                foreach (var v in vectors)
                {
                    minVector = Vector.Min(minVector, v);
                }

                // Reduce vector lanes
                for (int i = 0; i < Vector<int>.Count; i++)
                {
                    if (minVector[i] < min) min = minVector[i];
                }

                int processed = vectors.Length * Vector<int>.Count;
                span = span.Slice(processed);
            }

            foreach (var val in span)
            {
                if (val < min) min = val;
            }

            return min;
        }

        /// <summary>
        /// Calculates the maximum value using SIMD (only for non-nullable).
        /// </summary>
        public int Max()
        {
            if (_length == 0) return 0;

            if (IsNullable)
            {
                return MaxNullable();
            }

            var span = Values.Span;
            int max = int.MinValue;

            if (Vector.IsHardwareAccelerated && span.Length >= Vector<int>.Count)
            {
                var vectors = MemoryMarshal.Cast<int, Vector<int>>(span);
                var maxVector = new Vector<int>(int.MinValue);

                foreach (var v in vectors)
                {
                    maxVector = Vector.Max(maxVector, v);
                }

                for (int i = 0; i < Vector<int>.Count; i++)
                {
                    if (maxVector[i] > max) max = maxVector[i];
                }

                int processed = vectors.Length * Vector<int>.Count;
                span = span.Slice(processed);
            }

            foreach (var val in span)
            {
                if (val > max) max = val;
            }

            return max;
        }

        // Fallback helpers for Nullable types (Scalar loop with null checks)
        private int MinNullable()
        {
            int min = int.MaxValue;
            bool hasValue = false;
            for (int i = 0; i < _length; i++)
            {
                if (!IsNull(i))
                {
                    int val = _data[i];
                    if (val < min) min = val;
                    hasValue = true;
                }
            }
            return hasValue ? min : 0;
        }

        private int MaxNullable()
        {
            int max = int.MinValue;
            bool hasValue = false;
            for (int i = 0; i < _length; i++)
            {
                if (!IsNull(i))
                {
                    int val = _data[i];
                    if (val > max) max = val;
                    hasValue = true;
                }
            }
            return hasValue ? max : 0;
        }

        // --- Memory Management ---

        /// <inheritdoc />
        public override void EnsureCapacity(int minCapacity)
        {
            if (_data.Length >= minCapacity) return;

            int newCapacity = Math.Max(_data.Length * 2, minCapacity);

            var newBuffer = ArrayPool<int>.Shared.Rent(newCapacity);
            Array.Copy(_data, newBuffer, _length);
            ArrayPool<int>.Shared.Return(_data);
            _data = newBuffer;

            _nulls?.Resize(newCapacity);
        }

        private void CheckBounds(int index)
        {
            if ((uint)index >= (uint)_length)
                throw new IndexOutOfRangeException($"Index {index} is out of range (Length: {_length})");
        }

        /// <inheritdoc />
        public override IColumn CloneSubset(IReadOnlyList<int> indices)
        {
            var newCol = new IntColumn(Name, indices.Count, IsNullable);

            for (int i = 0; i < indices.Count; i++)
            {
                int sourceIndex = indices[i];
                if (IsNullable && IsNull(sourceIndex))
                {
                    newCol.Append(null);
                }
                else
                {
                    newCol.Append(Get(sourceIndex));
                }
            }
            return newCol;
        }

        /// <inheritdoc />
        public void Dispose()
        {
            if (_data != null)
            {
                ArrayPool<int>.Shared.Return(_data);
                _data = null!;
            }

            _nulls?.Dispose();
            _nulls = null;
        }

        // --- Arithmetic Operators ---

        /// <summary>
        /// Adds two integer columns element-wise.
        /// </summary>
        public static IntColumn operator +(IntColumn a, IntColumn b) => ExecuteOp(a, b, VectorizedMathOps.MathOp.Add);

        /// <summary>
        /// Subtracts the second integer column from the first element-wise.
        /// </summary>
        public static IntColumn operator -(IntColumn a, IntColumn b) => ExecuteOp(a, b, VectorizedMathOps.MathOp.Subtract);

        /// <summary>
        /// Multiplies two integer columns element-wise.
        /// </summary>
        public static IntColumn operator *(IntColumn a, IntColumn b) => ExecuteOp(a, b, VectorizedMathOps.MathOp.Multiply);

        /// <summary>
        /// Divides the first integer column by the second element-wise.
        /// </summary>
        public static IntColumn operator /(IntColumn a, IntColumn b) => ExecuteOp(a, b, VectorizedMathOps.MathOp.Divide);

        /// <summary>
        /// Adds a scalar value to every element in the column.
        /// </summary>
        public static IntColumn operator +(IntColumn a, int b) => ExecuteOpScalar(a, b, VectorizedMathOps.MathOp.Add);

        /// <summary>
        /// Subtracts a scalar value from every element in the column.
        /// </summary>
        public static IntColumn operator -(IntColumn a, int b) => ExecuteOpScalar(a, b, VectorizedMathOps.MathOp.Subtract);

        /// <summary>
        /// Multiplies every element in the column by a scalar value.
        /// </summary>
        public static IntColumn operator *(IntColumn a, int b) => ExecuteOpScalar(a, b, VectorizedMathOps.MathOp.Multiply);

        /// <summary>
        /// Divides every element in the column by a scalar value.
        /// </summary>
        public static IntColumn operator /(IntColumn a, int b) => ExecuteOpScalar(a, b, VectorizedMathOps.MathOp.Divide);

        private static IntColumn ExecuteOp(IntColumn a, IntColumn b, VectorizedMathOps.MathOp op)
        {
            if (a.Length != b.Length) throw new ArgumentException("Column lengths mismatch");

            bool resultNullable = a.IsNullable || b.IsNullable;
            var result = new IntColumn($"{a.Name}_op_{b.Name}", a.Length, resultNullable);

            result._length = a.Length;
            VectorizedMathOps.Calculate<int>(a._data.AsSpan(0, a.Length), b._data.AsSpan(0, b.Length), result._data.AsSpan(0, a.Length), op);

            if (resultNullable)
            {
                result._nulls?.Dispose();
                result._nulls = NullBitmap.MergeOr(a._nulls, b._nulls, a.Length);
            }
            return result;
        }

        private static IntColumn ExecuteOpScalar(IntColumn a, int scalar, VectorizedMathOps.MathOp op)
        {
            var result = new IntColumn($"{a.Name}_op_scalar", a.Length, a.IsNullable);
            result._length = a.Length;

            VectorizedMathOps.CalculateScalar<int>(a._data.AsSpan(0, a.Length), scalar, result._data.AsSpan(0, a.Length), op);

            if (a.IsNullable && a._nulls != null)
            {
                result._nulls?.Dispose();
                result._nulls = NullBitmap.MergeOr(a._nulls, null, a.Length);
            }
            return result;
        }
    }
}
===== FILE: src/LeichtFrame.Core/Columns/SlicedColumn.cs =====
using System;
using System.Collections.Generic;

namespace LeichtFrame.Core
{
    /// <summary>
    /// A zero-copy view over a subset of another column.
    /// Delegates calls to the source column with an index offset without allocating new memory for data.
    /// </summary>
    /// <typeparam name="T">The type of data stored in the column.</typeparam>
    public class SlicedColumn<T> : IColumn<T>, IDisposable
    {
        private readonly IColumn<T> _source;
        private readonly int _offset;
        private readonly int _length;

        /// <summary>
        /// Initializes a new instance of the <see cref="SlicedColumn{T}"/> class.
        /// </summary>
        /// <param name="source">The underlying source column.</param>
        /// <param name="offset">The zero-based starting index in the source column.</param>
        /// <param name="length">The number of rows in the slice.</param>
        /// <exception cref="ArgumentOutOfRangeException">Thrown if offset or length are negative.</exception>
        /// <exception cref="ArgumentException">Thrown if the slice range exceeds the source column bounds.</exception>
        public SlicedColumn(IColumn<T> source, int offset, int length)
        {
            if (offset < 0) throw new ArgumentOutOfRangeException(nameof(offset));
            if (length < 0) throw new ArgumentOutOfRangeException(nameof(length));

            if (offset + length > source.Length)
                throw new ArgumentException($"Slice range ({offset}..{offset + length}) exceeds source column bounds (Length: {source.Length}).");

            _source = source;
            _offset = offset;
            _length = length;
        }

        /// <inheritdoc />
        public string Name => _source.Name;

        /// <inheritdoc />
        public Type DataType => _source.DataType;

        /// <inheritdoc />
        public int Length => _length;

        /// <inheritdoc />
        public bool IsNullable => _source.IsNullable;

        /// <summary>
        /// Gets the underlying memory storage of the slice.
        /// </summary>
        public ReadOnlyMemory<T> Values => _source.Slice(_offset, _length);

        /// <inheritdoc />
        public ReadOnlySpan<T> AsSpan() => Values.Span;

        // --- Data Access ---

        /// <inheritdoc cref="IColumn{T}.GetValue(int)" />
        public T Get(int index)
        {
            CheckBounds(index);
            return _source.GetValue(index + _offset);
        }

        // Interface Implementation
        /// <exclude />
        T IColumn<T>.GetValue(int index) => Get(index);

        /// <inheritdoc />
        public object? GetValue(int index)
        {
            CheckBounds(index);
            return _source.GetValue(index + _offset);
        }

        /// <inheritdoc />
        public void SetValue(int index, T value)
        {
            CheckBounds(index);
            _source.SetValue(index + _offset, value);
        }

        // --- Appending (Not Supported for Views) ---
        // Views cannot grow, so we explicitly forbid appending.

        /// <summary>
        /// Not supported for SlicedColumn. Slices have a fixed size.
        /// </summary>
        /// <exception cref="NotSupportedException">Always thrown.</exception>
        public void Append(T value)
        {
            throw new NotSupportedException("Cannot append to a SlicedColumn view. Append to the source column instead.");
        }

        /// <summary>
        /// Not supported for SlicedColumn. Slices have a fixed size.
        /// </summary>
        /// <exception cref="NotSupportedException">Always thrown.</exception>
        public void AppendObject(object? value)
        {
            throw new NotSupportedException("Cannot append to a SlicedColumn view. Append to the source column instead.");
        }

        /// <summary>
        /// Not supported for SlicedColumn.
        /// </summary>
        /// <exception cref="NotSupportedException">Always thrown.</exception>
        public void EnsureCapacity(int capacity)
        {
            throw new NotSupportedException("Cannot resize a SlicedColumn view.");
        }

        // --- Slicing ---

        /// <inheritdoc />
        public ReadOnlyMemory<T> Slice(int start, int length)
        {
            CheckBounds(start);
            if (start + length > _length) throw new ArgumentOutOfRangeException(nameof(length));

            // Delegate to source slice with accumulated offset
            return _source.Slice(start + _offset, length);
        }

        /// <inheritdoc />
        public IColumn CloneSubset(IReadOnlyList<int> indices)
        {
            var mappedIndices = new int[indices.Count];
            for (int i = 0; i < indices.Count; i++)
            {
                if (indices[i] < 0 || indices[i] >= _length)
                    throw new IndexOutOfRangeException();

                mappedIndices[i] = indices[i] + _offset;
            }
            return _source.CloneSubset(mappedIndices);
        }

        // --- Null Handling ---

        /// <inheritdoc />
        public bool IsNull(int index)
        {
            CheckBounds(index);
            return _source.IsNull(index + _offset);
        }

        /// <inheritdoc />
        public void SetNull(int index)
        {
            CheckBounds(index);
            _source.SetNull(index + _offset);
        }

        // --- Helpers ---

        /// <inheritdoc />
        public void Dispose()
        {
            // Do nothing. We do NOT own the underlying memory.
        }

        private void CheckBounds(int index)
        {
            if ((uint)index >= (uint)_length)
                throw new IndexOutOfRangeException($"Index {index} is out of slice bounds (Length {_length})");
        }
    }
}
===== FILE: src/LeichtFrame.Core/Columns/StringColumn.cs =====
using System.Buffers;
using System.Runtime.CompilerServices;
using System.Text;

namespace LeichtFrame.Core
{
    /// <summary>
    /// A high-performance column for storing variable-length strings using Arrow-style layout.
    /// Data is stored as contiguous UTF-8 bytes to minimize GC pressure and improve locality.
    /// </summary>
    public class StringColumn : Column<string?>, IDisposable
    {
        // 1. Offsets: Start position of each string in the byte buffer. Size: RowCount + 1
        private int[] _offsets;

        // 2. Values: The concatenated UTF-8 bytes of all strings.
        private byte[] _values;

        // 3. Nulls: Bitmap for null values.
        private NullBitmap? _nulls;

        private int _length;          // Number of rows
        private int _totalByteCount;  // Currently used bytes in _values

        /// <summary>
        /// Initializes a new instance of the <see cref="StringColumn"/> class.
        /// </summary>
        /// <param name="name">The name of the column.</param>
        /// <param name="capacity">The initial row capacity.</param>
        /// <param name="isNullable">Whether nulls are allowed.</param>
        public StringColumn(string name, int capacity = 16, bool isNullable = false)
            : base(name, isNullable)
        {
            _length = 0;
            _totalByteCount = 0;

            // Offsets always need N+1 entries (Start of next is End of current)
            _offsets = ArrayPool<int>.Shared.Rent(capacity + 1);
            _offsets[0] = 0;

            // Heuristic: Assume average string length is 32 bytes.
            // This prevents frequent resizing at the beginning.
            int initialByteCapacity = capacity * 32;
            if (initialByteCapacity < 64) initialByteCapacity = 64;

            _values = ArrayPool<byte>.Shared.Rent(initialByteCapacity);

            if (isNullable)
            {
                _nulls = new NullBitmap(capacity);
            }
        }

        /// <inheritdoc />
        public override int Length => _length;

        /// <summary>
        /// Not supported for variable length layout directly as contiguous memory.
        /// Use <see cref="Get(int)"/> or specialized Span accessors.
        /// </summary>
        /// <exception cref="NotSupportedException">Always thrown.</exception>
        public override ReadOnlyMemory<string?> Values => throw new NotSupportedException(
            "StringColumn uses Arrow-style byte storage. Contiguous string references are not available.");

        // --- Core Access ---

        /// <inheritdoc />
        [MethodImpl(MethodImplOptions.AggressiveInlining)]
        public override string? Get(int index)
        {
            CheckBounds(index);

            if (_nulls != null && _nulls.IsNull(index))
                return null;

            int start = _offsets[index];
            int end = _offsets[index + 1]; // Length = Offset[i+1] - Offset[i]
            int byteLen = end - start;

            if (byteLen == 0) return string.Empty;

            // Allocates a new string (Lazy Decoding)
            return Encoding.UTF8.GetString(_values, start, byteLen);
        }

        /// <summary>
        /// Sets the value at the specified index.
        /// <para>
        /// ‚ö†Ô∏è **PERFORMANCE WARNING:** This operation is **O(N)** because it requires shifting all subsequent bytes 
        /// in the underlying buffer to accommodate the new string length. 
        /// Use this method only for corrections, not for bulk updates.
        /// </para>
        /// </summary>
        /// <param name="index">The zero-based row index.</param>
        /// <param name="value">The new string value.</param>
        public override void SetValue(int index, string? value)
        {
            CheckBounds(index);

            // 1. Determine old length
            int oldStart = _offsets[index];
            int oldLen = _offsets[index + 1] - oldStart;

            // 2. Calculate new length
            int newLen = 0;
            byte[]? newBytes = null;

            if (value != null)
            {
                // Optimization: Encoding.UTF8.GetByteCount would be faster for alloc check,
                // but we need the bytes anyway.
                newBytes = Encoding.UTF8.GetBytes(value);
                newLen = newBytes.Length;
            }

            // 3. Calculate shift difference
            int diff = newLen - oldLen;

            // Make space or close gap?
            if (diff > 0)
            {
                EnsureByteCapacity(_totalByteCount + diff);
                // Shift Right: Move everything after the old string to the right
                Array.Copy(_values, oldStart + oldLen,
                           _values, oldStart + newLen,
                           _totalByteCount - (oldStart + oldLen));
            }
            else if (diff < 0)
            {
                // Shift Left: Pull everything forward
                Array.Copy(_values, oldStart + oldLen,
                           _values, oldStart + newLen,
                           _totalByteCount - (oldStart + oldLen));
            }

            // 4. Write data
            if (newBytes != null)
            {
                Array.Copy(newBytes, 0, _values, oldStart, newLen);
                if (IsNullable) SetNotNull(index);
            }
            else
            {
                if (!IsNullable) throw new ArgumentNullException(nameof(value), "Column is not nullable");
                _nulls?.SetNull(index);
            }

            // 5. Update offsets (for ALL subsequent rows!)
            for (int i = index + 1; i <= _length; i++)
            {
                _offsets[i] += diff;
            }

            _totalByteCount += diff;
        }

        /// <inheritdoc />
        public override void Append(string? value)
        {
            EnsureCapacity(_length + 1);

            int byteLen = 0;
            if (value != null)
            {
                // 1. Calculate bytes
                byteLen = Encoding.UTF8.GetByteCount(value);

                // 2. Ensure byte capacity
                EnsureByteCapacity(_totalByteCount + byteLen);

                // 3. Write bytes
                Encoding.UTF8.GetBytes(value, 0, value.Length, _values, _totalByteCount);

                if (_nulls != null) _nulls.SetNotNull(_length);
            }
            else
            {
                if (_nulls == null)
                    throw new InvalidOperationException("Cannot append null to non-nullable column.");

                _nulls.SetNull(_length);
            }

            // 4. Update pointers
            _totalByteCount += byteLen;
            _offsets[_length + 1] = _totalByteCount;

            _length++;
        }

        /// <summary>
        /// Compares the string at indexA with the string at indexB directly on the byte buffer.
        /// Returns -1, 0, or 1.
        /// Zero-Allocation implementation.
        /// </summary>
        public int CompareRaw(int indexA, int indexB)
        {
            // 1. Null Handling
            bool nullA = IsNull(indexA);
            bool nullB = IsNull(indexB);

            if (nullA && nullB) return 0;
            if (nullA) return -1; // Null is smaller
            if (nullB) return 1;

            // 2. Get Spans (Zero-Copy pointers)
            int startA = _offsets[indexA];
            int lenA = _offsets[indexA + 1] - startA;
            ReadOnlySpan<byte> spanA = _values.AsSpan(startA, lenA);

            int startB = _offsets[indexB];
            int lenB = _offsets[indexB + 1] - startB;
            ReadOnlySpan<byte> spanB = _values.AsSpan(startB, lenB);

            // 3. Compare Bytes directly
            // SequenceCompareTo is an optimized .NET intrinsic method
            return spanA.SequenceCompareTo(spanB);
        }

        // --- INTERNAL ACCESS FOR OPTIMIZED OPS ---

        /// <summary>Internal access to raw offsets for high-performance grouping/sorting.</summary>
        internal int[] Offsets => _offsets;

        /// <summary>Internal access to raw bytes for high-performance grouping/sorting.</summary>
        internal byte[] RawBytes => _values;

        // --- Null Handling ---

        /// <inheritdoc />
        [MethodImpl(MethodImplOptions.AggressiveInlining)]
        public override bool IsNull(int index)
        {
            CheckBounds(index);
            return _nulls != null && _nulls.IsNull(index);
        }

        /// <inheritdoc />
        public override void SetNull(int index)
        {
            // We use SetValue to correctly shift bytes (length 0).
            SetValue(index, null);
        }

        /// <inheritdoc />
        public override void SetNotNull(int index)
        {
            CheckBounds(index);
            _nulls?.SetNotNull(index);
        }

        // --- Memory ---

        /// <inheritdoc />
        public override void EnsureCapacity(int minCapacity)
        {
            // 1. Resize Offsets Array (Rows)
            if (_offsets.Length < minCapacity + 1)
            {
                int newCap = Math.Max(_offsets.Length * 2, minCapacity + 1);
                var newBuf = ArrayPool<int>.Shared.Rent(newCap);
                Array.Copy(_offsets, newBuf, _length + 1);
                ArrayPool<int>.Shared.Return(_offsets);
                _offsets = newBuf;

                _nulls?.Resize(newCap);
            }
        }

        private void EnsureByteCapacity(int minBytes)
        {
            if (_values.Length < minBytes)
            {
                // Double capacity or match required bytes
                int newCap = Math.Max(_values.Length * 2, minBytes);
                var newBuf = ArrayPool<byte>.Shared.Rent(newCap);

                Array.Copy(_values, newBuf, _totalByteCount);

                ArrayPool<byte>.Shared.Return(_values);
                _values = newBuf;
            }
        }

        private void CheckBounds(int index)
        {
            if ((uint)index >= (uint)_length) throw new IndexOutOfRangeException();
        }

        /// <inheritdoc />
        public override IColumn CloneSubset(IReadOnlyList<int> indices)
        {
            var newCol = new StringColumn(Name, indices.Count, IsNullable);
            foreach (var idx in indices)
            {
                // Currently decoding the string.
                // In Phase 3, we could implement "Raw Byte Copy" for speed.
                newCol.Append(Get(idx));
            }
            return newCol;
        }

        /// <inheritdoc />
        public void Dispose()
        {
            if (_offsets != null)
            {
                ArrayPool<int>.Shared.Return(_offsets);
                _offsets = null!;
            }
            if (_values != null)
            {
                ArrayPool<byte>.Shared.Return(_values);
                _values = null!;
            }
            _nulls?.Dispose();
            _nulls = null;
        }
    }
}
===== FILE: src/LeichtFrame.Core/CompareOp.cs =====
namespace LeichtFrame.Core
{
    /// <summary>
    /// Defines the comparison operations available for vectorized filtering.
    /// </summary>
    public enum CompareOp
    {
        /// <summary>
        /// Checks if the value is equal to the target.
        /// </summary>
        Equal,

        /// <summary>
        /// Checks if the value is not equal to the target.
        /// </summary>
        NotEqual,

        /// <summary>
        /// Checks if the value is strictly greater than the target.
        /// </summary>
        GreaterThan,

        /// <summary>
        /// Checks if the value is greater than or equal to the target.
        /// </summary>
        GreaterThanOrEqual,

        /// <summary>
        /// Checks if the value is strictly less than the target.
        /// </summary>
        LessThan,

        /// <summary>
        /// Checks if the value is less than or equal to the target.
        /// </summary>
        LessThanOrEqual
    }
}
===== FILE: src/LeichtFrame.Core/DataFrame/DataFrame.cs =====
using System.Reflection;
using System.Text;

namespace LeichtFrame.Core
{
    /// <summary>
    /// Represents a high-performance, column-oriented in-memory data table.
    /// Optimized for low memory allocation and fast analytical queries using SIMD and <see cref="Span{T}"/>.
    /// </summary>
    public class DataFrame : IDisposable
    {
        /// <summary>
        /// Creates a new, empty DataFrame based on the provided schema.
        /// Pre-allocates memory for the specified capacity to minimize resize operations.
        /// </summary>
        /// <param name="schema">The schema defining the columns.</param>
        /// <param name="capacity">The initial capacity (number of rows) to reserve.</param>
        /// <returns>A new DataFrame instance.</returns>
        public static DataFrame Create(DataFrameSchema schema, int capacity = 16)
        {
            if (schema == null) throw new ArgumentNullException(nameof(schema));
            if (capacity < 0) throw new ArgumentOutOfRangeException(nameof(capacity));

            var columns = new List<IColumn>(schema.Columns.Count);

            foreach (var colDef in schema.Columns)
            {
                var col = ColumnFactory.Create(colDef.Name, colDef.DataType, capacity, colDef.IsNullable);
                columns.Add(col);
            }

            return new DataFrame(columns);
        }

        /// <summary>
        /// Returns a short summary of the DataFrame (e.g., "DataFrame (1000 rows, 5 columns)").
        /// </summary>
        public override string ToString()
        {
            return $"DataFrame ({RowCount} rows, {ColumnCount} columns)";
        }

        /// <summary>
        /// Generates a formatted string representing the first N rows of the DataFrame.
        /// Useful for console output and debugging.
        /// </summary>
        /// <param name="limit">The maximum number of rows to display (default 10).</param>
        public string Inspect(int limit = 10)
        {
            if (ColumnCount == 0) return "Empty DataFrame";

            var sb = new StringBuilder();
            sb.AppendLine(ToString());
            sb.AppendLine(new string('-', 30));

            int rowsToShow = Math.Min(RowCount, limit);

            // 1. Calculate optimal column widths based on Header and Visible Data
            int[] widths = new int[ColumnCount];
            for (int c = 0; c < ColumnCount; c++)
            {
                var col = _columns[c];
                int maxWidth = col.Name.Length;

                // Consider type name length (e.g., <Int32>)
                maxWidth = Math.Max(maxWidth, col.DataType.Name.Length + 2);

                // Scan visible data for width
                for (int r = 0; r < rowsToShow; r++)
                {
                    object? val = col.GetValue(r);
                    int len = val?.ToString()?.Length ?? 4; // 4 for "null"
                    if (len > maxWidth) maxWidth = len;
                }

                // Limit to a reasonable max (e.g., 50 characters) to prevent console overflow
                widths[c] = Math.Min(maxWidth, 50) + 2; // +2 Padding
            }

            // 2. Print Header (Names)
            for (int c = 0; c < ColumnCount; c++)
            {
                sb.Append(_columns[c].Name.PadRight(widths[c]));
            }
            sb.AppendLine();

            // 3. Print Header (Types)
            for (int c = 0; c < ColumnCount; c++)
            {
                string typeStr = $"<{_columns[c].DataType.Name}>";
                sb.Append(typeStr.PadRight(widths[c]));
            }
            sb.AppendLine();

            // Separator line based on total width
            int totalWidth = widths.Sum();
            sb.AppendLine(new string('-', totalWidth));

            // 4. Print Rows
            for (int r = 0; r < rowsToShow; r++)
            {
                for (int c = 0; c < ColumnCount; c++)
                {
                    object? val = _columns[c].GetValue(r);
                    string valStr = val is null ? "null" : val.ToString() ?? "";

                    // Truncate if too long (Visual Safety)
                    if (valStr.Length > widths[c] - 1)
                        valStr = valStr.Substring(0, widths[c] - 4) + "...";

                    sb.Append(valStr.PadRight(widths[c]));
                }
                sb.AppendLine();
            }

            // 5. Footer hint
            if (RowCount > limit)
            {
                sb.AppendLine(new string('-', 20));
                sb.AppendLine($"... ({RowCount - limit} more rows)");
            }

            return sb.ToString();
        }

        private readonly List<IColumn> _columns;
        private bool _isDisposed;

        /// <summary>
        /// Gets the schema definition of this DataFrame.
        /// </summary>
        public DataFrameSchema Schema { get; }

        /// <summary>
        /// Gets the internal list of columns.
        /// </summary>
        public IReadOnlyList<IColumn> Columns => _columns;

        /// <summary>
        /// Gets the number of rows in the DataFrame.
        /// </summary>
        public int RowCount => _columns.Count > 0 ? _columns[0].Length : 0;

        /// <summary>
        /// Gets the number of columns in the DataFrame.
        /// </summary>
        public int ColumnCount => _columns.Count;

        /// <summary>
        /// Creates a new DataFrame from the provided columns.
        /// Validates that all columns share the same length.
        /// </summary>
        public DataFrame(IEnumerable<IColumn> columns)
        {
            if (columns == null) throw new ArgumentNullException(nameof(columns));

            _columns = columns.ToList();

            // 1. Validation: Row Count Consistency
            if (_columns.Count > 0)
            {
                int expectedLength = _columns[0].Length;
                for (int i = 1; i < _columns.Count; i++)
                {
                    if (_columns[i].Length != expectedLength)
                    {
                        throw new ArgumentException(
                            $"Column length mismatch. Column '{_columns[i].Name}' has length {_columns[i].Length}, " +
                            $"but expected {expectedLength} (from '{_columns[0].Name}').");
                    }
                }
            }

            // 2. Build Schema automatically from column metadata
            var definitions = _columns.Select(c => new ColumnDefinition(c.Name, c.DataType, c.IsNullable));
            Schema = new DataFrameSchema(definitions);
        }

        /// <summary>
        /// Gets the column at the specified index.
        /// </summary>
        public IColumn this[int index] => _columns[index];

        /// <summary>
        /// Gets the column with the specified name.
        /// Throws <see cref="ArgumentException"/> if the column does not exist.
        /// </summary>
        public IColumn this[string name]
        {
            get
            {
                // Schema lookup handles the exception if name is missing
                int index = Schema.GetColumnIndex(name);
                return _columns[index];
            }
        }

        /// <summary>
        /// Tries to get the column with the specified name.
        /// Returns true if found, otherwise false.
        /// </summary>
        public bool TryGetColumn(string name, out IColumn? column)
        {
            if (Schema.HasColumn(name))
            {
                int index = Schema.GetColumnIndex(name);
                column = _columns[index];
                return true;
            }

            column = null;
            return false;
        }

        /// <summary>
        /// Creates a DataFrame from a collection of objects (POCOs) using Reflection.
        /// The schema is automatically generated from the public properties of <typeparamref name="T"/>.
        /// </summary>
        /// <typeparam name="T">The type of the objects, determining the schema.</typeparam>
        /// <param name="objects">The collection of objects to load.</param>
        /// <returns>A populated DataFrame containing the data from the objects.</returns>
        public static DataFrame FromObjects<T>(IEnumerable<T> objects)
        {
            if (objects == null) throw new ArgumentNullException(nameof(objects));

            // 1. Get Schema via centralized logic
            var schema = DataFrameSchema.FromType<T>();

            // 2. Prepare for data population
            int estimatedCount = objects is ICollection<T> coll ? coll.Count : 16;
            var df = DataFrame.Create(schema, estimatedCount);

            // Cache PropertyInfos for speed
            var type = typeof(T);
            var propMap = new Dictionary<string, PropertyInfo>();
            foreach (var col in df.Columns)
            {
                propMap[col.Name] = type.GetProperty(col.Name)!;
            }

            // 3. Populate Data
            foreach (var item in objects)
            {
                foreach (var col in df.Columns)
                {
                    var prop = propMap[col.Name];
                    object? val = prop.GetValue(item);
                    col.AppendObject(val);
                }
            }

            return df;
        }

        /// <summary>
        /// Disposes all contained columns, returning their memory to the pool.
        /// </summary>
        public void Dispose()
        {
            Dispose(true);
            GC.SuppressFinalize(this);
        }


        /// <summary>
        /// Releases unmanaged and - optionally - managed resources.
        /// </summary>
        /// <param name="disposing"><c>true</c> to release both managed and unmanaged resources; <c>false</c> to release only unmanaged resources.</param>
        protected virtual void Dispose(bool disposing)
        {
            if (_isDisposed) return;

            if (disposing)
            {
                foreach (var col in _columns)
                {
                    // Check if the column implements IDisposable (our concrete columns do)
                    if (col is IDisposable disposableCol)
                    {
                        disposableCol.Dispose();
                    }
                }
            }
            _isDisposed = true;
        }

        /// <summary>
        /// Checks if a column with the given name exists in the DataFrame.
        /// </summary>
        public bool HasColumn(string name)
        {
            if (string.IsNullOrEmpty(name)) return false;
            return Schema.HasColumn(name);
        }

        /// <summary>
        /// Returns the names of all columns in the DataFrame.
        /// </summary>
        public IEnumerable<string> GetColumnNames()
        {
            return _columns.Select(c => c.Name);
        }

        /// <summary>
        /// Returns the .NET Type of the data stored in the specified column.
        /// Throws ArgumentException if the column does not exist.
        /// </summary>
        public Type GetColumnType(string name)
        {
            // We use the existing indexer, which already handles validation/exception
            return this[name].DataType;
        }
    }
}
===== FILE: src/LeichtFrame.Core/DataFrame/DataFrameSchema.cs =====
using System.Text.Json;

namespace LeichtFrame.Core;

/// <summary>
/// Defines the metadata for a single column within a DataFrame schema.
/// </summary>
/// <param name="Name">The unique name of the column.</param>
/// <param name="DataType">The CLR type of the data stored in the column.</param>
/// <param name="IsNullable">Indicates if the column supports null values.</param>
public record ColumnDefinition(string Name, Type DataType, bool IsNullable = false);

/// <summary>
/// Represents the structure of a DataFrame, consisting of a collection of column definitions.
/// Provides lookup methods for column indices and types.
/// </summary>
public class DataFrameSchema
{
    private readonly List<ColumnDefinition> _columns;
    private readonly Dictionary<string, int> _nameMap;

    /// <summary>
    /// Gets the list of column definitions in this schema.
    /// </summary>
    public IReadOnlyList<ColumnDefinition> Columns => _columns;

    /// <summary>
    /// Initializes a new instance of the <see cref="DataFrameSchema"/> class.
    /// </summary>
    /// <param name="columns">The collection of column definitions.</param>
    /// <exception cref="ArgumentNullException">Thrown if columns is null.</exception>
    /// <exception cref="ArgumentException">Thrown if duplicate column names are detected.</exception>
    public DataFrameSchema(IEnumerable<ColumnDefinition> columns)
    {
        _columns = columns?.ToList() ?? throw new ArgumentNullException(nameof(columns));
        _nameMap = new Dictionary<string, int>();

        // Build lookup dictionary for fast access
        for (int i = 0; i < _columns.Count; i++)
        {
            var col = _columns[i];
            if (_nameMap.ContainsKey(col.Name))
                throw new ArgumentException($"Duplicate column name '{col.Name}' is not allowed.");

            _nameMap[col.Name] = i;
        }
    }

    /// <summary>
    /// Checks if a column with the given name exists in the schema.
    /// </summary>
    /// <param name="name">The name of the column to check.</param>
    /// <returns><c>true</c> if the column exists; otherwise, <c>false</c>.</returns>
    public bool HasColumn(string name) => _nameMap.ContainsKey(name);

    /// <summary>
    /// Gets the zero-based index of the column with the specified name.
    /// </summary>
    /// <param name="name">The name of the column.</param>
    /// <returns>The index of the column.</returns>
    /// <exception cref="ArgumentException">Thrown if the column does not exist.</exception>
    public int GetColumnIndex(string name)
    {
        if (_nameMap.TryGetValue(name, out int index))
            return index;

        throw new ArgumentException($"Column '{name}' does not exist in the schema.");
    }

    // --- JSON Serialization Logic ---

    /// <summary>
    /// Serializes the schema to a JSON string representation.
    /// Useful for persisting metadata or transferring schemas between processes.
    /// </summary>
    /// <returns>A JSON string defining the schema.</returns>
    public string ToJson()
    {
        // Convert to DTO because System.Type implies security risks and complexity in raw JSON. We store the Type Name as a string.
        var dto = new SchemaDto
        {
            Columns = _columns.Select(c => new ColumnDto
            {
                Name = c.Name,
                DataTypeName = c.DataType.AssemblyQualifiedName ?? c.DataType.FullName ?? c.DataType.Name,
                IsNullable = c.IsNullable
            }).ToList()
        };

        return JsonSerializer.Serialize(dto, new JsonSerializerOptions { WriteIndented = true });
    }

    /// <summary>
    /// Creates a <see cref="DataFrameSchema"/> from a JSON string.
    /// </summary>
    /// <param name="json">The JSON string containing the schema definition.</param>
    /// <returns>The deserialized schema.</returns>
    /// <exception cref="ArgumentException">Thrown if the JSON is invalid.</exception>
    public static DataFrameSchema FromJson(string json)
    {
        var dto = JsonSerializer.Deserialize<SchemaDto>(json);
        if (dto == null || dto.Columns == null)
            throw new ArgumentException("Invalid JSON schema.");

        var definitions = dto.Columns.Select(c => new ColumnDefinition(
            c.Name,
            Type.GetType(c.DataTypeName) ?? throw new InvalidOperationException($"Type '{c.DataTypeName}' not found."),
            c.IsNullable
        ));

        return new DataFrameSchema(definitions);
    }

    /// <summary>
    /// Helper to get the <see cref="Type"/> of a column by name.
    /// </summary>
    /// <param name="name">The column name.</param>
    /// <returns>The data type of the column.</returns>
    /// <exception cref="ArgumentException">Thrown if the column does not exist.</exception>
    public Type GetColumnType(string name)
    {
        int index = GetColumnIndex(name); // Wirft Fehler, wenn nicht gefunden
        return _columns[index].DataType;
    }

    // --- Private Helper Classes for JSON ---
    private class SchemaDto
    {
        public List<ColumnDto> Columns { get; set; } = new();
    }

    private class ColumnDto
    {
        public string Name { get; set; } = string.Empty;
        public string DataTypeName { get; set; } = string.Empty;
        public bool IsNullable { get; set; }
    }

    /// <summary>
    /// Creates a schema definition automatically from a C# class (POCO) using Reflection.
    /// Only supported primitive types (int, double, bool, string, DateTime) are mapped.
    /// </summary>
    /// <typeparam name="T">The POCO type to analyze.</typeparam>
    /// <returns>A derived <see cref="DataFrameSchema"/>.</returns>
    /// <exception cref="ArgumentException">Thrown if the type has no supported public properties.</exception>
    public static DataFrameSchema FromType<T>()
    {
        var properties = typeof(T).GetProperties(System.Reflection.BindingFlags.Public | System.Reflection.BindingFlags.Instance);
        var colDefs = new List<ColumnDefinition>();

        foreach (var prop in properties)
        {
            Type type = prop.PropertyType;
            // Unbox Nullable<T> -> T
            Type coreType = Nullable.GetUnderlyingType(type) ?? type;
            bool isNullable = !type.IsValueType || Nullable.GetUnderlyingType(type) != null;

            // Supported Types Check
            if (coreType != typeof(int) && coreType != typeof(double) &&
                coreType != typeof(string) && coreType != typeof(bool) &&
                coreType != typeof(DateTime))
            {
                continue; // Skip unsupported types
            }

            colDefs.Add(new ColumnDefinition(prop.Name, coreType, isNullable));
        }

        if (colDefs.Count == 0)
            throw new ArgumentException($"Type '{typeof(T).Name}' has no supported public properties.");

        return new DataFrameSchema(colDefs);
    }
}
===== FILE: src/LeichtFrame.Core/DataFrame/GroupedDataFrame.cs =====
namespace LeichtFrame.Core
{
    /// <summary>
    /// Represents an intermediate state of a DataFrame grouped by a specific column.
    /// Used to perform aggregated calculations per group.
    /// </summary>
    public abstract class GroupedDataFrame
    {
        /// <summary>
        /// The original DataFrame.
        /// </summary>
        public DataFrame Source { get; }
        /// <summary>
        /// The name of the column used for grouping.
        /// </summary>
        public string GroupColumnName { get; }
        /// <summary>
        /// Initializes a new instance of the <see cref="GroupedDataFrame"/> class.
        /// </summary>
        protected GroupedDataFrame(DataFrame source, string groupColName)
        {
            Source = source;
            GroupColumnName = groupColName;
        }

        // Internal accessors for aggregation logic
        internal abstract int GroupCount { get; }
        internal abstract Array GetKeys();
        internal abstract int[] GroupOffsets { get; }
        internal abstract int[] RowIndices { get; }
    }

    /// <summary>
    /// High-performance typed grouping result (CSR format).
    /// </summary>
    internal class GroupedDataFrame<TKey> : GroupedDataFrame
    {
        private readonly TKey[] _keys;
        private readonly int[] _offsets;
        private readonly int[] _indices;

        public GroupedDataFrame(DataFrame source, string groupColName, TKey[] keys, int[] offsets, int[] indices)
            : base(source, groupColName)
        {
            _keys = keys;
            _offsets = offsets;
            _indices = indices;
        }

        internal override int GroupCount => _keys.Length;
        internal override Array GetKeys() => _keys;
        internal override int[] GroupOffsets => _offsets;
        internal override int[] RowIndices => _indices;
    }
}
===== FILE: src/LeichtFrame.Core/DataFrame/Operations/AggregationOps.cs =====
namespace LeichtFrame.Core
{
    /// <summary>
    /// Provides extension methods for calculating aggregations (Sum, Min, Max, Mean) on DataFrames.
    /// </summary>
    public static class DataFrameAggregationExtensions
    {
        /// <summary>
        /// Calculates the Sum of a numeric column.
        /// </summary>
        /// <param name="df">The source DataFrame.</param>
        /// <param name="columnName">The name of the column.</param>
        /// <returns>The sum of all values.</returns>
        public static double Sum(this DataFrame df, string columnName)
        {
            var col = df[columnName];

            if (col is DoubleColumn doubleCol) return doubleCol.Sum();
            if (col is IntColumn intCol) return (double)intCol.Sum();

            throw new NotSupportedException($"Sum operation is not supported for column type '{col.DataType.Name}'.");
        }

        /// <summary>
        /// Calculates the Minimum value of a numeric column.
        /// </summary>
        /// <param name="df">The source DataFrame.</param>
        /// <param name="columnName">The name of the column.</param>
        /// <returns>The minimum value.</returns>
        public static double Min(this DataFrame df, string columnName)
        {
            var col = df[columnName];

            if (col is DoubleColumn doubleCol) return doubleCol.Min();
            if (col is IntColumn intCol) return (double)intCol.Min();

            throw new NotSupportedException($"Min operation is not supported for column type '{col.DataType.Name}'.");
        }

        /// <summary>
        /// Calculates the Maximum value of a numeric column.
        /// </summary>
        /// <param name="df">The source DataFrame.</param>
        /// <param name="columnName">The name of the column.</param>
        /// <returns>The maximum value.</returns>
        public static double Max(this DataFrame df, string columnName)
        {
            var col = df[columnName];

            if (col is DoubleColumn doubleCol) return doubleCol.Max();
            if (col is IntColumn intCol) return (double)intCol.Max();

            throw new NotSupportedException($"Max operation is not supported for column type '{col.DataType.Name}'.");
        }

        /// <summary>
        /// Calculates the arithmetic Mean (Average) of a numeric column.
        /// </summary>
        /// <param name="df">The source DataFrame.</param>
        /// <param name="columnName">The name of the column.</param>
        /// <returns>The mean value.</returns>
        public static double Mean(this DataFrame df, string columnName)
        {
            var col = df[columnName];
            double sum = df.Sum(columnName);
            int count = 0;

            if (col.IsNullable)
            {
                // Simple loop to count non-nulls.
                for (int i = 0; i < col.Length; i++)
                    if (!col.IsNull(i)) count++;
            }
            else
            {
                count = col.Length;
            }

            if (count == 0) return 0;
            return sum / count;
        }
    }

    /// <summary>
    /// Provides extension methods for performing aggregations on grouped dataframes.
    /// Optimized for high performance (Zero-Allocation per group).
    /// </summary>
    public static class GroupAggregationExtensions
    {
        /// <summary>
        /// Aggregates the grouped data by counting rows in each group.
        /// Returns a new DataFrame with columns: [GroupColumn, "Count"].
        /// </summary>
        /// <param name="gdf">The grouped dataframe.</param>
        /// <returns>A new dataframe containing the group keys and their counts.</returns>
        public static DataFrame Count(this GroupedDataFrame gdf)
        {
            // For Count, the value column doesn't matter, we can pass the key column as a placeholder.
            var keyCol = gdf.Source[gdf.GroupColumnName];
            return ExecuteAggregation(gdf, keyCol, "Count", (indices, _) => indices.Count);
        }

        /// <summary>
        /// Aggregates the grouped data by summing values in the specified column.
        /// Returns a new DataFrame with columns: [GroupColumn, "Sum_TargetColumn"].
        /// </summary>
        /// <param name="gdf">The grouped dataframe.</param>
        /// <param name="aggregateColumnName">The column to sum up per group.</param>
        /// <returns>A new dataframe containing the group keys and the sums.</returns>
        public static DataFrame Sum(this GroupedDataFrame gdf, string aggregateColumnName)
        {
            return ExecuteNumericAggregation(gdf, aggregateColumnName, "Sum",
                (indices, col) =>
                {
                    long sum = 0;
                    foreach (var i in indices)
                    {
                        if (!col.IsNull(i)) sum += col.Get(i);
                    }
                    return sum;
                },
                (indices, col) =>
                {
                    double sum = 0;
                    foreach (var i in indices)
                    {
                        if (!col.IsNull(i)) sum += col.Get(i);
                    }
                    return sum;
                }
            );
        }

        /// <summary>
        /// Aggregates the grouped data by finding the minimum value in the specified column.
        /// Returns a new DataFrame with columns: [GroupColumn, "Min_TargetColumn"].
        /// </summary>
        /// <param name="gdf">The grouped dataframe.</param>
        /// <param name="aggregateColumnName">The target column.</param>
        /// <returns>A new dataframe containing the group keys and the minimums.</returns>
        public static DataFrame Min(this GroupedDataFrame gdf, string aggregateColumnName)
        {
            return ExecuteNumericAggregation(gdf, aggregateColumnName, "Min",
                (indices, col) =>
                {
                    if (indices.Count == 0) return 0;
                    int min = int.MaxValue;
                    bool hasVal = false;
                    foreach (var i in indices)
                    {
                        if (!col.IsNull(i))
                        {
                            int v = col.Get(i);
                            if (v < min) min = v;
                            hasVal = true;
                        }
                    }
                    return hasVal ? min : 0;
                },
                (indices, col) =>
                {
                    if (indices.Count == 0) return 0;
                    double min = double.MaxValue;
                    bool hasVal = false;
                    foreach (var i in indices)
                    {
                        if (!col.IsNull(i))
                        {
                            double v = col.Get(i);
                            if (v < min) min = v;
                            hasVal = true;
                        }
                    }
                    return hasVal ? min : 0;
                }
            );
        }

        /// <summary>
        /// Aggregates the grouped data by finding the maximum value in the specified column.
        /// Returns a new DataFrame with columns: [GroupColumn, "Max_TargetColumn"].
        /// </summary>
        /// <param name="gdf">The grouped dataframe.</param>
        /// <param name="aggregateColumnName">The target column.</param>
        /// <returns>A new dataframe containing the group keys and the maximums.</returns>
        public static DataFrame Max(this GroupedDataFrame gdf, string aggregateColumnName)
        {
            return ExecuteNumericAggregation(gdf, aggregateColumnName, "Max",
                (indices, col) =>
                {
                    if (indices.Count == 0) return 0;
                    int max = int.MinValue;
                    bool hasVal = false;
                    foreach (var i in indices)
                    {
                        if (!col.IsNull(i))
                        {
                            int v = col.Get(i);
                            if (v > max) max = v;
                            hasVal = true;
                        }
                    }
                    return hasVal ? max : 0;
                },
                (indices, col) =>
                {
                    if (indices.Count == 0) return 0;
                    double max = double.MinValue;
                    bool hasVal = false;
                    foreach (var i in indices)
                    {
                        if (!col.IsNull(i))
                        {
                            double v = col.Get(i);
                            if (v > max) max = v;
                            hasVal = true;
                        }
                    }
                    return hasVal ? max : 0;
                }
            );
        }

        /// <summary>
        /// Aggregates the grouped data by calculating the mean value in the specified column.
        /// Returns a new DataFrame with columns: [GroupColumn, "Mean_TargetColumn"].
        /// </summary>
        /// <param name="gdf">The grouped dataframe.</param>
        /// <param name="aggregateColumnName">The target column.</param>
        /// <returns>A new dataframe containing the group keys and the means.</returns>
        public static DataFrame Mean(this GroupedDataFrame gdf, string aggregateColumnName)
        {
            return ExecuteNumericAggregation(gdf, aggregateColumnName, "Mean",
                (indices, col) =>
                {
                    long sum = 0;
                    int count = 0;
                    foreach (var i in indices)
                    {
                        if (!col.IsNull(i))
                        {
                            sum += col.Get(i);
                            count++;
                        }
                    }
                    return count == 0 ? 0 : (double)sum / count;
                },
                (indices, col) =>
                {
                    double sum = 0;
                    int count = 0;
                    foreach (var i in indices)
                    {
                        if (!col.IsNull(i))
                        {
                            sum += col.Get(i);
                            count++;
                        }
                    }
                    return count == 0 ? 0 : sum / count;
                }
            );
        }

        // --- Private Helpers ---

        private delegate double TypedAggregator<TColumn>(List<int> indices, TColumn col);

        private static DataFrame ExecuteNumericAggregation(
            GroupedDataFrame gdf,
            string inputColName,
            string operationPrefix,
            TypedAggregator<IntColumn> intOp,
            TypedAggregator<DoubleColumn> doubleOp)
        {
            // Resolve the actual value column (e.g. "Salary")
            var valueCol = gdf.Source[inputColName];

            Func<List<int>, IColumn, double> calculator;

            if (valueCol is IntColumn)
            {
                calculator = (indices, col) => intOp(indices, (IntColumn)col);
            }
            else if (valueCol is DoubleColumn)
            {
                calculator = (indices, col) => doubleOp(indices, (DoubleColumn)col);
            }
            else
            {
                throw new NotSupportedException($"Operation {operationPrefix} not supported for type {valueCol.DataType.Name}");
            }

            // Important: Pass 'valueCol' down to ExecuteAggregation
            return ExecuteAggregation(gdf, valueCol, $"{operationPrefix}_{inputColName}", calculator);
        }

        private static DataFrame ExecuteAggregation(
            GroupedDataFrame gdf,
            IColumn valueCol,
            string resultColName,
            Func<List<int>, IColumn, double> aggFunc)
        {
            var sourceKeyCol = gdf.Source[gdf.GroupColumnName];
            var keyCol = ColumnFactory.Create(gdf.GroupColumnName, sourceKeyCol.DataType, gdf.GroupMap.Count, sourceKeyCol.IsNullable);

            IColumn resultCol;
            if (resultColName == "Count")
                resultCol = new IntColumn(resultColName, gdf.GroupMap.Count);
            else
                resultCol = new DoubleColumn(resultColName, gdf.GroupMap.Count);

            foreach (var kvp in gdf.GroupMap)
            {
                object? realKey = DataFrameGroupingExtensions.GetRealValue(kvp.Key);
                keyCol.AppendObject(realKey);

                // Pass the correct value column (not the key column) to the calculator
                double val = aggFunc(kvp.Value, valueCol);

                resultCol.AppendObject(val);
            }

            return new DataFrame(new[] { keyCol, resultCol });
        }
    }
}
===== FILE: src/LeichtFrame.Core/DataFrame/Operations/CleaningOps.cs =====
namespace LeichtFrame.Core
{
    /// <summary>
    /// Provides extension methods for cleaning data (handling nulls).
    /// </summary>
    public static class CleaningOps
    {
        /// <summary>
        /// Removes all rows that contain at least one null value in any column.
        /// </summary>
        /// <param name="df">The source DataFrame.</param>
        /// <returns>A new DataFrame with only complete rows.</returns>
        public static DataFrame DropNulls(this DataFrame df)
        {
            // 1. Identify columns that are actually nullable (Optimization)
            var nullableCols = new List<IColumn>();
            foreach (var col in df.Columns)
            {
                if (col.IsNullable) nullableCols.Add(col);
            }

            // If no columns are nullable, return the original (or a clone if we want strict immutability semantics? 
            // Usually DropNulls implies "if nothing dropped, return self" is acceptable for performance).
            if (nullableCols.Count == 0) return df; // Zero-Copy optimization

            var indices = new List<int>(df.RowCount);

            // 2. Scan rows
            for (int i = 0; i < df.RowCount; i++)
            {
                bool hasNull = false;
                // Only check nullable columns
                for (int c = 0; c < nullableCols.Count; c++)
                {
                    if (nullableCols[c].IsNull(i))
                    {
                        hasNull = true;
                        break;
                    }
                }

                if (!hasNull)
                {
                    indices.Add(i);
                }
            }

            // 3. Create Subset
            // If we kept all rows, return original
            if (indices.Count == df.RowCount) return df;

            var newColumns = new List<IColumn>(df.ColumnCount);
            foreach (var col in df.Columns)
            {
                newColumns.Add(col.CloneSubset(indices));
            }

            return new DataFrame(newColumns);
        }

        /// <summary>
        /// Replaces null values in the specified column with a constant value.
        /// </summary>
        /// <typeparam name="T">The type of the column data.</typeparam>
        /// <param name="df">The source DataFrame.</param>
        /// <param name="columnName">The name of the column to fill.</param>
        /// <param name="value">The value to replace nulls with.</param>
        /// <returns>A new DataFrame with the filled column.</returns>
        public static DataFrame FillNull<T>(this DataFrame df, string columnName, T value)
        {
            var targetCol = df[columnName];

            // If column is not nullable, nothing to do (return self logic, but we need to reconstruct DF to be safe?)
            // Let's assume we modify the specific column in the new DF.
            if (!targetCol.IsNullable) return df;

            // 1. Create a deep copy of the target column but WITHOUT NullBitmap support (IsNullable = false)
            // Strategy: We create a new column, copy all values manually, replacing nulls on the fly.

            // Note: We cannot easily "Deep Copy" an IColumn via Interface.
            // We use ColumnFactory to create a fresh one.
            var newCol = ColumnFactory.Create<T>(columnName, df.RowCount, isNullable: false);

            if (targetCol is IColumn<T> typedSource)
            {
                for (int i = 0; i < df.RowCount; i++)
                {
                    if (typedSource.IsNull(i))
                    {
                        newCol.Append(value);
                    }
                    else
                    {
                        newCol.Append(typedSource.GetValue(i));
                    }
                }
            }
            else
            {
                throw new ArgumentException($"Column '{columnName}' is not of type {typeof(T).Name}");
            }

            // 2. Build new DataFrame
            var newColumns = new List<IColumn>(df.ColumnCount);
            foreach (var col in df.Columns)
            {
                if (col.Name == columnName)
                {
                    newColumns.Add(newCol);
                }
                else
                {
                    // Zero-Copy for other columns
                    newColumns.Add(col);
                }
            }

            return new DataFrame(newColumns);
        }
    }
}
===== FILE: src/LeichtFrame.Core/DataFrame/Operations/DeduplicationOps.cs =====
namespace LeichtFrame.Core
{
    /// <summary>
    /// Provides extension methods for removing duplicate rows.
    /// </summary>
    public static class DeduplicationOps
    {
        /// <summary>
        /// Returns a new DataFrame containing only unique rows.
        /// </summary>
        public static DataFrame Distinct(this DataFrame df)
        {
            return Distinct(df, df.GetColumnNames().ToArray());
        }

        /// <summary>
        /// Returns a new DataFrame containing rows that are unique based on the specified subset of columns.
        /// </summary>
        public static DataFrame Distinct(this DataFrame df, params string[] columnNames)
        {
            if (columnNames == null || columnNames.Length == 0)
                throw new ArgumentException("At least one column must be specified.");

            // Optimization: Single Column Distinct
            // We can use a typed HashSet<T> to avoid boxing/allocations
            if (columnNames.Length == 1)
            {
                return DistinctSingleColumn(df, columnNames[0]);
            }

            // Fallback: Multi-column slow path
            return DistinctMultiColumn(df, columnNames);
        }

        private static DataFrame DistinctSingleColumn(DataFrame df, string columnName)
        {
            var col = df[columnName];
            Type type = col.DataType;
            Type coreType = Nullable.GetUnderlyingType(type) ?? type;

            if (coreType == typeof(int)) return ExecuteDistinctSingle<int>(df, col);
            if (coreType == typeof(double)) return ExecuteDistinctSingle<double>(df, col);
            if (coreType == typeof(string)) return ExecuteDistinctSingle<string>(df, col);
            if (coreType == typeof(bool)) return ExecuteDistinctSingle<bool>(df, col);
            if (coreType == typeof(DateTime)) return ExecuteDistinctSingle<DateTime>(df, col);

            return ExecuteDistinctSingle<object>(df, col);
        }

        private static DataFrame ExecuteDistinctSingle<T>(DataFrame df, IColumn colUntyped) where T : notnull
        {
            var col = (IColumn<T>)colUntyped;
            var seen = new HashSet<T>();
            var indices = new List<int>(df.RowCount);
            bool nullSeen = false;

            for (int i = 0; i < df.RowCount; i++)
            {
                if (col.IsNull(i))
                {
                    if (!nullSeen)
                    {
                        nullSeen = true;
                        indices.Add(i);
                    }
                    continue;
                }

                T val = col.GetValue(i);

                // HashSet.Add returns true if the element was added (new unique)
                if (val != null && seen.Add(val))
                {
                    indices.Add(i);
                }
                else if (val == null && !nullSeen) // Handle nulls in reference types (strings)
                {
                    nullSeen = true;
                    indices.Add(i);
                }
            }

            return CreateSubset(df, indices);
        }

        private static DataFrame DistinctMultiColumn(DataFrame df, string[] columnNames)
        {
            var colsToCheck = new IColumn[columnNames.Length];
            for (int i = 0; i < columnNames.Length; i++)
            {
                colsToCheck[i] = df[columnNames[i]];
            }

            var comparer = new RowIndexComparer(colsToCheck);
            var seenRows = new HashSet<int>(comparer);
            var uniqueIndices = new List<int>(df.RowCount);

            for (int i = 0; i < df.RowCount; i++)
            {
                if (seenRows.Add(i))
                {
                    uniqueIndices.Add(i);
                }
            }

            return CreateSubset(df, uniqueIndices);
        }

        private static DataFrame CreateSubset(DataFrame df, List<int> indices)
        {
            if (indices.Count == df.RowCount) return df;

            var newColumns = new List<IColumn>(df.ColumnCount);
            foreach (var col in df.Columns)
            {
                newColumns.Add(col.CloneSubset(indices));
            }
            return new DataFrame(newColumns);
        }

        private class RowIndexComparer : IEqualityComparer<int>
        {
            private readonly IColumn[] _columns;

            public RowIndexComparer(IColumn[] columns)
            {
                _columns = columns;
            }

            public bool Equals(int x, int y)
            {
                for (int c = 0; c < _columns.Length; c++)
                {
                    var col = _columns[c];
                    object? valX = col.GetValue(x);
                    object? valY = col.GetValue(y);
                    if (!object.Equals(valX, valY)) return false;
                }
                return true;
            }

            public int GetHashCode(int obj)
            {
                var hash = new HashCode();
                for (int c = 0; c < _columns.Length; c++)
                {
                    hash.Add(_columns[c].GetValue(obj));
                }
                return hash.ToHashCode();
            }
        }
    }
}
===== FILE: src/LeichtFrame.Core/DataFrame/Operations/FilterOps.cs =====
namespace LeichtFrame.Core
{
    /// <summary>
    /// Provides extension methods for filtering <see cref="DataFrame"/> rows based on predicates.
    /// </summary>
    public static class DataFrameFilterExtensions
    {
        /// <summary>
        /// Filters rows based on a predicate function.
        /// Creates a new <see cref="DataFrame"/> with COPIED data containing only the matching rows.
        /// </summary>
        /// <param name="df">The source DataFrame.</param>
        /// <param name="predicate">A function to test each row. Return <c>true</c> to keep the row, <c>false</c> to drop it.</param>
        /// <returns>A new DataFrame containing only the rows that satisfy the condition.</returns>
        /// <exception cref="ArgumentNullException">Thrown if <paramref name="predicate"/> is null.</exception>
        public static DataFrame Where(this DataFrame df, Func<RowView, bool> predicate)
        {
            if (predicate == null) throw new ArgumentNullException(nameof(predicate));

            // 1. Phase: Scan (Collect indices)
            // We use a capacity estimate to minimize resizing of the list
            var indices = new List<int>(df.RowCount / 2);

            // RowView is a struct (stack-only), so very cheap to create
            for (int i = 0; i < df.RowCount; i++)
            {
                var row = new RowView(i, df.Columns, df.Schema);
                if (predicate(row))
                {
                    indices.Add(i);
                }
            }

            // 2. Phase: Copy (Column-wise)
            var newColumns = new List<IColumn>(df.ColumnCount);
            foreach (var col in df.Columns)
            {
                // Each column takes care of efficiently copying the indices
                newColumns.Add(col.CloneSubset(indices));
            }

            return new DataFrame(newColumns);
        }

        /// <summary>
        /// Filters rows based on a predicate, returning a Zero-Copy View (<see cref="IndirectColumn{T}"/>).
        /// <para>
        /// **Performance:** Extremely fast creation (O(N) scan, 0 allocation for data). 
        /// **Trade-off:** Subsequent read access is slower due to indirection, and Vectorized operations (SIMD) 
        /// are not supported on the result until it is materialized.
        /// </para>
        /// </summary>
        public static DataFrame WhereView(this DataFrame df, Func<RowView, bool> predicate)
        {
            if (predicate == null) throw new ArgumentNullException(nameof(predicate));

            // 1. Scan (Collect indices)
            var indicesList = new List<int>(df.RowCount / 4); // Heuristic
            for (int i = 0; i < df.RowCount; i++)
            {
                var row = new RowView(i, df.Columns, df.Schema);
                if (predicate(row))
                {
                    indicesList.Add(i);
                }
            }
            int[] indicesArray = indicesList.ToArray();

            // 2. Create Views
            var newColumns = new List<IColumn>(df.ColumnCount);
            foreach (var col in df.Columns)
            {
                // Create IndirectColumn via Reflection (Generic Factory)
                var genericType = typeof(IndirectColumn<>).MakeGenericType(col.DataType);
                var view = Activator.CreateInstance(genericType, col, indicesArray);
                newColumns.Add((IColumn)view!);
            }

            return new DataFrame(newColumns);
        }
    }
}
===== FILE: src/LeichtFrame.Core/DataFrame/Operations/GroupingOps.cs =====
using System.Collections.Concurrent;
using System.Runtime.CompilerServices;
using LeichtFrame.Core.Internal;

namespace LeichtFrame.Core
{
    /// <summary>
    /// Provides extension methods for grouping operations on <see cref="DataFrame"/>.
    /// Optimized using generic type dispatching, custom hash maps, and striped parallelism.
    /// </summary>
    public static class DataFrameGroupingExtensions
    {
        private static readonly object NullKey = new object();

        // Thresholds
        private const int ParallelThreshold = 100_000;
        private const int PartitionCount = 1024; // Power of 2 for fast modulo

        /// <summary>
        /// Groups the rows of the DataFrame by the values in the specified column.
        /// Automatically selects between highly optimized primitive grouping (single-threaded) 
        /// and partitioned parallel execution based on data type and row count.
        /// </summary>
        /// <param name="df">The source DataFrame.</param>
        /// <param name="columnName">The name of the column to group by.</param>
        /// <returns>A <see cref="GroupedDataFrame"/> object used to apply aggregations.</returns>
        /// <exception cref="ArgumentNullException">Thrown if columnName is null or empty.</exception>
        public static GroupedDataFrame GroupBy(this DataFrame df, string columnName)
        {
            if (string.IsNullOrEmpty(columnName)) throw new ArgumentNullException(nameof(columnName));

            var col = df[columnName];
            Type t = Nullable.GetUnderlyingType(col.DataType) ?? col.DataType;

            // 1. Primitive Optimized Path
            if (t == typeof(int)) return DispatchPrimitive<int>(df, columnName);
            if (t == typeof(double)) return DispatchPrimitive<double>(df, columnName);
            if (t == typeof(long)) return DispatchPrimitive<long>(df, columnName);
            if (t == typeof(bool)) return DispatchPrimitive<bool>(df, columnName);
            if (t == typeof(DateTime)) return DispatchPrimitive<DateTime>(df, columnName);

            // 2. String Optimized Path
            if (t == typeof(string)) return GroupByStringDispatch(df, columnName);

            // 3. Fallback
            return GroupBySequentialObject(df, columnName);
        }

        // --- DISPATCHERS ---

        private static GroupedDataFrame DispatchPrimitive<T>(DataFrame df, string columnName)
            where T : unmanaged, IEquatable<T>
        {
            if (df.RowCount >= ParallelThreshold)
                return GroupByPrimitiveParallel<T>(df, columnName);

            return GroupByPrimitiveSequential<T>(df, columnName);
        }

        private static GroupedDataFrame GroupByStringDispatch(DataFrame df, string columnName)
        {
            if (df.RowCount >= ParallelThreshold)
                return GroupByStringParallel(df, columnName);

            return GroupByStringSequential(df, columnName);
        }

        // ==========================================================================================
        // 1. PRIMITIVE IMPLEMENTATIONS (Int, Double, ...)
        // ==========================================================================================

        private static GroupedDataFrame GroupByPrimitiveSequential<T>(DataFrame df, string columnName)
            where T : unmanaged, IEquatable<T>
        {
            var col = (IColumn<T>)df[columnName];
            // Heuristic: Start smaller to save RAM, resize if needed
            int capacity = Math.Max(1024, df.RowCount / 10);

            var map = new PrimitiveKeyMap<T>(capacity, df.RowCount);
            var nullIndices = new List<int>();

            for (int i = 0; i < df.RowCount; i++)
            {
                if (col.IsNull(i)) { nullIndices.Add(i); continue; }
                map.AddRow(col.GetValue(i), i);
            }

            var result = FinalizeResult(df, columnName, map.ToDictionary(), nullIndices);
            map.Dispose();
            return result;
        }

        private static GroupedDataFrame GroupByPrimitiveParallel<T>(DataFrame df, string columnName)
            where T : unmanaged, IEquatable<T>
        {
            var col = (IColumn<T>)df[columnName];

            // "Striped Partitioning" using typed Dictionaries
            var partitionMaps = new Dictionary<T, List<int>>[PartitionCount];
            var partitionLocks = new object[PartitionCount];
            var globalNulls = new ConcurrentBag<int>();

            int initialCap = Math.Max(16, (df.RowCount / PartitionCount) / 2);

            for (int i = 0; i < PartitionCount; i++)
            {
                partitionMaps[i] = new Dictionary<T, List<int>>(initialCap);
                partitionLocks[i] = new object();
            }

            // Parallel Scan
            Parallel.ForEach(Partitioner.Create(0, df.RowCount), range =>
            {
                for (int i = range.Item1; i < range.Item2; i++)
                {
                    if (col.IsNull(i))
                    {
                        globalNulls.Add(i);
                        continue;
                    }

                    T val = col.GetValue(i);
                    // Fast Hash for Partition Selection
                    int pIdx = (val.GetHashCode() & 0x7FFFFFFF) % PartitionCount;

                    // Fine-Grained Locking
                    lock (partitionLocks[pIdx])
                    {
                        var map = partitionMaps[pIdx];
                        if (!map.TryGetValue(val, out var list))
                        {
                            list = new List<int>();
                            map[val] = list;
                        }
                        list.Add(i);
                    }
                }
            });

            // Merge partitions
            var finalResult = new Dictionary<object, List<int>>(df.RowCount / 10);

            foreach (var map in partitionMaps)
            {
                foreach (var kvp in map)
                {
                    finalResult.Add(kvp.Key, kvp.Value);
                }
            }

            if (!globalNulls.IsEmpty)
            {
                finalResult.Add(NullKey, globalNulls.ToList());
            }

            return new GroupedDataFrame(df, columnName, finalResult);
        }

        // ==========================================================================================
        // 2. STRING IMPLEMENTATIONS
        // ==========================================================================================

        private static GroupedDataFrame GroupByStringSequential(DataFrame df, string columnName)
        {
            var col = (StringColumn)df[columnName];
            int capacity = Math.Max(1024, df.RowCount / 10);

            // Zero-Alloc String Map
            var map = new StringKeyMap(col.RawBytes, col.Offsets, capacity, df.RowCount);
            var nullIndices = new List<int>();

            for (int i = 0; i < df.RowCount; i++)
            {
                if (col.IsNull(i)) { nullIndices.Add(i); continue; }
                map.AddRow(i);
            }

            var result = FinalizeResult(df, columnName, map.ToDictionary(), nullIndices);
            map.Dispose();
            return result;
        }

        private static GroupedDataFrame GroupByStringParallel(DataFrame df, string columnName)
        {
            var col = (StringColumn)df[columnName];
            var rawBytes = col.RawBytes;
            var offsets = col.Offsets;

            var partitionMaps = new Dictionary<string, List<int>>[PartitionCount];
            var partitionLocks = new object[PartitionCount];
            var globalNulls = new ConcurrentBag<int>();

            for (int i = 0; i < PartitionCount; i++)
            {
                partitionMaps[i] = new Dictionary<string, List<int>>();
                partitionLocks[i] = new object();
            }

            Parallel.ForEach(Partitioner.Create(0, df.RowCount), range =>
            {
                for (int i = range.Item1; i < range.Item2; i++)
                {
                    if (col.IsNull(i))
                    {
                        globalNulls.Add(i);
                        continue;
                    }

                    // 1. Calculate Hash from BYTES (Zero-Alloc)
                    int start = offsets[i];
                    int len = offsets[i + 1] - start;
                    int hashCode = ComputeFnvHash(rawBytes, start, len);
                    int pIdx = (hashCode & 0x7FFFFFFF) % PartitionCount;

                    // 2. Materialize String ONLY when needed
                    // We must create the string here because Dictionary<string> needs it as key.
                    // This is still better than Sequential because creating strings happens in parallel.
                    string strVal = col.Get(i)!;

                    lock (partitionLocks[pIdx])
                    {
                        var map = partitionMaps[pIdx];
                        if (!map.TryGetValue(strVal, out var list))
                        {
                            list = new List<int>();
                            map[strVal] = list;
                        }
                        list.Add(i);
                    }
                }
            });

            var finalResult = new Dictionary<object, List<int>>();
            foreach (var map in partitionMaps)
            {
                foreach (var kvp in map) finalResult.Add(kvp.Key, kvp.Value);
            }
            if (!globalNulls.IsEmpty) finalResult.Add(NullKey, globalNulls.ToList());

            return new GroupedDataFrame(df, columnName, finalResult);
        }

        // ==========================================================================================
        // 3. HELPERS
        // ==========================================================================================

        private static GroupedDataFrame GroupBySequentialObject(DataFrame df, string columnName)
        {
            var col = (IColumn)df[columnName];
            var fastMap = new Dictionary<object, List<int>>();

            for (int i = 0; i < df.RowCount; i++)
            {
                object? val = col.GetValue(i);
                object key = val ?? NullKey;
                if (!fastMap.TryGetValue(key, out var indices)) { indices = new List<int>(); fastMap[key] = indices; }
                indices.Add(i);
            }
            return new GroupedDataFrame(df, columnName, fastMap);
        }

        private static GroupedDataFrame FinalizeResult(
            DataFrame df, string colName, Dictionary<object, List<int>> map, List<int> nulls)
        {
            if (nulls.Count > 0) map.Add(NullKey, nulls);
            return new GroupedDataFrame(df, colName, map);
        }

        [MethodImpl(MethodImplOptions.AggressiveInlining)]
        private static int ComputeFnvHash(byte[] bytes, int start, int length)
        {
            int hash = -2128831035;
            int end = start + length;
            for (int i = start; i < end; i++)
            {
                hash = (hash ^ bytes[i]) * 16777619;
            }
            return hash;
        }

        /// <summary>
        /// Internal helper to unwrap the NullKey sentinel.
        /// </summary>
        internal static object? GetRealValue(object key) => ReferenceEquals(key, NullKey) ? null : key;
    }
}
===== FILE: src/LeichtFrame.Core/DataFrame/Operations/JoinOps.cs =====
namespace LeichtFrame.Core
{
    /// <summary>
    /// Provides extension methods for joining multiple <see cref="DataFrame"/> objects.
    /// Optimized with typed HashMaps to avoid boxing overhead.
    /// </summary>
    public static class DataFrameJoinExtensions
    {
        /// <summary>
        /// Joins two DataFrames based on a common key column using a Hash Join algorithm.
        /// Supports Inner and Left joins.
        /// </summary>
        public static DataFrame Join(this DataFrame left, DataFrame right, string on, JoinType joinType = JoinType.Inner)
        {
            Type type = left[on].DataType;

            Type coreType = Nullable.GetUnderlyingType(type) ?? type;

            if (coreType == typeof(int))
                return ExecuteJoin<int>(left, right, on, joinType);

            if (coreType == typeof(double))
                return ExecuteJoin<double>(left, right, on, joinType);

            if (coreType == typeof(string))
                return ExecuteJoin<string>(left, right, on, joinType);

            if (coreType == typeof(bool))
                return ExecuteJoin<bool>(left, right, on, joinType);

            if (coreType == typeof(DateTime))
                return ExecuteJoin<DateTime>(left, right, on, joinType);

            return ExecuteJoin<object>(left, right, on, joinType);
        }

        private static DataFrame ExecuteJoin<T>(DataFrame left, DataFrame right, string on, JoinType joinType)
            where T : notnull
        {
            var leftKeyCol = (IColumn<T>)left[on];
            var rightKeyCol = (IColumn<T>)right[on];

            var hashTable = new Dictionary<T, List<int>>();

            for (int r = 0; r < right.RowCount; r++)
            {
                if (rightKeyCol.IsNull(r)) continue;

                T key = rightKeyCol.GetValue(r);

                if (key == null) continue;

                if (!hashTable.TryGetValue(key, out var indices))
                {
                    indices = new List<int>();
                    hashTable[key] = indices;
                }
                indices.Add(r);
            }

            var leftIndices = new List<int>(left.RowCount);
            var rightIndices = new List<int>(left.RowCount);

            for (int l = 0; l < left.RowCount; l++)
            {
                if (leftKeyCol.IsNull(l))
                {
                    if (joinType == JoinType.Left)
                    {
                        leftIndices.Add(l);
                        rightIndices.Add(-1);
                    }
                    continue;
                }

                T key = leftKeyCol.GetValue(l);
                if (key == null)
                {
                    if (joinType == JoinType.Left) { leftIndices.Add(l); rightIndices.Add(-1); }
                    continue;
                }

                if (hashTable.TryGetValue(key, out var matchingRightIndices))
                {
                    foreach (var rIdx in matchingRightIndices)
                    {
                        leftIndices.Add(l);
                        rightIndices.Add(rIdx);
                    }
                }
                else if (joinType == JoinType.Left)
                {
                    leftIndices.Add(l);
                    rightIndices.Add(-1);
                }
            }

            return MaterializeResult(left, right, on, leftIndices, rightIndices, joinType);
        }

        private static DataFrame MaterializeResult(
            DataFrame left,
            DataFrame right,
            string on,
            List<int> leftIndices,
            List<int> rightIndices,
            JoinType joinType)
        {
            var newColumns = new List<IColumn>();

            foreach (var col in left.Columns)
            {
                newColumns.Add(col.CloneSubset(leftIndices));
            }

            foreach (var col in right.Columns)
            {
                if (col.Name == on) continue;

                if (left.Schema.HasColumn(col.Name))
                    throw new NotSupportedException($"Column collision: '{col.Name}' exists in both DataFrames.");

                bool forceNullable = joinType == JoinType.Left || col.IsNullable;
                IColumn newCol = MaterializeRightColumn(col, rightIndices, forceNullable);
                newColumns.Add(newCol);
            }

            return new DataFrame(newColumns);
        }

        private static IColumn MaterializeRightColumn(IColumn source, List<int> indices, bool isNullable)
        {
            IColumn newCol = ColumnFactory.Create(source.Name, source.DataType, indices.Count, isNullable);

            if (source is IntColumn ic && newCol is IntColumn nic)
            {
                for (int i = 0; i < indices.Count; i++)
                {
                    int idx = indices[i];
                    if (idx == -1 || ic.IsNull(idx)) nic.Append(null);
                    else nic.Append(ic.Get(idx));
                }
            }
            else if (source is DoubleColumn dc && newCol is DoubleColumn ndc)
            {
                for (int i = 0; i < indices.Count; i++)
                {
                    int idx = indices[i];
                    if (idx == -1 || dc.IsNull(idx)) ndc.Append(null);
                    else ndc.Append(dc.Get(idx));
                }
            }
            else if (source is StringColumn sc && newCol is StringColumn nsc)
            {
                for (int i = 0; i < indices.Count; i++)
                {
                    int idx = indices[i];
                    if (idx == -1) nsc.Append(null);
                    else nsc.Append(sc.Get(idx));
                }
            }
            else if (source is BoolColumn bc && newCol is BoolColumn nbc)
            {
                for (int i = 0; i < indices.Count; i++)
                {
                    int idx = indices[i];
                    if (idx == -1 || bc.IsNull(idx)) nbc.Append(null);
                    else nbc.Append(bc.Get(idx));
                }
            }
            else if (source is DateTimeColumn dtc && newCol is DateTimeColumn ndtc)
            {
                for (int i = 0; i < indices.Count; i++)
                {
                    int idx = indices[i];
                    if (idx == -1 || dtc.IsNull(idx)) ndtc.Append(null);
                    else ndtc.Append(dtc.Get(idx));
                }
            }
            else
            {
                // Fallback
                for (int i = 0; i < indices.Count; i++)
                {
                    int idx = indices[i];
                    if (idx == -1) newCol.AppendObject(null);
                    else newCol.AppendObject(source.GetValue(idx));
                }
            }

            return newCol;
        }
    }
}
===== FILE: src/LeichtFrame.Core/DataFrame/Operations/OrderOps.cs =====
namespace LeichtFrame.Core
{
    /// <summary>
    /// Provides extension methods for sorting DataFrames.
    /// </summary>
    public static class OrderOps
    {
        /// <summary>
        /// Sorts the DataFrame rows in ascending order based on the values in the specified column.
        /// Returns a new DataFrame with reordered rows.
        /// </summary>
        /// <param name="df">The source DataFrame.</param>
        /// <param name="columnName">The name of the column to sort by.</param>
        /// <returns>A new, sorted DataFrame.</returns>
        public static DataFrame OrderBy(this DataFrame df, string columnName)
        {
            return SortInternal(df, columnName, ascending: true);
        }

        /// <summary>
        /// Sorts the DataFrame rows in descending order based on the values in the specified column.
        /// Returns a new DataFrame with reordered rows.
        /// </summary>
        /// <param name="df">The source DataFrame.</param>
        /// <param name="columnName">The name of the column to sort by.</param>
        /// <returns>A new, sorted DataFrame.</returns>
        public static DataFrame OrderByDescending(this DataFrame df, string columnName)
        {
            return SortInternal(df, columnName, ascending: false);
        }

        private static DataFrame SortInternal(DataFrame df, string columnName, bool ascending)
        {
            if (string.IsNullOrEmpty(columnName)) throw new ArgumentNullException(nameof(columnName));

            // 1. Get the column to sort by
            var sortCol = df[columnName];

            // 2. Calculate the permutation vector (ArgSort)
            // This gives us the indices [2, 0, 1, ...] representing the sorted order.
            int[] sortedIndices = sortCol.GetSortedIndices(ascending);

            // 3. Reorder all columns based on these indices
            // We use CloneSubset, which creates a deep copy of the data in the new order.
            var newColumns = new List<IColumn>(df.ColumnCount);

            foreach (var col in df.Columns)
            {
                newColumns.Add(col.CloneSubset(sortedIndices));
            }

            return new DataFrame(newColumns);
        }
    }
}
===== FILE: src/LeichtFrame.Core/DataFrame/Operations/SelectionOps.cs =====
namespace LeichtFrame.Core
{
    /// <summary>
    /// Provides extension methods for selecting columns and slicing rows from a <see cref="DataFrame"/>.
    /// </summary>
    public static class DataFrameSelectionExtensions
    {
        /// <summary>
        /// Projects the DataFrame to a new DataFrame containing only the selected columns.
        /// This is a Zero-Copy operation: The new DataFrame shares the underlying column data with the original.
        /// </summary>
        /// <param name="df">The source DataFrame.</param>
        /// <param name="columnNames">The names of the columns to select.</param>
        /// <returns>A new DataFrame instance containing the selected columns.</returns>
        public static DataFrame Select(this DataFrame df, params string[] columnNames)
        {
            if (df == null) throw new ArgumentNullException(nameof(df));
            if (columnNames == null || columnNames.Length == 0)
                throw new ArgumentException("At least one column must be selected.", nameof(columnNames));

            // We collect the column references from the original.
            var selectedColumns = new List<IColumn>(columnNames.Length);

            foreach (var name in columnNames)
            {
                selectedColumns.Add(df[name]);
            }

            // Create a new container with the same column instances.
            return new DataFrame(selectedColumns);
        }

        /// <summary>
        /// Returns a zero-copy view of the DataFrame restricted to the specified row range.
        /// </summary>
        /// <param name="df">The source DataFrame.</param>
        /// <param name="start">The zero-based starting row index.</param>
        /// <param name="length">The number of rows to include in the slice.</param>
        /// <returns>A new DataFrame containing the subset of rows.</returns>
        public static DataFrame Slice(this DataFrame df, int start, int length)
        {
            if (start < 0) throw new ArgumentOutOfRangeException(nameof(start));

            // Bounds adjusting (Robustness)
            if (start >= df.RowCount)
            {
                // Return empty DataFrame with same schema
                return DataFrame.Create(df.Schema, 0);
            }

            int validLength = Math.Min(length, df.RowCount - start);

            var newColumns = new List<IColumn>(df.ColumnCount);

            foreach (var col in df.Columns)
            {
                // Magic: Create SlicedColumn<T> dynamically
                var genericType = typeof(SlicedColumn<>).MakeGenericType(col.DataType);

                // Invoke Constructor: SlicedColumn(source, offset, length)
                var slicedCol = Activator.CreateInstance(genericType, col, start, validLength);

                newColumns.Add((IColumn)slicedCol!);
            }

            return new DataFrame(newColumns);
        }

        /// <summary>
        /// Returns the first <paramref name="count"/> rows of the DataFrame.
        /// </summary>
        /// <param name="df">The source DataFrame.</param>
        /// <param name="count">The number of rows to return from the beginning.</param>
        /// <returns>A new DataFrame containing the first rows.</returns>
        public static DataFrame Head(this DataFrame df, int count)
        {
            return df.Slice(0, count);
        }

        /// <summary>
        /// Returns the last <paramref name="count"/> rows of the DataFrame.
        /// </summary>
        /// <param name="df">The source DataFrame.</param>
        /// <param name="count">The number of rows to return from the end.</param>
        /// <returns>A new DataFrame containing the last rows.</returns>
        public static DataFrame Tail(this DataFrame df, int count)
        {
            int start = Math.Max(0, df.RowCount - count);
            // length is count, but Slice logic handles if start+count > RowCount (though here it matches)
            int length = Math.Min(count, df.RowCount);
            return df.Slice(start, length);
        }
    }
}
===== FILE: src/LeichtFrame.Core/DataFrame/Operations/SortingOps.cs =====
namespace LeichtFrame.Core
{
    /// <summary>
    /// Provides sorting functionality for DataFrames and Columns.
    /// </summary>
    public static class SortingOps
    {
        /// <summary>
        /// Returns an array of row indices sorted by the values in the specified column.
        /// Does not modify the original data.
        /// </summary>
        /// <param name="column">The column to sort by.</param>
        /// <param name="ascending">If true, sorts from smallest to largest. If false, largest to smallest.</param>
        /// <returns>An array of integers representing the new row order.</returns>
        public static int[] GetSortedIndices(this IColumn column, bool ascending = true)
        {
            // 1. Initialize indices [0, 1, 2, ... N-1]
            int[] indices = new int[column.Length];
            for (int i = 0; i < indices.Length; i++)
            {
                indices[i] = i;
            }

            // 2. Select optimized comparer based on column type
            IComparer<int> comparer;

            if (column is IntColumn ic)
            {
                comparer = new IntIndirectComparer(ic, ascending);
            }
            else if (column is DoubleColumn dc)
            {
                comparer = new DoubleIndirectComparer(dc, ascending);
            }
            else if (column is StringColumn sc)
            {
                comparer = new StringIndirectComparer(sc, ascending);
            }
            else if (column is DateTimeColumn dtc)
            {
                comparer = new DateTimeIndirectComparer(dtc, ascending);
            }
            else if (column is BoolColumn bc)
            {
                comparer = new BoolIndirectComparer(bc, ascending);
            }
            else
            {
                // Fallback for unknown types (slow via object boxing)
                comparer = new ObjectIndirectComparer(column, ascending);
            }

            // 3. Sort indices indirectly
            // Note: Array.Sort is not stable, but it's fast (Introsort)
            Array.Sort(indices, comparer);

            return indices;
        }

        // --- Comparers ---

        // Helper to handle null logic: Nulls usually come first (smallest)
        private static int CompareNulls(bool isNullX, bool isNullY)
        {
            if (isNullX && isNullY) return 0;
            if (isNullX) return -1; // Null is smaller than Value
            return 1;               // Value is larger than Null
        }

        private readonly struct IntIndirectComparer : IComparer<int>
        {
            private readonly IntColumn _col;
            private readonly int _direction; // 1 for asc, -1 for desc

            public IntIndirectComparer(IntColumn col, bool asc)
            {
                _col = col;
                _direction = asc ? 1 : -1;
            }

            public int Compare(int x, int y)
            {
                bool nx = _col.IsNull(x);
                bool ny = _col.IsNull(y);

                if (nx || ny) return CompareNulls(nx, ny) * _direction;

                int valX = _col.Get(x);
                int valY = _col.Get(y);

                return valX.CompareTo(valY) * _direction;
            }
        }

        private readonly struct DoubleIndirectComparer : IComparer<int>
        {
            private readonly DoubleColumn _col;
            private readonly int _direction;

            public DoubleIndirectComparer(DoubleColumn col, bool asc)
            {
                _col = col;
                _direction = asc ? 1 : -1;
            }

            public int Compare(int x, int y)
            {
                bool nx = _col.IsNull(x);
                bool ny = _col.IsNull(y);

                if (nx || ny) return CompareNulls(nx, ny) * _direction;

                double valX = _col.Get(x);
                double valY = _col.Get(y);

                return valX.CompareTo(valY) * _direction;
            }
        }

        private readonly struct StringIndirectComparer : IComparer<int>
        {
            private readonly StringColumn _col;
            private readonly int _direction;

            public StringIndirectComparer(StringColumn col, bool asc)
            {
                _col = col;
                _direction = asc ? 1 : -1;
            }

            public int Compare(int x, int y)
            {
                return _col.CompareRaw(x, y) * _direction;
            }
        }

        private readonly struct DateTimeIndirectComparer : IComparer<int>
        {
            private readonly DateTimeColumn _col;
            private readonly int _direction;

            public DateTimeIndirectComparer(DateTimeColumn col, bool asc)
            {
                _col = col;
                _direction = asc ? 1 : -1;
            }

            public int Compare(int x, int y)
            {
                bool nx = _col.IsNull(x);
                bool ny = _col.IsNull(y);

                if (nx || ny) return CompareNulls(nx, ny) * _direction;

                return _col.Get(x).CompareTo(_col.Get(y)) * _direction;
            }
        }

        private readonly struct BoolIndirectComparer : IComparer<int>
        {
            private readonly BoolColumn _col;
            private readonly int _direction;

            public BoolIndirectComparer(BoolColumn col, bool asc)
            {
                _col = col;
                _direction = asc ? 1 : -1;
            }

            public int Compare(int x, int y)
            {
                bool nx = _col.IsNull(x);
                bool ny = _col.IsNull(y);

                if (nx || ny) return CompareNulls(nx, ny) * _direction;

                return _col.Get(x).CompareTo(_col.Get(y)) * _direction;
            }
        }

        private readonly struct ObjectIndirectComparer : IComparer<int>
        {
            private readonly IColumn _col;
            private readonly int _direction;

            public ObjectIndirectComparer(IColumn col, bool asc)
            {
                _col = col;
                _direction = asc ? 1 : -1;
            }

            public int Compare(int x, int y)
            {
                bool nx = _col.IsNull(x);
                bool ny = _col.IsNull(y);

                if (nx || ny) return CompareNulls(nx, ny) * _direction;

                var valX = _col.GetValue(x) as IComparable;
                var valY = _col.GetValue(y) as IComparable;

                if (valX == null && valY == null) return 0;
                if (valX == null) return -1 * _direction;
                if (valY == null) return 1 * _direction;

                return valX.CompareTo(valY) * _direction;
            }
        }
    }
}
===== FILE: src/LeichtFrame.Core/DataFrame/Operations/TopNOps.cs =====
namespace LeichtFrame.Core
{
    /// <summary>
    /// Provides optimized Top-N / Bottom-N selection algorithms (Heap-based).
    /// </summary>
    public static class TopNOps
    {
        /// <summary>
        /// Returns the N rows with the smallest values in the specified column.
        /// (Equivalent to OrderBy(column).Head(n), but significantly faster).
        /// </summary>
        public static DataFrame Smallest(this DataFrame df, int n, string columnName)
        {
            return TopNInternal(df, n, columnName, ascending: true);
        }

        /// <summary>
        /// Returns the N rows with the largest values in the specified column.
        /// (Equivalent to OrderByDescending(column).Head(n), but significantly faster).
        /// </summary>
        public static DataFrame Largest(this DataFrame df, int n, string columnName)
        {
            return TopNInternal(df, n, columnName, ascending: false);
        }

        private static DataFrame TopNInternal(DataFrame df, int n, string columnName, bool ascending)
        {
            if (n <= 0) return df.Head(0); // Return empty schema
            if (n >= df.RowCount) return ascending ? df.OrderBy(columnName) : df.OrderByDescending(columnName);

            var col = df[columnName];
            var indices = new int[n];
            int finalCount = 0;

            if (col is IntColumn ic)
            {
                finalCount = GetIndices(ic, n, ascending, indices);
            }
            else if (col is DoubleColumn dc)
            {
                finalCount = GetIndices(dc, n, ascending, indices);
            }
            else if (col is StringColumn sc)
            {
                finalCount = GetIndices(sc, n, ascending, indices);
            }
            else
            {
                // Fallback: Full Sort
                return ascending ? df.OrderBy(columnName).Head(n) : df.OrderByDescending(columnName).Head(n);
            }

            Array.Resize(ref indices, finalCount);

            // Final Sort of the small result set
            var subsetIndices = SortIndicesByColumn(indices, col, ascending);

            var newColumns = new List<IColumn>(df.ColumnCount);
            foreach (var c in df.Columns)
            {
                newColumns.Add(c.CloneSubset(subsetIndices));
            }
            return new DataFrame(newColumns);
        }

        // --- Type Specific Implementations ---

        private static int GetIndices(IntColumn col, int n, bool smallestN, int[] resultBuffer)
        {
            var comparer = smallestN
                ? Comparer<int>.Create((x, y) => y.CompareTo(x))
                : Comparer<int>.Default;

            var queue = new PriorityQueue<int, int>(n, comparer);

            for (int i = 0; i < col.Length; i++)
            {
                int val = col.Get(i);

                if (queue.Count < n)
                {
                    queue.Enqueue(i, val);
                }
                else
                {
                    if (queue.TryPeek(out int _, out int worstVal))
                    {
                        bool shouldSwap = smallestN
                            ? val < worstVal
                            : val > worstVal;

                        if (shouldSwap)
                        {
                            queue.Dequeue();
                            queue.Enqueue(i, val);
                        }
                    }
                }
            }

            int count = queue.Count;
            for (int i = count - 1; i >= 0; i--)
            {
                resultBuffer[i] = queue.Dequeue();
            }
            return count;
        }

        private static int GetIndices(DoubleColumn col, int n, bool smallestN, int[] resultBuffer)
        {
            var comparer = smallestN
                ? Comparer<double>.Create((x, y) => y.CompareTo(x))
                : Comparer<double>.Default;

            var queue = new PriorityQueue<int, double>(n, comparer);

            for (int i = 0; i < col.Length; i++)
            {
                if (col.IsNull(i)) continue;

                double val = col.Get(i);

                if (queue.Count < n)
                {
                    queue.Enqueue(i, val);
                }
                else
                {
                    if (queue.TryPeek(out int _, out double worstVal))
                    {
                        bool shouldSwap = smallestN ? val < worstVal : val > worstVal;
                        if (shouldSwap)
                        {
                            queue.Dequeue();
                            queue.Enqueue(i, val);
                        }
                    }
                }
            }

            int count = queue.Count;
            for (int i = count - 1; i >= 0; i--) resultBuffer[i] = queue.Dequeue();
            return count;
        }

        private static int GetIndices(StringColumn col, int n, bool smallestN, int[] resultBuffer)
        {
            var comparer = Comparer<int>.Create((x, y) =>
            {
                int cmp = col.CompareRaw(x, y);
                return smallestN ? cmp * -1 : cmp;
            });

            var queue = new PriorityQueue<int, int>(n, comparer);

            for (int i = 0; i < col.Length; i++)
            {
                if (queue.Count < n)
                {
                    queue.Enqueue(i, i);
                }
                else
                {
                    int worstIndex = queue.Peek();

                    int cmp = col.CompareRaw(i, worstIndex);

                    bool isBetter = smallestN
                        ? cmp < 0
                        : cmp > 0;

                    if (isBetter)
                    {
                        queue.Dequeue();
                        queue.Enqueue(i, i);
                    }
                }
            }

            int count = queue.Count;
            for (int i = count - 1; i >= 0; i--)
            {
                resultBuffer[i] = queue.Dequeue();
            }
            return count;
        }

        private static int[] SortIndicesByColumn(int[] indices, IColumn col, bool ascending)
        {
            if (col is IntColumn ic)
            {
                Array.Sort(indices, (a, b) => (ascending ? 1 : -1) * ic.Get(a).CompareTo(ic.Get(b)));
            }
            else if (col is DoubleColumn dc)
            {
                Array.Sort(indices, (a, b) => (ascending ? 1 : -1) * dc.Get(a).CompareTo(dc.Get(b)));
            }
            else if (col is StringColumn sc)
            {
                Array.Sort(indices, (a, b) => (ascending ? 1 : -1) * sc.CompareRaw(a, b));
            }

            return indices;
        }
    }
}
===== FILE: src/LeichtFrame.Core/DataFrame/Operations/TransformationOps.cs =====
using System.Runtime.CompilerServices;

namespace LeichtFrame.Core
{
    /// <summary>
    /// Provides extension methods for transforming data and adding computed columns.
    /// </summary>
    public static class TransformationOps
    {
        /// <summary>
        /// Creates a new column by applying a function to every row and adds it to the DataFrame.
        /// Returns a new DataFrame instance (the original remains unchanged).
        /// </summary>
        /// <typeparam name="T">The type of the new column (e.g., int, double, string).</typeparam>
        /// <param name="df">The source DataFrame.</param>
        /// <param name="newColumnName">The name of the new column.</param>
        /// <param name="computer">A function that takes a RowView and returns the calculated value.</param>
        /// <returns>A new DataFrame containing the original columns plus the new computed column.</returns>
        public static DataFrame AddColumn<T>(this DataFrame df, string newColumnName, Func<RowView, T> computer)
        {
            if (string.IsNullOrEmpty(newColumnName)) throw new ArgumentNullException(nameof(newColumnName));
            if (computer == null) throw new ArgumentNullException(nameof(computer));

            if (df.HasColumn(newColumnName))
            {
                throw new ArgumentException($"Column '{newColumnName}' already exists in DataFrame.");
            }

            Type typeT = typeof(T);
            Type underlying = Nullable.GetUnderlyingType(typeT) ?? typeT;
            bool isNullable = underlying != typeT || !typeT.IsValueType; // e.g. int? or string

            // 1. Create the Column (Non-Generic Factory)
            // Wir nutzen hier Create(Type), das dank deines Fixes Nullable Types auspacken kann.
            IColumn newCol = ColumnFactory.Create(newColumnName, typeT, df.RowCount, isNullable);

            // 2. Compute & Append loop (Type-Dispatcher)

            // Case A: Exact Match (e.g. T=int, Col=IColumn<int>)
            // Auch StringColumn f√§llt hierunter (T=string, Col=IColumn<string>)
            if (newCol is IColumn<T> typedCol)
            {
                for (int i = 0; i < df.RowCount; i++)
                {
                    var row = new RowView(i, df.Columns, df.Schema);
                    typedCol.Append(computer(row));
                }
            }
            // Case B: Nullable Primitives (e.g. T=int?, Col=IntColumn)
            // IntColumn implementiert NICHT IColumn<int?>, hat aber eine Methode Append(int?).
            // Wir nutzen Unsafe.As, um den Delegaten zu casten ohne Boxing.
            else if (newCol is IntColumn ic && typeT == typeof(int?))
            {
                var func = Unsafe.As<Func<RowView, T>, Func<RowView, int?>>(ref computer);
                for (int i = 0; i < df.RowCount; i++)
                    ic.Append(func(new RowView(i, df.Columns, df.Schema)));
            }
            else if (newCol is DoubleColumn dc && typeT == typeof(double?))
            {
                var func = Unsafe.As<Func<RowView, T>, Func<RowView, double?>>(ref computer);
                for (int i = 0; i < df.RowCount; i++)
                    dc.Append(func(new RowView(i, df.Columns, df.Schema)));
            }
            else if (newCol is BoolColumn bc && typeT == typeof(bool?))
            {
                var func = Unsafe.As<Func<RowView, T>, Func<RowView, bool?>>(ref computer);
                for (int i = 0; i < df.RowCount; i++)
                    bc.Append(func(new RowView(i, df.Columns, df.Schema)));
            }
            else if (newCol is DateTimeColumn dtc && typeT == typeof(DateTime?))
            {
                var func = Unsafe.As<Func<RowView, T>, Func<RowView, DateTime?>>(ref computer);
                for (int i = 0; i < df.RowCount; i++)
                    dtc.Append(func(new RowView(i, df.Columns, df.Schema)));
            }
            else
            {
                // Fallback (Safe but slower due to boxing)
                for (int i = 0; i < df.RowCount; i++)
                {
                    var row = new RowView(i, df.Columns, df.Schema);
                    object? val = computer(row);
                    newCol.AppendObject(val);
                }
            }

            // 3. Construct new DataFrame
            var newColumnList = new List<IColumn>(df.Columns);
            newColumnList.Add(newCol);

            return new DataFrame(newColumnList);
        }
    }
}
===== FILE: src/LeichtFrame.Core/DataFrame/Operations/VectorizedFilterOps.cs =====
using System.Numerics;
using System.Runtime.InteropServices;

namespace LeichtFrame.Core
{
    /// <summary>
    /// Provides high-performance, SIMD-accelerated filtering operations for DataFrames.
    /// </summary>
    public static class VectorizedFilterOps
    {
        /// <summary>
        /// Filters the DataFrame using hardware-accelerated SIMD instructions.
        /// Supports primitive types like int, double, float.
        /// </summary>
        /// <typeparam name="T">The type of the column (must be an INumber).</typeparam>
        /// <param name="df">The source DataFrame.</param>
        /// <param name="columnName">The name of the column to filter by.</param>
        /// <param name="op">The comparison operator.</param>
        /// <param name="value">The value to compare against.</param>
        /// <returns>A new DataFrame containing only the matching rows.</returns>
        public static DataFrame WhereVec<T>(this DataFrame df, string columnName, CompareOp op, T value)
            where T : struct, INumber<T>
        {
            var col = df[columnName];
            if (col is not IColumn<T> typedCol)
            {
                throw new ArgumentException($"Column '{columnName}' is not of type {typeof(T).Name}");
            }

            ReadOnlySpan<T> data = typedCol.AsSpan();
            var indices = new List<int>(data.Length / 4);

            int i = 0;

            if (Vector.IsHardwareAccelerated)
            {
                int vectorSize = Vector<T>.Count;
                var valueVec = new Vector<T>(value);

                var vectorSpan = MemoryMarshal.Cast<T, Vector<T>>(data);

                for (int vIdx = 0; vIdx < vectorSpan.Length; vIdx++)
                {
                    var dataVec = vectorSpan[vIdx];
                    Vector<T> resultVec;

                    switch (op)
                    {
                        case CompareOp.Equal:
                            resultVec = Vector.Equals(dataVec, valueVec);
                            break;
                        case CompareOp.GreaterThan:
                            resultVec = Vector.GreaterThan(dataVec, valueVec);
                            break;
                        case CompareOp.GreaterThanOrEqual:
                            resultVec = Vector.GreaterThanOrEqual(dataVec, valueVec);
                            break;
                        case CompareOp.LessThan:
                            resultVec = Vector.LessThan(dataVec, valueVec);
                            break;
                        case CompareOp.LessThanOrEqual:
                            resultVec = Vector.LessThanOrEqual(dataVec, valueVec);
                            break;
                        case CompareOp.NotEqual:
                            resultVec = Vector.OnesComplement(Vector.Equals(dataVec, valueVec));
                            break;
                        default:
                            throw new NotSupportedException($"Operator {op} not supported.");
                    }

                    if (resultVec == Vector<T>.Zero)
                    {
                        i += vectorSize;
                        continue;
                    }

                    for (int k = 0; k < vectorSize; k++)
                    {
                        if (resultVec[k] != T.Zero)
                        {
                            int absoluteIndex = i + k;
                            if (!col.IsNullable || !col.IsNull(absoluteIndex))
                            {
                                indices.Add(absoluteIndex);
                            }
                        }
                    }
                    i += vectorSize;
                }
            }

            for (; i < data.Length; i++)
            {
                T val = data[i];
                if (col.IsNullable && col.IsNull(i)) continue;

                bool match = op switch
                {
                    CompareOp.Equal => val == value,
                    CompareOp.NotEqual => val != value,
                    CompareOp.GreaterThan => val > value,
                    CompareOp.GreaterThanOrEqual => val >= value,
                    CompareOp.LessThan => val < value,
                    CompareOp.LessThanOrEqual => val <= value,
                    _ => false
                };

                if (match) indices.Add(i);
            }

            var newColumns = new List<IColumn>();
            foreach (var originalCol in df.Columns)
            {
                newColumns.Add(originalCol.CloneSubset(indices));
            }

            return new DataFrame(newColumns);
        }
    }
}
===== FILE: src/LeichtFrame.Core/DataFrame/Operations/VectorizedMathOps.cs =====
using System.Numerics;
using System.Runtime.InteropServices;

namespace LeichtFrame.Core
{
    internal static class VectorizedMathOps
    {
        public enum MathOp { Add, Subtract, Multiply, Divide }

        public static void Calculate<T>(ReadOnlySpan<T> a, ReadOnlySpan<T> b, Span<T> result, MathOp op)
            where T : struct, INumber<T>
        {
            int i = 0;
            if (Vector.IsHardwareAccelerated)
            {
                int vecSize = Vector<T>.Count;
                var vecA = MemoryMarshal.Cast<T, Vector<T>>(a);
                var vecB = MemoryMarshal.Cast<T, Vector<T>>(b);
                var vecRes = MemoryMarshal.Cast<T, Vector<T>>(result);

                int limit = Math.Min(vecA.Length, vecB.Length);

                for (int v = 0; v < limit; v++)
                {
                    vecRes[v] = op switch
                    {
                        MathOp.Add => vecA[v] + vecB[v],
                        MathOp.Subtract => vecA[v] - vecB[v],
                        MathOp.Multiply => vecA[v] * vecB[v],
                        MathOp.Divide => vecA[v] / vecB[v],
                        _ => throw new NotSupportedException()
                    };
                }
                i = limit * vecSize;
            }

            // Tail Loop
            for (; i < a.Length; i++)
            {
                result[i] = op switch
                {
                    MathOp.Add => a[i] + b[i],
                    MathOp.Subtract => a[i] - b[i],
                    MathOp.Multiply => a[i] * b[i],
                    MathOp.Divide => a[i] / b[i],
                    _ => throw new NotSupportedException()
                };
            }
        }

        // Overload f√ºr Scalar (Column + 5)
        public static void CalculateScalar<T>(ReadOnlySpan<T> a, T scalar, Span<T> result, MathOp op)
            where T : struct, INumber<T>
        {
            int i = 0;
            if (Vector.IsHardwareAccelerated)
            {
                int vecSize = Vector<T>.Count;
                var vecA = MemoryMarshal.Cast<T, Vector<T>>(a);
                var vecRes = MemoryMarshal.Cast<T, Vector<T>>(result);
                var vecScalar = new Vector<T>(scalar);

                int limit = vecA.Length;

                for (int v = 0; v < limit; v++)
                {
                    vecRes[v] = op switch
                    {
                        MathOp.Add => vecA[v] + vecScalar,
                        MathOp.Subtract => vecA[v] - vecScalar,
                        MathOp.Multiply => vecA[v] * vecScalar,
                        MathOp.Divide => vecA[v] / vecScalar,
                        _ => throw new NotSupportedException()
                    };
                }
                i = limit * vecSize;
            }

            for (; i < a.Length; i++)
            {
                result[i] = op switch
                {
                    MathOp.Add => a[i] + scalar,
                    MathOp.Subtract => a[i] - scalar,
                    MathOp.Multiply => a[i] * scalar,
                    MathOp.Divide => a[i] / scalar,
                    _ => throw new NotSupportedException()
                };
            }
        }
    }
}
===== FILE: src/LeichtFrame.Core/DataFrame/RowView.cs =====
using System;
using System.Collections.Generic;

namespace LeichtFrame.Core
{
    /// <summary>
    /// Represents a lightweight, read-only view of a single row in a <see cref="DataFrame"/>.
    /// Acts as a zero-copy cursor enabling row-based operations without materializing objects.
    /// </summary>
    public readonly struct RowView
    {
        private readonly int _rowIndex;
        private readonly IReadOnlyList<IColumn> _columns;
        private readonly DataFrameSchema _schema;

        /// <summary>
        /// Initializes a new instance of the <see cref="RowView"/> struct.
        /// </summary>
        /// <param name="rowIndex">The zero-based index of the row.</param>
        /// <param name="columns">The list of columns backing the data.</param>
        /// <param name="schema">The schema definition for column name lookups.</param>
        /// <exception cref="ArgumentOutOfRangeException">Thrown if rowIndex is negative.</exception>
        /// <exception cref="ArgumentNullException">Thrown if columns or schema are null.</exception>
        public RowView(int rowIndex, IReadOnlyList<IColumn> columns, DataFrameSchema schema)
        {
            if (rowIndex < 0) throw new ArgumentOutOfRangeException(nameof(rowIndex));
            _rowIndex = rowIndex;
            _columns = columns ?? throw new ArgumentNullException(nameof(columns));
            _schema = schema ?? throw new ArgumentNullException(nameof(schema));
        }

        /// <summary>
        /// Gets the strongly-typed value from the specified column index.
        /// This is the fastest way to access data within a row.
        /// </summary>
        /// <typeparam name="T">The expected type of the value.</typeparam>
        /// <param name="columnIndex">The zero-based index of the column.</param>
        /// <returns>The value of type T.</returns>
        /// <exception cref="InvalidCastException">Thrown if the column type does not match T.</exception>
        public T Get<T>(int columnIndex)
        {
            var col = _columns[columnIndex];

            // Pattern matching on generic interface
            if (col is IColumn<T> typedCol)
            {
                return typedCol.GetValue(_rowIndex);
            }

            throw new InvalidCastException(
                $"Column '{col.Name}' is type {col.DataType.Name}, but '{typeof(T).Name}' was requested.");
        }

        /// <summary>
        /// Gets the strongly-typed value from the column with the specified name.
        /// </summary>
        /// <typeparam name="T">The expected type of the value.</typeparam>
        /// <param name="columnName">The name of the column.</param>
        /// <returns>The value of type T.</returns>
        /// <exception cref="ArgumentException">Thrown if the column name does not exist.</exception>
        public T Get<T>(string columnName)
        {
            int index = _schema.GetColumnIndex(columnName);
            return Get<T>(index);
        }

        /// <summary>
        /// Gets the value at the specified column index as an object (boxed).
        /// </summary>
        /// <param name="columnIndex">The zero-based index of the column.</param>
        /// <returns>The value as an object, or null.</returns>
        public object? GetValue(int columnIndex)
        {
            return _columns[columnIndex].GetValue(_rowIndex);
        }

        // Indexer for convenience

        /// <summary>
        /// Gets the value at the specified column index (untyped).
        /// </summary>
        /// <param name="index">The zero-based column index.</param>
        public object? this[int index] => GetValue(index);

        /// <summary>
        /// Gets the value of the column with the specified name (untyped).
        /// </summary>
        /// <param name="name">The name of the column.</param>
        public object? this[string name] => GetValue(_schema.GetColumnIndex(name));
    }
}
===== FILE: src/LeichtFrame.Core/Extensions/ColumnExtensions.cs =====
using System;

namespace LeichtFrame.Core
{
    /// <summary>
    /// Provides helper extension methods for interacting with <see cref="IColumn"/> instances.
    /// </summary>
    public static class ColumnExtensions
    {
        /// <summary>
        /// Helper extension to get a typed value from a generic <see cref="IColumn"/>.
        /// Performs a cast and calls the typed GetValue method if possible.
        /// </summary>
        /// <typeparam name="T">The expected return type.</typeparam>
        /// <param name="column">The column instance.</param>
        /// <param name="index">The row index to retrieve.</param>
        /// <returns>The value of type T.</returns>
        /// <exception cref="InvalidCastException">Thrown if the column type does not match T.</exception>
        public static T Get<T>(this IColumn column, int index)
        {
            // Fast Path: If it is already the correct typed interface
            if (column is IColumn<T> typedCol)
            {
                return typedCol.GetValue(index);
            }

            // Slow Path: Type does not match or is unknown -> Exception or Convert
            throw new InvalidCastException(
                $"Column '{column.Name}' is of type {column.DataType.Name}, but '{typeof(T).Name}' was requested.");
        }

        /// <summary>
        /// Appends an untyped object value to the column. 
        /// Handles type checking and dispatching to the concrete Append method.
        /// </summary>
        /// <param name="column">The target column.</param>
        /// <param name="value">The value to append (can be null if supported).</param>
        /// <exception cref="NotSupportedException">Thrown if the value type is incompatible or the column type is unknown.</exception>
        public static void AppendObject(this IColumn column, object? value)
        {
            if (value == null)
            {
                // We must unfortunately know which concrete types support Append(null).
                // Since IColumn does not have Append (only the concrete classes), we cast.
                if (column is IntColumn ic) ic.Append(null);
                else if (column is DoubleColumn dc) dc.Append(null);
                else if (column is StringColumn sc) sc.Append(null);
                else if (column is BoolColumn bc) bc.Append(null);
                else if (column is DateTimeColumn dtc) dtc.Append(null);
                else throw new NotSupportedException($"Column '{column.Name}' does not support null values or type is unknown.");
                return;
            }

            // Type dispatch
            if (column is IntColumn i) i.Append((int)value);
            else if (column is DoubleColumn d) d.Append(Convert.ToDouble(value)); // Convert allows int->double
            else if (column is StringColumn s) s.Append(value.ToString());
            else if (column is BoolColumn b) b.Append((bool)value);
            else if (column is DateTimeColumn dt) dt.Append((DateTime)value);
            else
                throw new NotSupportedException($"Cannot append object of type {value.GetType().Name} to column {column.GetType().Name}");
        }
    }
}
===== FILE: src/LeichtFrame.Core/Extensions/EnumerableDataFrameExtensions.cs =====
using System.Reflection;

namespace LeichtFrame.Core
{
    /// <summary>
    /// Provides extension methods to convert standard IEnumerable collections into LeichtFrame DataFrames.
    /// Supports batched processing to handle large datasets efficiently.
    /// </summary>
    public static class EnumerableDataFrameExtensions
    {
        /// <summary>
        /// Streams an IEnumerable of objects into multiple DataFrames (batches).
        /// This allows processing large collections without holding all objects in memory at once.
        /// </summary>
        /// <typeparam name="T">The type of the objects (POCO).</typeparam>
        /// <param name="source">The source collection.</param>
        /// <param name="batchSize">The number of rows per batch.</param>
        /// <returns>An enumerable of DataFrames.</returns>
        public static IEnumerable<DataFrame> ToDataFrameBatches<T>(this IEnumerable<T> source, int batchSize)
        {
            if (source == null) throw new ArgumentNullException(nameof(source));
            if (batchSize <= 0) throw new ArgumentOutOfRangeException(nameof(batchSize));

            // 1. One-time Setup: Infer Schema and Cache Reflection Data
            // We do this ONCE per stream, not per batch.
            var schema = DataFrameSchema.FromType<T>();
            var type = typeof(T);

            // Align PropertyInfos with Column Indices for fast access
            int colCount = schema.Columns.Count;
            var propertyCache = new PropertyInfo[colCount];

            for (int i = 0; i < colCount; i++)
            {
                string name = schema.Columns[i].Name;
                var prop = type.GetProperty(name);
                if (prop == null) throw new InvalidOperationException($"Property '{name}' not found on type '{type.Name}' during mapping.");
                propertyCache[i] = prop;
            }

            // 2. Iteration & Buffering
            var buffer = new List<T>(batchSize);

            foreach (var item in source)
            {
                buffer.Add(item);

                if (buffer.Count >= batchSize)
                {
                    yield return FlushBatch(buffer, schema, propertyCache);
                    buffer.Clear();
                }
            }

            // 3. Flush Remainder
            if (buffer.Count > 0)
            {
                yield return FlushBatch(buffer, schema, propertyCache);
            }
        }

        private static DataFrame FlushBatch<T>(List<T> buffer, DataFrameSchema schema, PropertyInfo[] propertyCache)
        {
            // Create DataFrame with exact capacity
            var df = DataFrame.Create(schema, buffer.Count);
            int colCount = df.ColumnCount;

            // Cache IColumn references to avoid indexer lookups in the loop
            var columns = new IColumn[colCount];
            for (int i = 0; i < colCount; i++)
            {
                columns[i] = df.Columns[i];
            }

            // Fill Data
            foreach (var item in buffer)
            {
                for (int c = 0; c < colCount; c++)
                {
                    object? val = propertyCache[c].GetValue(item);
                    columns[c].AppendObject(val);
                }
            }

            return df;
        }
    }
}
===== FILE: src/LeichtFrame.Core/JoinType.cs =====
namespace LeichtFrame.Core
{
    /// <summary>
    /// Specifies the type of join operation to perform when combining two DataFrames.
    /// </summary>
    public enum JoinType
    {
        /// <summary>
        /// Returns records that have matching values in both tables.
        /// </summary>
        Inner,

        /// <summary>
        /// Returns all records from the left table, and the matched records from the right table. 
        /// Unmatched records from the right side are null.
        /// </summary>
        Left
    }
}
===== FILE: src/LeichtFrame.Core/LeichtFrame.Core.csproj =====
Ôªø<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net8.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
  </PropertyGroup>

</Project>

===== FILE: src/LeichtFrame.Core/Memory/NullBitmap.cs =====
using System.Buffers;
using System.Runtime.CompilerServices;

namespace LeichtFrame.Core
{
    /// <summary>
    /// A memory-efficient bitset used to track null values in nullable columns.
    /// Uses 1 bit per row, resulting in very low memory overhead (approx. 1.5% of an integer array).
    /// </summary>
    public class NullBitmap : IDisposable
    {
        private ulong[] _buffer;
        private int _capacity;

        /// <summary>
        /// Initializes a new instance of the <see cref="NullBitmap"/> class.
        /// </summary>
        /// <param name="capacity">The initial number of bits (rows) to support.</param>
        public NullBitmap(int capacity)
        {
            _capacity = capacity;
            // Calculate how many ulongs are needed to cover 'capacity' bits
            int ulongCount = (capacity + 63) >> 6;
            _buffer = ArrayPool<ulong>.Shared.Rent(ulongCount);

            // IMPORTANT: Arrays from ArrayPool are "dirty", we need to clear them.
            Array.Clear(_buffer, 0, ulongCount);
        }

        /// <summary>
        /// Checks if the bit at the specified index is set (meaning the value is null).
        /// </summary>
        /// <param name="index">The zero-based index to check.</param>
        /// <returns><c>true</c> if the bit is set (null); otherwise, <c>false</c>.</returns>
        [MethodImpl(MethodImplOptions.AggressiveInlining)]
        public bool IsNull(int index)
        {
            // index >> 6 is identical to index / 64, but often faster
            // index & 63 is identical to index % 64
            return (_buffer[index >> 6] & (1UL << (index & 63))) != 0;
        }

        /// <summary>
        /// Sets the bit at the specified index (marking the value as null).
        /// </summary>
        /// <param name="index">The zero-based index to set.</param>
        [MethodImpl(MethodImplOptions.AggressiveInlining)]
        public void SetNull(int index)
        {
            _buffer[index >> 6] |= (1UL << (index & 63));
        }

        /// <summary>
        /// Clears the bit at the specified index (marking the value as not null).
        /// </summary>
        /// <param name="index">The zero-based index to clear.</param>
        [MethodImpl(MethodImplOptions.AggressiveInlining)]
        public void SetNotNull(int index)
        {
            _buffer[index >> 6] &= ~(1UL << (index & 63));
        }

        /// <summary>
        /// Merges two bitmaps using bitwise OR. 
        /// Result has a bit set (is null) if either A OR B has that bit set.
        /// </summary>
        public static NullBitmap? MergeOr(NullBitmap? a, NullBitmap? b, int length)
        {
            if (a == null && b == null) return null;

            var result = new NullBitmap(length);

            // Access internal buffers via Unsafe or assumes friend access? 
            // For MVP clean code, we iterate ulongs. 
            // Since we don't expose the ulong array publicly, we implement the logic here.

            int ulongCount = (length + 63) >> 6;

            // Note: This relies on the internal _buffer. 
            // If we are strictly outside, we can't access _buffer.
            // Let's assume for this specific internal helper we can access it 
            // or we implement it as an instance method "Or(other)".

            // Let's implement the logic assuming we act on 'result' using 'a' and 'b'.
            // To be safe and clean without friend-assemblies:
            for (int i = 0; i < ulongCount; i++)
            {
                ulong valA = (a != null && i < a._buffer.Length) ? a._buffer[i] : 0;
                ulong valB = (b != null && i < b._buffer.Length) ? b._buffer[i] : 0;
                result._buffer[i] = valA | valB;
            }

            return result;
        }

        /// <summary>
        /// Resizes the internal buffer to accommodate at least the specified number of bits.
        /// Preserves existing data.
        /// </summary>
        /// <param name="newCapacity">The new minimum capacity.</param>
        public void Resize(int newCapacity)
        {
            if (newCapacity <= _capacity) return;

            int oldUlongCount = (_capacity + 63) >> 6;
            int newUlongCount = (newCapacity + 63) >> 6;

            // Case 1: Buffer too small -> New buffer needed
            if (newUlongCount > _buffer.Length)
            {
                var newBuffer = ArrayPool<ulong>.Shared.Rent(newUlongCount);

                // Save old data
                Array.Copy(_buffer, newBuffer, oldUlongCount);

                // Clear the new area in the new buffer
                Array.Clear(newBuffer, oldUlongCount, newUlongCount - oldUlongCount);

                ArrayPool<ulong>.Shared.Return(_buffer);
                _buffer = newBuffer;
            }
            // Case 2: Buffer still large enough, but we now use more "words" from it
            else if (newUlongCount > oldUlongCount)
            {
                // Clear the "freshly uncovered" area in the existing dirty buffer
                Array.Clear(_buffer, oldUlongCount, newUlongCount - oldUlongCount);
            }

            _capacity = newCapacity;
        }

        /// <inheritdoc />
        public void Dispose()
        {
            if (_buffer != null)
            {
                ArrayPool<ulong>.Shared.Return(_buffer);
                _buffer = null!;
            }
        }
    }
}
===== FILE: src/LeichtFrame.Examples/LeichtFrame.Examples.csproj =====
Ôªø<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <OutputType>Exe</OutputType>
    <TargetFramework>net8.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <IsPackable>false</IsPackable>
    <GenerateDocumentationFile>false</GenerateDocumentationFile>
    <NoWarn>$(NoWarn);CS1591</NoWarn>
  </PropertyGroup>

  <ItemGroup>
    <ProjectReference Include="..\LeichtFrame.Core\LeichtFrame.Core.csproj" />
    <ProjectReference Include="..\LeichtFrame.IO\LeichtFrame.IO.csproj" />
  </ItemGroup>

</Project>
===== FILE: src/LeichtFrame.Examples/Program.cs =====
Ôªøusing System.Text;
using LeichtFrame.Core;
using LeichtFrame.IO;

Console.WriteLine("=========================================================");
Console.WriteLine("   üöÄ LeichtFrame - End-to-End Data Pipeline Demo");
Console.WriteLine("=========================================================");

// ---------------------------------------------------------
// 1. SETUP: Simulate Messy Input Data (CSV)
// ---------------------------------------------------------
string rawCsvData =
@"TransactionId,Department,SalesAmount,IsRefund
1,Sales,50.00,false
2,IT,120.50,false
3,,0.00,false
4,Sales,300.00,true
5,HR,45.00,false
6,Sales,15.50,false
7,,90.00,false
8,IT,200.00,false";

Console.WriteLine("\n[1] Generating simulated CSV data stream...");
using var memoryStream = new MemoryStream(Encoding.UTF8.GetBytes(rawCsvData));

// ---------------------------------------------------------
// 2. DEFINE SCHEMA (The "Gold Standard" Way via POCO)
// ---------------------------------------------------------
// Instead of manually building ColumnDefinitions, we simply use a class.
// This ensures type safety and clean code.
// ---------------------------------------------------------
var df = CsvReader.Read<TransactionData>(memoryStream);

Console.WriteLine($"[2] Read CSV into DataFrame. Loaded {df.RowCount} rows.");
Console.WriteLine("    Raw Data Preview:");
Console.WriteLine(df.Inspect());

// ---------------------------------------------------------
// 3. CLEANING (Filter)
// ---------------------------------------------------------
Console.WriteLine("[3] Cleaning Data (Removing missing Departments & Refunds)...");

var cleanedDf = df.Where(row =>
{
    // High-performance access via generic Get<T>
    string dept = row.Get<string>("Department");
    bool isRefund = row.Get<bool>("IsRefund");

    // Keep only if Department exists AND it's not a refund
    return !string.IsNullOrEmpty(dept) && !isRefund;
});

Console.WriteLine($"    Cleaned Data: {cleanedDf.RowCount} rows remaining.");
Console.WriteLine(cleanedDf.Inspect());

// ---------------------------------------------------------
// 4. AGGREGATION (GroupBy & Sum)
// ---------------------------------------------------------
Console.WriteLine("[4] Aggregating: Total Sales by Department...");

var reportDf = cleanedDf.GroupBy("Department").Sum("SalesAmount");

Console.WriteLine("    Report Result:");
Console.WriteLine(reportDf.Inspect());

// ---------------------------------------------------------
// 5. EXPORT (Parquet)
// ---------------------------------------------------------
string outputPath = "sales_report.parquet";
Console.WriteLine($"[5] Exporting Report to Parquet: '{outputPath}'...");

if (File.Exists(outputPath)) File.Delete(outputPath);
reportDf.WriteParquet(outputPath);

Console.WriteLine("‚úÖ Done! Pipeline executed successfully.");
Console.WriteLine("=========================================================");

// ---------------------------------------------------------
// POCO Definition
// ---------------------------------------------------------
public class TransactionData
{
    public int TransactionId { get; set; }

    // Nullable because input data might have missing values (e.g., "3,,0.00")
    public string? Department { get; set; }

    public double SalesAmount { get; set; }
    public bool IsRefund { get; set; }
}
===== FILE: src/LeichtFrame.IO/Arrow/ArrowConverter.cs =====
using Apache.Arrow;
using Apache.Arrow.Types;
using LeichtFrame.Core;

namespace LeichtFrame.IO
{
    /// <summary>
    /// Provides interoperability methods to convert between LeichtFrame <see cref="DataFrame"/> 
    /// and Apache Arrow <see cref="RecordBatch"/>.
    /// Enables integration with the broader data ecosystem (Spark, Python, etc.).
    /// </summary>
    public static class ArrowConverter
    {
        /// <summary>
        /// Converts an Apache Arrow RecordBatch into a LeichtFrame DataFrame.
        /// <para>
        /// **Note:** Currently performs a deep copy of the data.
        /// Zero-copy integration is planned for future releases.
        /// </para>
        /// </summary>
        /// <param name="batch">The source Apache Arrow RecordBatch.</param>
        /// <returns>A new <see cref="DataFrame"/> containing the data from the RecordBatch.</returns>
        /// <exception cref="ArgumentNullException">Thrown if the batch is null.</exception>
        /// <exception cref="NotSupportedException">Thrown if the Arrow data type is not supported by LeichtFrame.</exception>
        public static DataFrame ToDataFrame(RecordBatch batch)
        {
            if (batch == null) throw new ArgumentNullException(nameof(batch));

            var columns = new List<IColumn>(batch.ColumnCount);
            int rowCount = batch.Length;

            // Iterate over Arrow Arrays (Columns)
            foreach (var field in batch.Schema.FieldsList)
            {
                var arrowArray = batch.Column(field.Name);

                // We use the name from the schema
                string name = field.Name;

                // Conversion based on the Arrow type
                IColumn lfCol = ConvertArray(name, arrowArray, rowCount);
                columns.Add(lfCol);
            }

            return new DataFrame(columns);
        }

        /// <summary>
        /// Converts a LeichtFrame DataFrame into an Apache Arrow RecordBatch.
        /// </summary>
        /// <param name="df">The source DataFrame.</param>
        /// <returns>A new <see cref="RecordBatch"/> containing the data.</returns>
        /// <exception cref="ArgumentNullException">Thrown if the DataFrame is null.</exception>
        /// <exception cref="NotSupportedException">Thrown if a column type cannot be mapped to Arrow.</exception>
        public static RecordBatch ToRecordBatch(DataFrame df)
        {
            if (df == null) throw new ArgumentNullException(nameof(df));

            // 1. Build Arrow Schema
            var builder = new Schema.Builder();
            foreach (var col in df.Columns)
            {
                builder.Field(f => f.Name(col.Name).DataType(GetArrowType(col.DataType)).Nullable(col.IsNullable));
            }
            var arrowSchema = builder.Build();

            // 2. Build Arrow Arrays
            var arrowArrays = new List<IArrowArray>(df.ColumnCount);
            foreach (var col in df.Columns)
            {
                arrowArrays.Add(BuildArrowArray(col));
            }

            // 3. Create Batch
            return new RecordBatch(arrowSchema, arrowArrays, df.RowCount);
        }

        private static IArrowType GetArrowType(Type type)
        {
            if (type == typeof(int)) return Int32Type.Default;
            if (type == typeof(double)) return DoubleType.Default;
            if (type == typeof(bool)) return BooleanType.Default;
            if (type == typeof(string)) return StringType.Default;
            if (type == typeof(DateTime)) return TimestampType.Default;

            throw new NotSupportedException($"Type '{type.Name}' cannot be mapped to Arrow.");
        }

        private static IArrowArray BuildArrowArray(IColumn col)
        {
            if (col is IntColumn ic)
            {
                var builder = new Int32Array.Builder();
                for (int i = 0; i < ic.Length; i++)
                {
                    if (ic.IsNull(i)) builder.AppendNull();
                    else builder.Append(ic.Get(i));
                }
                return builder.Build();
            }

            if (col is DoubleColumn dc)
            {
                var builder = new DoubleArray.Builder();
                for (int i = 0; i < dc.Length; i++)
                {
                    if (dc.IsNull(i)) builder.AppendNull();
                    else builder.Append(dc.Get(i));
                }
                return builder.Build();
            }

            if (col is StringColumn sc)
            {
                var builder = new StringArray.Builder();
                for (int i = 0; i < sc.Length; i++)
                {
                    // StringColumn handles nulls internally in Get() usually, but checking IsNull is safer/consistent
                    if (sc.IsNull(i)) builder.AppendNull();
                    else builder.Append(sc.Get(i));
                }
                return builder.Build();
            }

            if (col is BoolColumn bc)
            {
                var builder = new BooleanArray.Builder();
                for (int i = 0; i < bc.Length; i++)
                {
                    if (bc.IsNull(i)) builder.AppendNull();
                    else builder.Append(bc.Get(i));
                }
                return builder.Build();
            }

            if (col is DateTimeColumn dtc)
            {
                var builder = new TimestampArray.Builder();
                for (int i = 0; i < dtc.Length; i++)
                {
                    if (dtc.IsNull(i)) builder.AppendNull();
                    else
                    {
                        // Arrow prefers DateTimeOffset usually, but creates TimestampArray from it.
                        builder.Append(new DateTimeOffset(dtc.Get(i)));
                    }
                }
                return builder.Build();
            }

            throw new NotSupportedException($"Column type '{col.GetType().Name}' is not supported for Arrow export.");
        }

        private static IColumn ConvertArray(string name, IArrowArray array, int length)
        {
            // 1. Int32
            if (array is Int32Array intArray)
            {
                var col = new IntColumn(name, length, isNullable: true); // Arrow is usually nullable
                for (int i = 0; i < length; i++)
                {
                    if (intArray.IsNull(i)) col.Append(null);
                    else col.Append(intArray.GetValue(i));
                }
                return col;
            }

            // 2. Double
            if (array is DoubleArray doubleArray)
            {
                var col = new DoubleColumn(name, length, isNullable: true);
                for (int i = 0; i < length; i++)
                {
                    if (doubleArray.IsNull(i)) col.Append(null);
                    else col.Append(doubleArray.GetValue(i));
                }
                return col;
            }

            // 3. String
            if (array is StringArray stringArray)
            {
                var col = new StringColumn(name, length, isNullable: true);
                for (int i = 0; i < length; i++)
                {
                    // GetString returns null if null
                    col.Append(stringArray.GetString(i));
                }
                return col;
            }

            // 4. Bool
            if (array is BooleanArray boolArray)
            {
                var col = new BoolColumn(name, length, isNullable: true);
                for (int i = 0; i < length; i++)
                {
                    if (boolArray.IsNull(i)) col.Append(null);
                    else col.Append(boolArray.GetValue(i));
                }
                return col;
            }

            // 5. Date/Timestamp (Arrow has many time types, we support basic Timestamp here)
            if (array is TimestampArray tsArray)
            {
                var col = new DateTimeColumn(name, length, isNullable: true);
                for (int i = 0; i < length; i++)
                {
                    if (tsArray.IsNull(i)) col.Append(null);
                    else
                    {
                        // Arrow Timestamp is usually DateTimeOffset, we take DateTime
                        col.Append(tsArray.GetTimestamp(i)?.DateTime);
                    }
                }
                return col;
            }

            // Fallback for Date32 (Common in Parquet/Arrow)
            if (array is Date32Array date32Array)
            {
                var col = new DateTimeColumn(name, length, isNullable: true);
                for (int i = 0; i < length; i++)
                {
                    if (date32Array.IsNull(i)) col.Append(null);
                    else col.Append(date32Array.GetDateTime(i));
                }
                return col;
            }

            throw new NotSupportedException($"Arrow array type '{array.GetType().Name}' is not supported yet.");
        }
    }
}
===== FILE: src/LeichtFrame.IO/Arrow/ArrowExtensions.cs =====
using Apache.Arrow;
using LeichtFrame.Core;

namespace LeichtFrame.IO
{
    /// <summary>
    /// Provides extension methods for seamless integration with Apache Arrow.
    /// Allows converting <see cref="RecordBatch"/> to <see cref="DataFrame"/> and vice versa via fluent syntax.
    /// </summary>
    public static class ArrowExtensions
    {
        /// <summary>
        /// Converts an Apache Arrow <see cref="RecordBatch"/> directly into a LeichtFrame <see cref="DataFrame"/>.
        /// </summary>
        /// <param name="batch">The source Arrow RecordBatch.</param>
        /// <returns>A new DataFrame containing the data from the batch.</returns>
        /// <exception cref="ArgumentNullException">Thrown if the batch is null.</exception>
        public static DataFrame ToDataFrame(this RecordBatch batch)
        {
            return ArrowConverter.ToDataFrame(batch);
        }

        /// <summary>
        /// Converts the <see cref="DataFrame"/> into an Apache Arrow <see cref="RecordBatch"/>.
        /// Useful for passing data to other libraries like ML.NET, Spark, or Python (via interop).
        /// </summary>
        /// <param name="df">The source DataFrame.</param>
        /// <returns>A new Arrow RecordBatch representing the DataFrame.</returns>
        /// <exception cref="ArgumentNullException">Thrown if the DataFrame is null.</exception>
        public static RecordBatch ToArrow(this DataFrame df)
        {
            return ArrowConverter.ToRecordBatch(df);
        }
    }
}
===== FILE: src/LeichtFrame.IO/Csv/CsvReadOptions.cs =====
using System.Globalization;

namespace LeichtFrame.IO
{
    /// <summary>
    /// Configuration options for reading CSV files.
    /// </summary>
    public class CsvReadOptions
    {
        /// <summary>
        /// Gets or sets the delimiter used to separate fields. Default is ",".
        /// </summary>
        public string Separator { get; set; } = ",";

        /// <summary>
        /// Gets or sets a value indicating whether the first row of the CSV contains column headers. 
        /// Default is <c>true</c>.
        /// </summary>
        public bool HasHeader { get; set; } = true;

        /// <summary>
        /// Gets or sets the culture information used to parse numbers and dates. 
        /// Default is <see cref="CultureInfo.InvariantCulture"/> (dot decimal separator).
        /// </summary>
        public CultureInfo Culture { get; set; } = CultureInfo.InvariantCulture;

        /// <summary>
        /// Gets or sets a specific date format string (e.g. "yyyy-MM-dd").
        /// If null (default), the parser attempts to detect the format automatically based on the Culture.
        /// </summary>
        public string? DateFormat { get; set; } = null;
    }
}
===== FILE: src/LeichtFrame.IO/Csv/CsvReader.cs =====
using System.Globalization;
using System.Text;
using LeichtFrame.Core;

namespace LeichtFrame.IO
{
    /// <summary>
    /// Provides high-performance methods to read CSV files into a <see cref="DataFrame"/>.
    /// Uses parallel processing for full loads and streaming for batched access.
    /// </summary>
    public static class CsvReader
    {
        // =======================================================================
        // STANDARD READ METHODS (Full Load - Parallelized)
        // =======================================================================

        /// <summary>
        /// Reads a CSV file into a DataFrame using parallel processing for maximum speed.
        /// </summary>
        public static DataFrame Read(string path, DataFrameSchema schema, CsvReadOptions? options = null)
        {
            options ??= new CsvReadOptions();

            // We read the file using a StreamReader
            using var reader = new StreamReader(path, Encoding.UTF8, detectEncodingFromByteOrderMarks: true, bufferSize: 65536);

            // Estimate capacity (e.g., 10k rows) to reduce resizing
            var df = DataFrame.Create(schema, capacity: 10000);

            // Cache column info for the parallel loop
            int colCount = df.ColumnCount;
            var columns = new IColumn[colCount];
            var colTypes = new Type[colCount];
            for (int i = 0; i < colCount; i++)
            {
                columns[i] = df.Columns[i];
                colTypes[i] = df.Columns[i].DataType;
            }

            // Skip Header
            if (options.HasHeader && !reader.EndOfStream)
            {
                reader.ReadLine();
            }

            char separator = options.Separator[0];

            // Chunk Size: Number of lines to read before spawning parallel tasks.
            // 50,000 is a good balance between memory usage and thread overhead.
            int chunkSize = 50_000;
            var lineBuffer = new List<string>(chunkSize);

            // 1. Read Loop (IO Bound - Single Thread)
            while (!reader.EndOfStream)
            {
                string? line = reader.ReadLine();
                if (line == null) break;

                lineBuffer.Add(line);

                if (lineBuffer.Count >= chunkSize)
                {
                    ProcessChunkParallel(lineBuffer, columns, colTypes, separator, options);
                    lineBuffer.Clear();
                }
            }

            // Process remainder
            if (lineBuffer.Count > 0)
            {
                ProcessChunkParallel(lineBuffer, columns, colTypes, separator, options);
            }

            return df;
        }

        /// <summary>
        /// Reads a CSV from a stream.
        /// Note: Since streams might not be seekable, we copy this to a temp file or read fully if memory allows.
        /// For this implementation, we simply delegate to the parallel logic if it's a FileStream, 
        /// or fall back to a simpler approach if purely in-memory stream to avoid complexity.
        /// </summary>
        public static DataFrame Read(Stream stream, DataFrameSchema schema, CsvReadOptions? options = null)
        {
            if (stream is FileStream fs)
            {
                // Re-open with the optimized path reader
                return Read(fs.Name, schema, options);
            }

            // Fallback for MemoryStream/NetworkStream: Use ReadBatches logic but aggregate into one DF.
            // This reuses the code from ReadBatches (DRY).
            var batches = ReadBatches(stream, schema, batchSize: 50_000, options).ToList();

            if (batches.Count == 0) return DataFrame.Create(schema, 0);
            if (batches.Count == 1) return batches[0];

            return ReadLegacySequential(stream, schema, options);
        }

        /// <summary>
        /// Fallback sequential reader for non-file streams.
        /// </summary>
        private static DataFrame ReadLegacySequential(Stream stream, DataFrameSchema schema, CsvReadOptions? options)
        {
            options ??= new CsvReadOptions();
            // Important: leaveOpen=true because we don't own the stream here
            using var reader = new StreamReader(stream, Encoding.UTF8, detectEncodingFromByteOrderMarks: true, bufferSize: 65536, leaveOpen: true);

            var df = DataFrame.Create(schema, 100);

            var columns = new IColumn[df.ColumnCount];
            for (int i = 0; i < df.ColumnCount; i++) columns[i] = df.Columns[i];

            if (options.HasHeader && !reader.EndOfStream) reader.ReadLine();

            char sep = options.Separator[0];
            string? line;

            while ((line = reader.ReadLine()) != null)
            {
                var parts = SplitCsvLine(line, sep);
                if (parts.Length < columns.Length) continue;

                for (int i = 0; i < columns.Length; i++)
                {
                    ParseAndAppend(columns[i], parts[i], options);
                }
            }
            return df;
        }

        /// <summary>
        /// Reads a CSV file, automatically inferring the schema.
        /// </summary>
        public static DataFrame Read(string path, CsvReadOptions? options = null)
        {
            var schema = InferSchema(path, options);
            return Read(path, schema, options);
        }

        /// <summary>
        /// Reads a CSV file using a POCO class schema.
        /// </summary>
        public static DataFrame Read<T>(string path, CsvReadOptions? options = null)
        {
            var schema = DataFrameSchema.FromType<T>();
            return Read(path, schema, options);
        }

        /// <summary>
        /// Reads a CSV from a stream using a POCO class schema.
        /// </summary>
        public static DataFrame Read<T>(Stream stream, CsvReadOptions? options = null)
        {
            var schema = DataFrameSchema.FromType<T>();
            return Read(stream, schema, options);
        }

        // =======================================================================
        // BATCHED READ METHODS (Streaming)
        // =======================================================================

        /// <summary>
        /// Reads a CSV file in chunks (batches) to enable processing of files larger than memory.
        /// </summary>
        public static IEnumerable<DataFrame> ReadBatches(string path, DataFrameSchema schema, int batchSize = 1000, CsvReadOptions? options = null)
        {
            using var stream = File.OpenRead(path);
            foreach (var batch in ReadBatches(stream, schema, batchSize, options))
            {
                yield return batch;
            }
        }

        /// <summary>
        /// Reads CSV batches from a stream.
        /// </summary>
        public static IEnumerable<DataFrame> ReadBatches(Stream stream, DataFrameSchema schema, int batchSize, CsvReadOptions? options = null)
        {
            if (batchSize <= 0) throw new ArgumentOutOfRangeException(nameof(batchSize), "Batch size must be greater than 0.");

            options ??= new CsvReadOptions();
            using var reader = new StreamReader(stream, Encoding.UTF8, detectEncodingFromByteOrderMarks: true, bufferSize: 65536, leaveOpen: true);

            if (options.HasHeader && !reader.EndOfStream)
            {
                reader.ReadLine();
            }

            char separator = options.Separator[0];
            int colCount = schema.Columns.Count;

            while (!reader.EndOfStream)
            {
                var batchDf = DataFrame.Create(schema, batchSize);
                var batchColumns = new IColumn[colCount];
                for (int i = 0; i < colCount; i++) batchColumns[i] = batchDf[i];

                int rowsInCurrentBatch = 0;

                while (rowsInCurrentBatch < batchSize && !reader.EndOfStream)
                {
                    var line = reader.ReadLine();
                    if (line == null) break;

                    var parts = SplitCsvLine(line, separator);

                    if (parts.Length < colCount) continue;

                    for (int i = 0; i < colCount; i++)
                    {
                        ParseAndAppend(batchColumns[i], parts[i], options);
                    }

                    rowsInCurrentBatch++;
                }

                if (rowsInCurrentBatch > 0)
                {
                    yield return batchDf;
                }
            }
        }

        // =======================================================================
        // INTERNAL HELPERS & PARALLEL LOGIC
        // =======================================================================

        private static void ProcessChunkParallel(List<string> lines, IColumn[] columns, Type[] types, char separator, CsvReadOptions options)
        {
            int count = lines.Count;
            int colCount = columns.Length;

            // Temp buffer: [RowIndex][ColIndex]
            var parsedRows = new object?[count][];

            // 1. CPU Bound: Parse in Parallel
            Parallel.For(0, count, rowIdx =>
            {
                string line = lines[rowIdx];
                var parts = SplitCsvLine(line, separator);

                parsedRows[rowIdx] = new object?[colCount];

                if (parts.Length >= colCount)
                {
                    for (int c = 0; c < colCount; c++)
                    {
                        parsedRows[rowIdx][c] = ParseValue(types[c], parts[c], options);
                    }
                }
            });

            // 2. Memory Bound: Write sequentially
            for (int r = 0; r < count; r++)
            {
                var rowData = parsedRows[r];
                if (rowData == null || rowData.Length == 0) continue;

                for (int c = 0; c < colCount; c++)
                {
                    columns[c].AppendObject(rowData[c]);
                }
            }
        }

        private static void ParseAndAppend(IColumn col, string raw, CsvReadOptions options)
        {
            // Re-introduced helper for sequential scenarios
            object? val = ParseValue(col.DataType, raw, options);
            col.AppendObject(val);
        }

        private static object? ParseValue(Type targetType, string raw, CsvReadOptions options)
        {
            if (string.IsNullOrEmpty(raw)) return null;

            if (targetType == typeof(int))
            {
                if (int.TryParse(raw, NumberStyles.Integer, options.Culture, out int result)) return result;
                return null;
            }
            if (targetType == typeof(double))
            {
                if (double.TryParse(raw, NumberStyles.Float | NumberStyles.AllowThousands, options.Culture, out double result)) return result;
                return null;
            }
            if (targetType == typeof(bool))
            {
                if (bool.TryParse(raw, out bool bResult)) return bResult;
                return raw == "1";
            }
            if (targetType == typeof(DateTime))
            {
                if (options.DateFormat != null)
                {
                    if (DateTime.TryParseExact(raw, options.DateFormat, options.Culture, DateTimeStyles.None, out DateTime dtResult))
                        return dtResult;
                }
                else
                {
                    if (DateTime.TryParse(raw, options.Culture, DateTimeStyles.None, out DateTime dtResult))
                        return dtResult;
                }
                return null;
            }
            return raw;
        }

        /// <summary>
        /// Scans the CSV file to infer the schema (column names and types).
        /// </summary>
        public static DataFrameSchema InferSchema(string path, CsvReadOptions? options = null, int sampleRows = 100)
        {
            options ??= new CsvReadOptions();
            using var reader = new StreamReader(File.OpenRead(path));

            string? line = reader.ReadLine();
            if (line == null) throw new IOException("File is empty.");

            char sep = options.Separator[0];
            string[] headers;

            if (options.HasHeader)
            {
                headers = SplitCsvLine(line, sep);
            }
            else
            {
                var firstLineParts = SplitCsvLine(line, sep);
                headers = new string[firstLineParts.Length];
                for (int i = 0; i < headers.Length; i++) headers[i] = $"Column{i}";

                reader.DiscardBufferedData();
                reader.BaseStream.Seek(0, SeekOrigin.Begin);
            }

            var colTypes = new Type[headers.Length];
            var colNullable = new bool[headers.Length];

            int readCount = 0;
            while (readCount < sampleRows && (line = reader.ReadLine()) != null)
            {
                var parts = SplitCsvLine(line, sep);
                if (parts.Length < headers.Length) continue;

                for (int i = 0; i < headers.Length; i++)
                {
                    string val = parts[i];
                    if (string.IsNullOrEmpty(val))
                    {
                        colNullable[i] = true;
                        continue;
                    }
                    Type cellType = DetectType(val, options);
                    colTypes[i] = MergeTypes(colTypes[i], cellType);
                }
                readCount++;
            }

            var definitions = new System.Collections.Generic.List<ColumnDefinition>();
            for (int i = 0; i < headers.Length; i++)
            {
                Type finalType = colTypes[i] ?? typeof(string);
                definitions.Add(new ColumnDefinition(headers[i], finalType, colNullable[i]));
            }

            return new DataFrameSchema(definitions);
        }

        private static string[] SplitCsvLine(string line, char separator)
        {
            var values = new System.Collections.Generic.List<string>();
            int start = 0;
            bool inQuotes = false;

            for (int i = 0; i < line.Length; i++)
            {
                char c = line[i];

                if (c == '\"') inQuotes = !inQuotes;
                else if (c == separator && !inQuotes)
                {
                    values.Add(Unescape(line.Substring(start, i - start)));
                    start = i + 1;
                }
            }

            if (start <= line.Length)
            {
                values.Add(Unescape(line.Substring(start)));
            }

            return values.ToArray();
        }

        private static string Unescape(string value)
        {
            if (string.IsNullOrEmpty(value)) return value;
            if (value.StartsWith("\"") && value.EndsWith("\"") && value.Length >= 2)
            {
                value = value.Substring(1, value.Length - 2);
                return value.Replace("\"\"", "\"");
            }
            return value;
        }

        private static Type DetectType(string val, CsvReadOptions options)
        {
            if (int.TryParse(val, NumberStyles.Integer, options.Culture, out _)) return typeof(int);
            if (double.TryParse(val, NumberStyles.Float | NumberStyles.AllowThousands, options.Culture, out _)) return typeof(double);
            if (bool.TryParse(val, out _)) return typeof(bool);
            if (DateTime.TryParse(val, options.Culture, DateTimeStyles.None, out _)) return typeof(DateTime);
            return typeof(string);
        }

        private static Type MergeTypes(Type? current, Type newType)
        {
            if (current == null) return newType;
            if (current == newType) return current;
            if ((current == typeof(int) && newType == typeof(double)) ||
                (current == typeof(double) && newType == typeof(int)))
                return typeof(double);
            return typeof(string);
        }
    }
}
===== FILE: src/LeichtFrame.IO/Csv/CsvWriteOptions.cs =====
using System.Globalization;

namespace LeichtFrame.IO
{
    /// <summary>
    /// Configuration options for writing CSV files.
    /// </summary>
    public class CsvWriteOptions
    {
        /// <summary>
        /// Gets or sets the delimiter used to separate fields. Default is ",".
        /// </summary>
        public string Separator { get; set; } = ",";

        /// <summary>
        /// Gets or sets a value indicating whether to write column names as the first row. 
        /// Default is <c>true</c>.
        /// </summary>
        public bool WriteHeader { get; set; } = true;

        /// <summary>
        /// Gets or sets the culture information used to format numbers and dates.
        /// Default is <see cref="CultureInfo.InvariantCulture"/> (dot decimal separator) to ensure compatibility.
        /// </summary>
        public CultureInfo Culture { get; set; } = CultureInfo.InvariantCulture;

        /// <summary>
        /// Gets or sets the format string for <see cref="DateTime"/> values.
        /// Default is "o" (ISO 8601 round-trip pattern), which is the safest standard for machine processing.
        /// </summary>
        public string DateFormat { get; set; } = "o";

        /// <summary>
        /// Gets or sets the string representation for null values. 
        /// Default is an empty string.
        /// </summary>
        public string NullValue { get; set; } = "";
    }
}
===== FILE: src/LeichtFrame.IO/Csv/CsvWriter.cs =====
using System.Text;
using LeichtFrame.Core;

namespace LeichtFrame.IO
{
    /// <summary>
    /// Provides methods for writing <see cref="DataFrame"/> content to CSV format.
    /// Handles proper escaping (RFC 4180) and formatting based on configurable options.
    /// </summary>
    public static class CsvWriter
    {
        /// <summary>
        /// Writes the DataFrame to a CSV file at the specified path.
        /// Overwrites the file if it already exists.
        /// </summary>
        /// <param name="df">The DataFrame to write.</param>
        /// <param name="path">The full file path.</param>
        /// <param name="options">Optional formatting options (separator, date format, etc.).</param>
        public static void Write(DataFrame df, string path, CsvWriteOptions? options = null)
        {
            // File.Create overrides existing files
            using var stream = File.Create(path);
            Write(df, stream, options);
        }

        /// <summary>
        /// Writes the DataFrame to a stream in CSV format.
        /// </summary>
        /// <param name="df">The DataFrame to write.</param>
        /// <param name="stream">The output stream (must be writable).</param>
        /// <param name="options">Optional formatting options.</param>
        public static void Write(DataFrame df, Stream stream, CsvWriteOptions? options = null)
        {
            options ??= new CsvWriteOptions();

            // UTF8 without BOM is the standard nowadays, let the stream decide or enforce it
            using var writer = new StreamWriter(stream, new UTF8Encoding(false), 1024, leaveOpen: true);

            // 1. Write Header
            if (options.WriteHeader)
            {
                // Uses the API from B.5.2
                var headers = df.GetColumnNames();
                writer.WriteLine(string.Join(options.Separator, headers));
            }

            // 2. Write Rows
            var sb = new StringBuilder();

            for (int i = 0; i < df.RowCount; i++)
            {
                sb.Clear();
                for (int c = 0; c < df.ColumnCount; c++)
                {
                    if (c > 0) sb.Append(options.Separator);

                    var col = df[c];
                    // Untyped access (GetValue) is okay here since IO is the bottleneck anyway
                    object? val = col.GetValue(i);

                    string valStr = FormatValue(val, options);

                    // CSV Escaping (RFC 4180): 
                    // If separator, quote, or newline are present -> enclose text in quotes
                    if (NeedsEscaping(valStr, options.Separator))
                    {
                        // Escape double quotes (" -> "")
                        valStr = "\"" + valStr.Replace("\"", "\"\"") + "\"";
                    }

                    sb.Append(valStr);
                }
                writer.WriteLine(sb.ToString());
            }

            writer.Flush();
        }

        private static bool NeedsEscaping(string val, string separator)
        {
            // Performance check: Contains any of the critical characters?
            return val.Contains(separator) || val.Contains("\"") || val.Contains("\n") || val.Contains("\r");
        }

        private static string FormatValue(object? val, CsvWriteOptions options)
        {
            if (val == null) return options.NullValue;

            if (val is DateTime dt)
            {
                return dt.ToString(options.DateFormat, options.Culture);
            }
            if (val is bool b)
            {
                // Lowercase (true/false) or C# standard (True/False)? 
                // C# ToString() produces "True", JSON/JS prefers "true". We stick to C# standard for consistency.
                return b.ToString(options.Culture);
            }
            if (val is IFormattable formattable)
            {
                return formattable.ToString(null, options.Culture);
            }

            return val.ToString() ?? "";
        }
    }
}
===== FILE: src/LeichtFrame.IO/Csv/DataFrameCsvExtensions.cs =====
using System.Globalization;
using System.Text;
using LeichtFrame.Core;

namespace LeichtFrame.IO
{
    /// <summary>
    /// Provides extension methods for importing and exporting <see cref="DataFrame"/> objects via CSV.
    /// </summary>
    public static class DataFrameCsvExtensions
    {
        // =========================================================
        // WRITE EXTENSIONS (Export)
        // =========================================================

        /// <summary>
        /// Writes the DataFrame to a CSV file at the specified path.
        /// </summary>
        /// <param name="df">The source DataFrame.</param>
        /// <param name="path">The full path to the output file. Will be overwritten if it exists.</param>
        /// <param name="options">Optional configuration for writing (separator, date format, etc.).</param>
        public static void WriteCsv(this DataFrame df, string path, CsvWriteOptions? options = null)
        {
            CsvWriter.Write(df, path, options);
        }

        /// <summary>
        /// Writes the DataFrame to a stream in CSV format.
        /// </summary>
        /// <param name="df">The source DataFrame.</param>
        /// <param name="stream">The output stream.</param>
        /// <param name="options">Optional configuration for writing.</param>
        public static void WriteCsv(this DataFrame df, Stream stream, CsvWriteOptions? options = null)
        {
            CsvWriter.Write(df, stream, options);
        }

        // =========================================================
        // READ EXTENSIONS (Import)
        // =========================================================

        /// <summary>
        /// Reads a CSV file from a given path using a specific schema.
        /// </summary>
        /// <param name="path">The file path to the CSV.</param>
        /// <param name="schema">The schema definition describing column names and types.</param>
        /// <param name="hasHeader">Indicates if the first row contains column headers.</param>
        /// <param name="separator">The character used to separate fields.</param>
        /// <returns>A populated <see cref="DataFrame"/>.</returns>
        public static DataFrame ReadCsv(string path, DataFrameSchema schema, bool hasHeader = true, char separator = ',')
        {
            using var stream = File.OpenRead(path);
            return ReadCsv(stream, schema, hasHeader, separator);
        }

        /// <summary>
        /// Reads a CSV from a stream using a specific schema.
        /// </summary>
        /// <param name="stream">The input stream containing CSV data.</param>
        /// <param name="schema">The schema definition describing column names and types.</param>
        /// <param name="hasHeader">Indicates if the first row contains column headers.</param>
        /// <param name="separator">The character used to separate fields.</param>
        /// <returns>A populated <see cref="DataFrame"/>.</returns>
        /// <exception cref="ArgumentNullException">Thrown if stream or schema is null.</exception>
        public static DataFrame ReadCsv(Stream stream, DataFrameSchema schema, bool hasHeader = true, char separator = ',')
        {
            if (stream == null) throw new ArgumentNullException(nameof(stream));
            if (schema == null) throw new ArgumentNullException(nameof(schema));

            // Estimate row count roughly to minimize resizing (Performance optimization).
            // Assumption: approx. 100 bytes per row. Better than starting at capacity 0.
            int estimatedRows = (int)(stream.Length / 100);
            if (estimatedRows < 16) estimatedRows = 16;

            // 1. Create DataFrame (with schema and estimated capacity).
            var df = DataFrame.Create(schema, estimatedRows);

            using var reader = new StreamReader(stream, Encoding.UTF8, detectEncodingFromByteOrderMarks: true, bufferSize: 65536);

            // 2. Skip Header if present
            if (hasHeader && !reader.EndOfStream)
            {
                reader.ReadLine();
            }

            // Cache columns to avoid dictionary lookup per row
            var columns = df.Columns;
            int colCount = columns.Count;

            // 3. Read and parse lines
            while (!reader.EndOfStream)
            {
                var line = reader.ReadLine();
                if (string.IsNullOrWhiteSpace(line)) continue;

                var parts = line.Split(separator);

                // Strict schema check: Ignore lines with fewer columns than schema
                if (parts.Length < colCount) continue;

                for (int i = 0; i < colCount; i++)
                {
                    string rawValue = parts[i];
                    var col = columns[i];

                    try
                    {
                        ParseAndAppend(col, rawValue);
                    }
                    catch
                    {
                        // Fallback on parse error: Append null or default
                        if (col.IsNullable)
                        {
                            col.AppendObject(null);
                        }
                        else
                        {
                            col.AppendObject(GetDefault(col.DataType));
                        }
                    }
                }
            }

            return df;
        }

        // =========================================================
        // INTERNAL HELPERS
        // =========================================================

        private static void ParseAndAppend(IColumn col, string rawValue)
        {
            Type targetType = col.DataType;

            // Handle Nulls
            if (string.IsNullOrEmpty(rawValue))
            {
                if (col.IsNullable)
                {
                    col.AppendObject(null);
                    return;
                }
            }

            // Parsing Logic (Always use InvariantCulture for data interchange!)
            if (targetType == typeof(int))
            {
                if (int.TryParse(rawValue, NumberStyles.Any, CultureInfo.InvariantCulture, out int result))
                    col.AppendObject(result);
                else
                    col.AppendObject(GetDefault(typeof(int))); // Fallback
            }
            else if (targetType == typeof(double))
            {
                if (double.TryParse(rawValue, NumberStyles.Any, CultureInfo.InvariantCulture, out double result))
                    col.AppendObject(result);
                else
                    col.AppendObject(GetDefault(typeof(double)));
            }
            else if (targetType == typeof(bool))
            {
                if (bool.TryParse(rawValue, out bool result))
                    col.AppendObject(result);
                else
                    col.AppendObject(false);
            }
            else if (targetType == typeof(string))
            {
                col.AppendObject(rawValue);
            }
            else if (targetType == typeof(DateTime))
            {
                if (DateTime.TryParse(rawValue, CultureInfo.InvariantCulture, DateTimeStyles.None, out DateTime result))
                    col.AppendObject(result);
                else
                    col.AppendObject(GetDefault(typeof(DateTime)));
            }
            else
            {
                // General Fallback
                try
                {
                    col.AppendObject(Convert.ChangeType(rawValue, targetType, CultureInfo.InvariantCulture));
                }
                catch
                {
                    col.AppendObject(GetDefault(targetType));
                }
            }
        }

        private static object? GetDefault(Type type)
        {
            if (type.IsValueType)
            {
                return Activator.CreateInstance(type);
            }
            return null;
        }
    }
}
===== FILE: src/LeichtFrame.IO/LeichtFrame.IO.csproj =====
Ôªø<Project Sdk="Microsoft.NET.Sdk">

  <ItemGroup>
    <ProjectReference Include="..\LeichtFrame.Core\LeichtFrame.Core.csproj" />
  </ItemGroup>

  <ItemGroup>
    <PackageReference Include="Apache.Arrow" Version="22.1.0" />
    <PackageReference Include="Parquet.Net" Version="5.4.0" />
  </ItemGroup>

  <PropertyGroup>
    <TargetFramework>net8.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
  </PropertyGroup>

</Project>

===== FILE: src/LeichtFrame.IO/Parquet/DataFrameParquetExtensions.cs =====
using LeichtFrame.Core;

namespace LeichtFrame.IO
{
    /// <summary>
    /// Provides extension methods for exporting <see cref="DataFrame"/> objects to Apache Parquet format.
    /// </summary>
    public static class DataFrameParquetExtensions
    {
        /// <summary>
        /// Writes the DataFrame to a Parquet file at the specified path.
        /// </summary>
        /// <param name="df">The source DataFrame to export.</param>
        /// <param name="path">The file path where the Parquet file will be created or overwritten.</param>
        public static void WriteParquet(this DataFrame df, string path)
        {
            ParquetWriter.Write(df, path);
        }

        /// <summary>
        /// Writes the DataFrame to a stream in Parquet format.
        /// </summary>
        /// <param name="df">The source DataFrame to export.</param>
        /// <param name="stream">The writable output stream.</param>
        public static void WriteParquet(this DataFrame df, Stream stream)
        {
            ParquetWriter.Write(df, stream);
        }

        /// <summary>
        /// Writes the DataFrame to a stream asynchronously in Parquet format.
        /// Recommended for Web APIs to avoid blocking threads during I/O.
        /// </summary>
        /// <param name="df">The source DataFrame to export.</param>
        /// <param name="stream">The writable output stream.</param>
        /// <returns>A task that represents the asynchronous write operation.</returns>
        public static Task WriteParquetAsync(this DataFrame df, Stream stream)
        {
            return ParquetWriter.WriteAsync(df, stream);
        }
    }
}
===== FILE: src/LeichtFrame.IO/Parquet/ParquetReader.cs =====
using LeichtFrame.Core;
using Parquet.Schema;
using Parquet;

namespace LeichtFrame.IO
{
    /// <summary>
    /// Provides high-performance methods to read Apache Parquet files into a <see cref="DataFrame"/>.
    /// Automatically maps Parquet schema types to LeichtFrame column types.
    /// Supports both full-load and batched streaming (RowGroup-based).
    /// </summary>
    public static class ParquetReader
    {
        // =======================================================================
        // STANDARD READ METHODS (Full Load)
        // =======================================================================

        /// <summary>
        /// Reads a Parquet file from the specified file path.
        /// </summary>
        /// <param name="path">The full path to the Parquet file.</param>
        /// <returns>A populated <see cref="DataFrame"/> containing all data.</returns>
        public static DataFrame Read(string path)
        {
            using var stream = File.OpenRead(path);
            return Read(stream);
        }

        /// <summary>
        /// Reads a Parquet file from a stream synchronously.
        /// </summary>
        /// <param name="stream">The input stream containing Parquet data.</param>
        /// <returns>A populated <see cref="DataFrame"/>.</returns>
        public static DataFrame Read(Stream stream)
        {
            // Synchronous Wrapper for the Async method
            return ReadAsync(stream).GetAwaiter().GetResult();
        }

        /// <summary>
        /// Reads a Parquet file from a stream asynchronously.
        /// Recommended for I/O-bound operations in Web APIs to avoid blocking threads.
        /// </summary>
        /// <param name="stream">The input stream containing Parquet data.</param>
        /// <returns>A task that represents the asynchronous read operation, containing the resulting <see cref="DataFrame"/>.</returns>
        public static async Task<DataFrame> ReadAsync(Stream stream)
        {
            using var reader = await Parquet.ParquetReader.CreateAsync(stream);

            // 1. Schema Mapping (Parquet -> LeichtFrame)
            var dataFields = reader.Schema.GetDataFields();
            var colDefs = dataFields.Select(f => MapToColumnDefinition(f));
            var schema = new DataFrameSchema(colDefs);

            // 2. Create DataFrame
            // We start with a capacity estimate. Parquet has metadata for total rows, but reader.ThriftMetadata might be internal.
            // Safe default.
            var df = DataFrame.Create(schema, capacity: 1000);

            // 3. Read Data (RowGroup by RowGroup)
            for (int i = 0; i < reader.RowGroupCount; i++)
            {
                using var groupReader = reader.OpenRowGroupReader(i);

                foreach (var field in dataFields)
                {
                    var column = df[field.Name];

                    // Reads the entire column of this RowGroup as an array
                    var parquetColumn = await groupReader.ReadColumnAsync(field);

                    // 4. Copy Data to LeichtFrame Column
                    AppendData(column, parquetColumn.Data);
                }
            }

            return df;
        }

        // =======================================================================
        // BATCHED READ METHODS (Streaming)
        // =======================================================================

        /// <summary>
        /// Reads a Parquet file in batches, mapping 1 Parquet RowGroup to 1 DataFrame.
        /// This allows processing files larger than available memory.
        /// </summary>
        /// <param name="path">The file path.</param>
        /// <returns>An enumerable of DataFrames.</returns>
        public static IEnumerable<DataFrame> ReadBatches(string path)
        {
            using var stream = File.OpenRead(path);
            foreach (var batch in ReadBatches(stream))
            {
                yield return batch;
            }
        }

        /// <summary>
        /// Reads Parquet batches from a stream synchronously.
        /// Note: This performs blocking calls on the underlying async Parquet library.
        /// </summary>
        /// <param name="stream">The input stream.</param>
        /// <returns>An enumerable of DataFrames.</returns>
        public static IEnumerable<DataFrame> ReadBatches(Stream stream)
        {
            // 1. Open Reader (Blocking wait)
            var task = Parquet.ParquetReader.CreateAsync(stream);
            task.Wait();
            using var reader = task.Result;

            // 2. Schema Mapping
            var dataFields = reader.Schema.GetDataFields();
            var colDefs = dataFields.Select(f => MapToColumnDefinition(f));
            var schema = new DataFrameSchema(colDefs);

            // 3. Iterate RowGroups
            for (int i = 0; i < reader.RowGroupCount; i++)
            {
                using var groupReader = reader.OpenRowGroupReader(i);

                // If RowGroup is empty, we skip or produce empty DF. Parquet usually doesn't store empty groups.
                long groupRowCount = groupReader.RowCount;

                // Create a fresh DataFrame for this batch
                var batchDf = DataFrame.Create(schema, (int)groupRowCount);

                // Read all columns for this group
                foreach (var field in dataFields)
                {
                    var column = batchDf[field.Name];

                    // Read Column Data (Blocking wait)
                    var readTask = groupReader.ReadColumnAsync(field);
                    readTask.Wait();
                    var parquetColumn = readTask.Result;

                    AppendData(column, parquetColumn.Data);
                }

                yield return batchDf;
            }
        }

        // =======================================================================
        // INTERNAL HELPERS
        // =======================================================================

        private static ColumnDefinition MapToColumnDefinition(DataField field)
        {
            // Mapping Parquet Types -> .NET Types
            Type targetType = field.ClrNullableIfHasNullsType;

            // We want the core type for LeichtFrame (int instead of int?) + IsNullable flag
            Type coreType = Nullable.GetUnderlyingType(targetType) ?? targetType;
            bool isNullable = field.IsNullable || targetType.IsGenericType; // rough rule

            // Support Check
            if (coreType != typeof(int) && coreType != typeof(double) &&
                coreType != typeof(string) && coreType != typeof(bool) &&
                coreType != typeof(DateTime))
            {
                // Fallback for types not strictly typed in our system
                throw new NotSupportedException($"Parquet type '{coreType.Name}' for column '{field.Name}' is not supported yet.");
            }

            return new ColumnDefinition(field.Name, coreType, isNullable);
        }

        private static void AppendData(IColumn col, Array data)
        {
            // The array from Parquet.Net is typed (e.g., int[] or int?[])
            // We iterate and append.

            if (col is IntColumn ic)
            {
                foreach (var item in data) ic.Append((int?)item);
            }
            else if (col is DoubleColumn dc)
            {
                foreach (var item in data) dc.Append((double?)item);
            }
            else if (col is StringColumn sc)
            {
                foreach (var item in data) sc.Append((string?)item);
            }
            else if (col is BoolColumn bc)
            {
                foreach (var item in data) bc.Append((bool?)item);
            }
            else if (col is DateTimeColumn dtc)
            {
                foreach (var item in data) dtc.Append((DateTime?)item);
            }
        }
    }
}
===== FILE: src/LeichtFrame.IO/Parquet/ParquetWriter.cs =====
using LeichtFrame.Core;
using Parquet.Data;
using Parquet.Schema;

namespace LeichtFrame.IO
{
    /// <summary>
    /// Provides methods for writing <see cref="DataFrame"/> objects into Apache Parquet format.
    /// Handles schema mapping and efficient data conversion for storage.
    /// </summary>
    public static class ParquetWriter
    {
        /// <summary>
        /// Writes the DataFrame to a Parquet file at the specified path.
        /// If the file exists, it will be overwritten.
        /// </summary>
        /// <param name="df">The source DataFrame.</param>
        /// <param name="path">The output file path.</param>
        public static void Write(DataFrame df, string path)
        {
            // Allow overwrite
            using var stream = File.Create(path);
            Write(df, stream);
        }

        /// <summary>
        /// Writes the DataFrame to a stream in Parquet format synchronously.
        /// </summary>
        /// <param name="df">The source DataFrame.</param>
        /// <param name="stream">The writable output stream.</param>
        public static void Write(DataFrame df, Stream stream)
        {
            // Synchronous Wrapper
            WriteAsync(df, stream).GetAwaiter().GetResult();
        }

        /// <summary>
        /// Writes the DataFrame to a stream in Parquet format asynchronously.
        /// </summary>
        /// <param name="df">The source DataFrame.</param>
        /// <param name="stream">The writable output stream.</param>
        /// <returns>A task representing the asynchronous write operation.</returns>
        public static async Task WriteAsync(DataFrame df, Stream stream)
        {
            // 1. Schema Mapping (LeichtFrame -> Parquet)
            var dataFields = df.Schema.Columns.Select(MapToDataField).ToArray();
            var parquetSchema = new ParquetSchema(dataFields);

            // 2. Writer Setup
            using var writer = await Parquet.ParquetWriter.CreateAsync(parquetSchema, stream);

            // We write everything in one RowGroup (simplest solution for MVP)
            using var groupWriter = writer.CreateRowGroup();

            // 3. Column Data Conversion & Write
            for (int i = 0; i < df.ColumnCount; i++)
            {
                var col = df.Columns[i];
                var field = dataFields[i];

                // Data conversion (NullBitmap -> Nullable Array)
                Array data = ConvertToParquetArray(col);

                var dataColumn = new DataColumn(field, data);
                await groupWriter.WriteColumnAsync(dataColumn);
            }
        }

        private static DataField MapToDataField(ColumnDefinition def)
        {
            // Int -> Int32, Nullable handling via Type?
            Type t = def.DataType;
            if (def.IsNullable && t.IsValueType)
            {
                t = typeof(Nullable<>).MakeGenericType(t);
            }
            return new DataField(def.Name, t);
        }

        private static Array ConvertToParquetArray(IColumn col)
        {
            // Fast Path: If not nullable and primitive, we might be able to use the array directly?
            // Unfortunately, Values.Span does not return the array, and Parquet.Net requires an Array.
            // We usually have to copy to be safe (snapshot).

            if (col is IntColumn ic)
            {
                if (!ic.IsNullable) return ic.Values.ToArray(); // int[]

                // Nullable Conversion: int[] + bitmap -> int?[]
                var result = new int?[ic.Length];
                for (int i = 0; i < ic.Length; i++)
                    result[i] = ic.IsNull(i) ? null : ic.Get(i);
                return result;
            }

            if (col is DoubleColumn dc)
            {
                if (!dc.IsNullable) return dc.Values.ToArray();

                var result = new double?[dc.Length];
                for (int i = 0; i < dc.Length; i++)
                    result[i] = dc.IsNull(i) ? null : dc.Get(i);
                return result;
            }

            if (col is BoolColumn bc)
            {
                // BoolColumn is bit-packed internally. We need to unpack to bool[] or bool?[]
                if (!bc.IsNullable)
                {
                    var result = new bool[bc.Length];
                    for (int i = 0; i < bc.Length; i++) result[i] = bc.Get(i);
                    return result;
                }
                else
                {
                    var result = new bool?[bc.Length];
                    for (int i = 0; i < bc.Length; i++)
                        result[i] = bc.IsNull(i) ? null : bc.Get(i);
                    return result;
                }
            }

            if (col is StringColumn sc)
            {
                var result = new string?[sc.Length];
                for (int i = 0; i < sc.Length; i++)
                {
                    result[i] = sc.Get(i);
                }
                return result;
            }

            if (col is DateTimeColumn dtc)
            {
                if (!dtc.IsNullable) return dtc.Values.ToArray();

                var result = new DateTime?[dtc.Length];
                for (int i = 0; i < dtc.Length; i++)
                    result[i] = dtc.IsNull(i) ? null : dtc.Get(i);
                return result;
            }

            throw new NotSupportedException($"Writing column type '{col.DataType.Name}' to Parquet is not supported.");
        }
    }
}
===== FILE: tests/LeichtFrame.Core.Tests/Columns/BoolColumnTests.cs =====
namespace LeichtFrame.Core.Tests.Columns
{
    public class BoolColumnTests
    {
        [Fact]
        public void BitPacking_Works_Across_ByteBoundaries()
        {
            // Capacity 16 = 2 Bytes
            using var col = new BoolColumn("Bits", 16);

            // Set index 0, 7 (Byte 0 ends), 8 (Byte 1 starts)
            for (int i = 0; i < 10; i++) col.Append(false);

            col.SetValue(0, true);
            col.SetValue(7, true);
            col.SetValue(8, true);

            Assert.True(col.Get(0));
            Assert.True(col.Get(7));
            Assert.True(col.Get(8));

            Assert.False(col.Get(1));
            Assert.False(col.Get(6));
            Assert.False(col.Get(9));
        }

        [Fact]
        public void AnyTrue_And_AllTrue_Logic()
        {
            using var col = new BoolColumn("Logic", 100);

            // 1. Empty/All False
            col.Append(false);
            col.Append(false);
            Assert.False(col.AnyTrue());
            Assert.False(col.AllTrue());

            // 2. Set one true
            col.SetValue(0, true);
            Assert.True(col.AnyTrue());
            Assert.False(col.AllTrue());

            // 3. Set all true
            col.SetValue(1, true);
            Assert.True(col.AllTrue());
        }

        [Fact]
        public void Logic_Ignores_Nulls()
        {
            using var col = new BoolColumn("NullLogic", 10, isNullable: true);

            col.Append(true);
            col.Append((bool?)null); // Should be ignored

            Assert.True(col.AllTrue()); // True because the only valid value is true
            Assert.True(col.AnyTrue());

            col.Append(false);
            Assert.False(col.AllTrue()); // Now we have a false
        }

        [Fact]
        public void Values_Property_Throws_Exception()
        {
            using var col = new BoolColumn("NoSlice", 10);
            Assert.Throws<NotSupportedException>(() => _ = col.Values);
        }

        [Fact]
        public void Resizing_Preserves_Bits()
        {
            using var col = new BoolColumn("Resize", 8); // 1 Byte
            for (int i = 0; i < 8; i++) col.Append(true); // Fill byte with 1s (255)

            col.Append(false); // Trigger resize to 2nd byte

            Assert.Equal(9, col.Length);
            Assert.True(col.Get(0));
            Assert.True(col.Get(7));
            Assert.False(col.Get(8));
        }
    }
}
===== FILE: tests/LeichtFrame.Core.Tests/Columns/ColumnFactoryTests.cs =====
using LeichtFrame.Core;


public class ColumnFactoryTests
{
    [Fact]
    public void Create_WithIntType_ReturnsIntColumn()
    {
        var col = ColumnFactory.Create("age", typeof(int), capacity: 32);
        Assert.NotNull(col);
        Assert.IsType<IntColumn>(col);
        Assert.Equal("age", col.Name);
        Assert.Equal(typeof(int), col.DataType);
    }

    [Fact]
    public void Create_GenericInt_Returns_IColumnOfInt()
    {
        var col = ColumnFactory.Create<int>("age", capacity: 16);
        Assert.NotNull(col);
        Assert.IsAssignableFrom<IColumn<int>>(col);
        Assert.Equal("age", col.Name);
        Assert.Equal(typeof(int), col.DataType);
    }

    [Fact]
    public void Create_UnsupportedType_Throws()
    {
        Assert.Throws<NotSupportedException>(() =>
        {
            ColumnFactory.Create("obj", typeof(DateTimeOffset), capacity: 4);
        });
    }
}

===== FILE: tests/LeichtFrame.Core.Tests/Columns/ColumnTests.cs =====
using LeichtFrame.Core.Tests.Mocks;

namespace LeichtFrame.Core.Tests;

public class ColumnTests
{
    [Fact]
    public void Column_Should_Have_Correct_Metadata()
    {
        // Arrange
        var col = new SimpleMockColumn<int>("Age", 10);

        // Assert
        Assert.Equal("Age", col.Name);
        Assert.Equal(typeof(int), col.DataType);
        Assert.Equal(10, col.Length);
    }

    [Fact]
    public void Column_Should_Throw_On_Invalid_Name()
    {
        Assert.Throws<ArgumentException>(() => new SimpleMockColumn<int>("", 10));
        Assert.Throws<ArgumentException>(() => new SimpleMockColumn<int>(null!, 10));
    }

    [Fact]
    public void Column_Get_Set_Values_Work()
    {
        // Arrange
        var col = new SimpleMockColumn<int>("Id", 5);

        // Act
        col.SetValue(0, 42);
        col.SetValue(2, 100);

        // Assert
        Assert.Equal(42, col.Get(0));
        Assert.Equal(0, col.Get(1));
        Assert.Equal(100, col.Get(2));
    }

    [Fact]
    public void Column_Null_Handling_Works()
    {
        // Arrange
        var col = new SimpleMockColumn<string>("Names", 3);

        // Act
        col.SetValue(0, "Alice");
        col.SetNull(1);

        // Assert
        Assert.False(col.IsNull(0));
        Assert.True(col.IsNull(1));
    }
}
===== FILE: tests/LeichtFrame.Core.Tests/Columns/DateColumnTests.cs =====
namespace LeichtFrame.Core.Tests.Columns
{
    public class DateTimeColumnTests
    {
        [Fact]
        public void Basic_Roundtrip_Works()
        {
            using var col = new DateTimeColumn("Dates", 10);
            var now = DateTime.Now;
            var tomorrow = now.AddDays(1);

            col.Append(now);
            col.Append(tomorrow);

            Assert.Equal(2, col.Length);
            Assert.Equal(now, col.Get(0));
            Assert.Equal(tomorrow, col.Get(1));
        }

        [Fact]
        public void Nullable_Support_Works()
        {
            using var col = new DateTimeColumn("NullableDates", 10, isNullable: true);
            var now = DateTime.UtcNow;

            col.Append(now);
            col.Append((DateTime?)null);

            Assert.False(col.IsNull(0));
            Assert.True(col.IsNull(1));

            Assert.Equal(default(DateTime), col.Get(1));
        }

        [Fact]
        public void Resizing_Preserves_Data()
        {
            using var col = new DateTimeColumn("Resize", 2);
            col.Append(new DateTime(2023, 1, 1));
            col.Append(new DateTime(2023, 1, 2));
            col.Append(new DateTime(2023, 1, 3));

            Assert.Equal(3, col.Length);
            Assert.Equal(new DateTime(2023, 1, 3), col.Get(2));
        }

        [Fact]
        public void NonNullable_Throws_On_Null()
        {
            using var col = new DateTimeColumn("Strict", 5, isNullable: false);

            Assert.Throws<InvalidOperationException>(() => col.Append((DateTime?)null));

            col.Append(DateTime.Now);
            Assert.Throws<InvalidOperationException>(() => col.SetNull(0));
        }
    }
}
===== FILE: tests/LeichtFrame.Core.Tests/Columns/DoubleColumnTests.cs =====
namespace LeichtFrame.Core.Tests.Columns
{
    public class DoubleColumnTests
    {
        [Fact]
        public void Statistical_Helpers_Ignore_Nulls()
        {
            using var col = new DoubleColumn("Stats", 10, isNullable: true);
            col.Append(10.0);
            col.Append(20.0);
            col.Append((double?)null);
            col.Append(5.0);

            Assert.Equal(35.0, col.Sum());
            Assert.Equal(5.0, col.Min());
            Assert.Equal(20.0, col.Max());
        }

        [Fact]
        public void NaN_Distinction_Works()
        {
            // Requirement: NaN = actual NaN, Null = bitmap
            using var col = new DoubleColumn("NaNTest", 10, isNullable: true);

            col.Append(double.NaN);       // Mathematical NaN
            col.Append((double?)null);    // Logical Null

            // Index 0: Not Null, but value is NaN
            Assert.False(col.IsNull(0));
            Assert.True(double.IsNaN(col.Get(0)));

            // Index 1: Is Null
            Assert.True(col.IsNull(1));
        }

        [Fact]
        public void Aggregations_Work_On_NonNullable()
        {
            using var col = new DoubleColumn("Strict", 10, isNullable: false);
            col.Append(1.5);
            col.Append(2.5);

            Assert.Equal(4.0, col.Sum());
            Assert.Equal(1.5, col.Min());
            Assert.Equal(2.5, col.Max());
        }
    }
}
===== FILE: tests/LeichtFrame.Core.Tests/Columns/IndirectColumnTests.cs =====
using LeichtFrame.Core;

namespace LeichtFrame.Core.Tests.Columns
{
    public class IndirectColumnTests
    {
        [Fact]
        public void Get_Returns_Correct_Value_Via_Indirection()
        {
            // Source: [10, 20, 30, 40, 50]
            using var source = new IntColumn("Src", 5);
            source.Append(10); source.Append(20); source.Append(30); source.Append(40); source.Append(50);

            // View: Only indices 1 (20) and 3 (40)
            var indices = new[] { 1, 3 };
            using var view = new IndirectColumn<int>(source, indices);

            Assert.Equal(2, view.Length);
            Assert.Equal(20, view.Get(0));
            Assert.Equal(40, view.Get(1));
        }

        [Fact]
        public void SetValue_Writes_Through_To_Source()
        {
            using var source = new IntColumn("Src", 3);
            source.Append(100);
            source.Append(200);
            source.Append(300);

            // View on index 1 (200)
            var view = new IndirectColumn<int>(source, new[] { 1 });

            // Act: Change value in View
            view.SetValue(0, 999);

            // Assert: Source must be updated
            Assert.Equal(999, source.Get(1));
        }

        [Fact]
        public void CloneSubset_Materializes_View_To_Real_Column()
        {
            using var source = new IntColumn("Src", 3);
            source.Append(10); source.Append(20); source.Append(30);

            var view = new IndirectColumn<int>(source, new[] { 2, 0 }); // [30, 10]

            // Act: Clone subset of the view (take first element -> 30)
            var materialized = view.CloneSubset(new[] { 0 });

            // Assert: Should be a real IntColumn now, not Indirect
            Assert.IsType<IntColumn>(materialized);
            Assert.Equal(1, materialized.Length);
            Assert.Equal(30, ((IntColumn)materialized).Get(0));
        }

        [Fact]
        public void Unsupported_Operations_Throw()
        {
            using var source = new IntColumn("Src", 1);
            var view = new IndirectColumn<int>(source, new[] { 0 });

            Assert.Throws<NotSupportedException>(() => view.Append(1));
            Assert.Throws<NotSupportedException>(() => view.EnsureCapacity(10));
            Assert.Throws<NotSupportedException>(() => _ = view.Values); // No Span support
        }
    }
}
===== FILE: tests/LeichtFrame.Core.Tests/Columns/IntColumnTests.cs =====
namespace LeichtFrame.Core.Tests.Columns
{
    public class IntColumnTests
    {
        [Fact]
        public void Constructor_Sets_IsNullable_Correctly()
        {
            using var col1 = new IntColumn("A", 10, isNullable: false);
            using var col2 = new IntColumn("B", 10, isNullable: true);

            Assert.False(col1.IsNullable);
            Assert.True(col2.IsNullable);
        }

        [Fact]
        public void SetValue_And_GetValue_Work()
        {
            using var col = new IntColumn("Test", 10);
            col.Append(0);

            col.SetValue(0, 42);

            Assert.Equal(42, col.Get(0));
        }

        [Fact]
        public void Append_Resizes_Automatically()
        {
            using var col = new IntColumn("Test", capacity: 2);

            col.Append(1);
            col.Append(2);
            col.Append(3);

            Assert.Equal(3, col.Length);
            Assert.Equal(1, col.Get(0));
            Assert.Equal(3, col.Get(2));
        }

        [Fact]
        public void NonNullable_Column_Throws_On_SetNull()
        {
            using var col = new IntColumn("Strict", 10, isNullable: false);
            col.Append(1);

            Assert.Throws<InvalidOperationException>(() => col.SetNull(0));
        }

        [Fact]
        public void Nullable_Column_Can_Store_Nulls()
        {
            using var col = new IntColumn("Nullable", 10, isNullable: true);

            col.Append(10);
            col.Append((int?)null);

            Assert.False(col.IsNull(0));
            Assert.True(col.IsNull(1));

            Assert.Equal(0, col.Get(1));
        }

        [Fact]
        public void SetValue_Clears_Null_Flag()
        {
            using var col = new IntColumn("Nullable", 10, isNullable: true);
            col.Append((int?)null);
            Assert.True(col.IsNull(0));

            col.SetValue(0, 99);

            Assert.False(col.IsNull(0));
            Assert.Equal(99, col.Get(0));
        }

        [Fact]
        public void Dispose_Can_Be_Called_Safely()
        {
            var col = new IntColumn("Temp", 10);
            col.Append(1);

            col.Dispose();

            Assert.ThrowsAny<Exception>(() => col.Get(0));
        }
    }
}
===== FILE: tests/LeichtFrame.Core.Tests/Columns/SliceTests.cs =====
namespace LeichtFrame.Core.Tests.Columns
{
    public class SliceTests
    {
        [Fact]
        public void Slice_Returns_Correct_SubSet()
        {
            using var col = new IntColumn("Data", 10);
            col.Append(10);
            col.Append(20);
            col.Append(30);
            col.Append(40);
            col.Append(50);

            // Slice from index 1, length 3 -> [20, 30, 40]
            var slice = col.Slice(1, 3);

            Assert.Equal(3, slice.Length);
            Assert.Equal(20, slice.Span[0]);
            Assert.Equal(40, slice.Span[2]);
        }

        [Fact]
        public void Slice_Is_ZeroCopy()
        {
            // Slice operations do not allocate copies
            using var col = new IntColumn("ZeroCopy", 10);
            col.Append(100);
            col.Append(200);

            var slice = col.Slice(0, 2);

            // Modify ORIGINAL column
            col.SetValue(1, 999);

            // Verify SLICE sees the change (proof that it points to same memory)
            Assert.Equal(999, slice.Span[1]);
        }

        [Fact]
        public void Slice_Throws_On_Invalid_Bounds()
        {
            // Slice throws on invalid bounds
            using var col = new IntColumn("Bounds", 5);
            col.Append(1);
            col.Append(2);

            // Length is 2
            Assert.Throws<ArgumentOutOfRangeException>(() => col.Slice(0, 3)); // Too long
            Assert.Throws<ArgumentOutOfRangeException>(() => col.Slice(2, 1)); // Start at end
            Assert.Throws<ArgumentOutOfRangeException>(() => col.Slice(-1, 1)); // Negative start
        }

        [Fact]
        public void BoolColumn_Throws_NotSupported_On_Slice()
        {
            // BoolColumn special case
            using var col = new BoolColumn("Bools", 8);
            col.Append(true);

            Assert.Throws<NotSupportedException>(() => col.Slice(0, 1));
        }

        [Fact]
        public void StringColumn_Throws_NotSupported_On_Slice()
        {
            using var col = new StringColumn("Strings", 5);
            col.Append("A");
            col.Append("B");

            Assert.Throws<NotSupportedException>(() => col.Slice(0, 1));
        }
    }
}
===== FILE: tests/LeichtFrame.Core.Tests/Columns/StringColumnTests.cs =====
namespace LeichtFrame.Core.Tests.Columns
{
    public class StringColumnTests
    {
        [Fact]
        public void Basic_Append_Read()
        {
            using var col = new StringColumn("Names", 10);
            col.Append("Alice");
            col.Append("Bob");

            Assert.Equal(2, col.Length);
            Assert.Equal("Alice", col.Get(0));
            Assert.Equal("Bob", col.Get(1));
        }

        [Fact]
        public void Nullable_String_Works()
        {
            using var col = new StringColumn("Nullable", 10, isNullable: true);
            col.Append("Text");
            col.Append(null);

            Assert.False(col.IsNull(0));
            Assert.True(col.IsNull(1));
            Assert.Null(col.Get(1));
        }

        [Fact]
        public void Dispose_Clears_References()
        {
            // As we use ArrayPool, it is difficult to directly test 
            // if the array was cleared, as we lose the reference.
            // But we check that Dispose does not throw an exception.
            var col = new StringColumn("Temp", 10);
            col.Append("Foo");
            col.Dispose();
        }

        [Fact]
        public void CompareRaw_Sorts_Bytes_Correctly()
        {
            using var col = new StringColumn("SortTest", 5, isNullable: true);

            col.Append("A");        // 0
            col.Append("B");        // 1
            col.Append("AA");       // 2
            col.Append("a");        // 3 (ASCII 97 > 65)
            col.Append(null);       // 4

            // 1. A < B
            Assert.Equal(-1, Math.Sign(col.CompareRaw(0, 1)));

            // 2. B > A
            Assert.Equal(1, Math.Sign(col.CompareRaw(1, 0)));

            // 3. A < AA (Prefix Logik)
            Assert.Equal(-1, Math.Sign(col.CompareRaw(0, 2)));

            // 4. A < a (Case Sensitivity: 'A'=65, 'a'=97)
            Assert.Equal(-1, Math.Sign(col.CompareRaw(0, 3)));

            // 5. Null Handling
            // Null (4) vs A (0)
            Assert.Equal(-1, col.CompareRaw(4, 0));
            // A (0) vs Null (4)
            Assert.Equal(1, col.CompareRaw(0, 4));
            // Null vs Null -> 0
            Assert.Equal(0, col.CompareRaw(4, 4));
        }
    }
}
===== FILE: tests/LeichtFrame.Core.Tests/DataFrames/DataFrameFactoryTests.cs =====
namespace LeichtFrame.Core.Tests.DataFrameTests
{
    public class DataFrameFactoryTests
    {
        // POCO for Testing
        private class User
        {
            public int Id { get; set; }
            public string Name { get; set; } = null!;
            public double? Score { get; set; } // Nullable!
            public DateTime Created { get; set; }
            public bool IsActive { get; set; }
        }

        [Fact]
        public void FromObjects_Creates_Populated_DataFrame()
        {
            var now = DateTime.Now;
            var users = new List<User>
            {
                new User { Id = 1, Name = "Alice", Score = 99.5, Created = now, IsActive = true },
                new User { Id = 2, Name = "Bob", Score = null, Created = now.AddDays(1), IsActive = false }
            };

            var df = DataFrame.FromObjects(users);

            // Verify Structure
            Assert.Equal(2, df.RowCount);
            Assert.Equal(5, df.ColumnCount);

            // Check Schema
            Assert.Equal(typeof(int), df["Id"].DataType);
            Assert.Equal(typeof(double), df["Score"].DataType);
            Assert.True(df["Score"].IsNullable); // Should detect int? as nullable

            // Check Data
            Assert.Equal(1, df["Id"].Get<int>(0));
            Assert.Equal("Bob", df["Name"].Get<string>(1));

            // Check Nullable
            Assert.Equal(99.5, df["Score"].Get<double>(0));
            Assert.True(df["Score"].IsNull(1));
        }

        [Fact]
        public void FromObjects_Skips_Unsupported_Types()
        {
            var list = new[] { new { Id = 1, Complex = new object() } }; // Complex object should be skipped
            var df = DataFrame.FromObjects(list);

            Assert.Equal(1, df.ColumnCount);
            Assert.True(df.Schema.HasColumn("Id"));
            Assert.False(df.Schema.HasColumn("Complex"));
        }
    }
}
===== FILE: tests/LeichtFrame.Core.Tests/DataFrames/DataFrameTests.cs =====
namespace LeichtFrame.Core.Tests.DataFrames
{
    public class DataFrameTests
    {
        [Fact]
        public void Constructor_Builds_Schema_And_Sets_Counts()
        {
            using var col1 = new IntColumn("Id", 10);
            col1.Append(1);

            using var col2 = new StringColumn("Name", 10);
            col2.Append("A");

            var df = new DataFrame(new IColumn[] { col1, col2 });

            Assert.Equal(1, df.RowCount);
            Assert.Equal(2, df.ColumnCount);

            Assert.True(df.Schema.HasColumn("Id"));
            Assert.True(df.Schema.HasColumn("Name"));
            Assert.Equal(typeof(int), df.Schema.Columns[0].DataType);
        }

        [Fact]
        public void Constructor_Throws_On_Length_Mismatch()
        {
            using var col1 = new IntColumn("Id", 10);
            col1.Append(1); // Length 1

            using var col2 = new StringColumn("Name", 10);
            col2.Append("A");
            col2.Append("B"); // Length 2

            var ex = Assert.Throws<ArgumentException>(() => new DataFrame(new IColumn[] { col1, col2 }));

            Assert.Contains("mismatch", ex.Message);
        }

        [Fact]
        public void Dispose_Calls_Dispose_On_Columns()
        {
            // As we find it difficult to "look inside" the columns to check if they are disposed (without crashing),
            // we primarily test here that df.Dispose() does not throw any errors.
            // A real "was Dispose called" test would require mocks (Moq), 
            // but we use real classes here.

            var col = new IntColumn("Temp", 10);
            col.Append(1);

            var df = new DataFrame(new[] { col });

            df.Dispose();

            // Indirect proof: Accessing the column should now be unsafe 
            // (or in IntColumn in A.2 implementation: _data is null).
            Assert.ThrowsAny<Exception>(() => col.Get(0));
        }

        [Fact]
        public void Empty_DataFrame_Is_Valid()
        {
            var df = new DataFrame(new IColumn[0]);

            Assert.Equal(0, df.RowCount);
            Assert.Equal(0, df.ColumnCount);
            Assert.NotNull(df.Schema);
        }

        [Fact]
        public void Indexer_By_Int_Returns_Correct_Column()
        {
            using var col1 = new IntColumn("Col1", 5);
            using var col2 = new IntColumn("Col2", 5);
            var df = new DataFrame(new[] { col1, col2 });

            Assert.Same(col1, df[0]);
            Assert.Same(col2, df[1]);
        }

        [Fact]
        public void Indexer_By_Int_Throws_On_Invalid_Index()
        {
            var df = new DataFrame(new IColumn[0]);
            Assert.Throws<ArgumentOutOfRangeException>(() => df[0]);
        }

        [Fact]
        public void Indexer_By_Name_Returns_Correct_Column()
        {
            using var age = new IntColumn("Age", 5);
            using var name = new StringColumn("Name", 5);
            var df = new DataFrame(new IColumn[] { age, name });

            Assert.Same(age, df["Age"]);
            Assert.Same(name, df["Name"]);
        }

        [Fact]
        public void Indexer_By_Name_Throws_If_Missing()
        {
            using var col = new IntColumn("Data", 5);
            var df = new DataFrame(new[] { col });

            // Exception comes from Schema.GetColumnIndex
            Assert.Throws<ArgumentException>(() => df["Missing"]);
        }

        [Fact]
        public void TryGetColumn_Returns_False_If_Missing()
        {
            using var col = new IntColumn("Data", 5);
            var df = new DataFrame(new[] { col });

            bool found = df.TryGetColumn("Missing", out var result);

            Assert.False(found);
            Assert.Null(result);
        }

        [Fact]
        public void TryGetColumn_Returns_True_And_Column_If_Found()
        {
            using var col = new IntColumn("Data", 5);
            var df = new DataFrame(new[] { col });

            bool found = df.TryGetColumn("Data", out var result);

            Assert.True(found);
            Assert.Same(col, result);
        }

        [Fact]
        public void Create_Factory_Builds_Correct_Structure_From_Schema()
        {
            // 1. Define Schema (Blueprint)
            var schema = new DataFrameSchema(new[] {
                new ColumnDefinition("Id", typeof(int), IsNullable: false),
                new ColumnDefinition("Value", typeof(double), IsNullable: true),
                new ColumnDefinition("Label", typeof(string))
            });

            // 2. Create via Factory
            var df = DataFrame.Create(schema, capacity: 100);

            // 3. Verify Basics
            Assert.Equal(0, df.RowCount); // Must be empty
            Assert.Equal(3, df.ColumnCount);

            // 4. Verify Columns match Schema
            // Check ID
            var idCol = df["Id"];
            Assert.IsType<IntColumn>(idCol);
            Assert.False(idCol.IsNullable);

            // Check Value
            var valCol = df["Value"];
            Assert.IsType<DoubleColumn>(valCol);
            Assert.True(valCol.IsNullable);

            // 5. Verify Capacity (indirectly via functionality)
            ((IntColumn)idCol).Append(1);
            ((DoubleColumn)valCol).Append(null);
            ((StringColumn)df["Label"]).Append("Test");

            Assert.Equal(1, df.RowCount);
        }

        [Fact]
        public void ToString_Returns_Short_Summary()
        {
            var df = DataFrame.Create(new DataFrameSchema(new[] { new ColumnDefinition("A", typeof(int)) }), 5);
            // We do not add any data, capacity is 5, but length is 0 (because not appended)
            // Wait: Create allocates capacity, but length is 0. 
            // So we append 1 row.
            ((IntColumn)df["A"]).Append(100);

            Assert.Equal("DataFrame (1 rows, 1 columns)", df.ToString());
        }

        [Fact]
        public void Inspect_Formats_Output_Correctly()
        {
            // Arrange
            var schema = new DataFrameSchema(new[] {
                new ColumnDefinition("ID", typeof(int)),
                new ColumnDefinition("Name", typeof(string), IsNullable: true)
            });
            var df = DataFrame.Create(schema, 10);

            var idCol = (IntColumn)df["ID"];
            var nameCol = (StringColumn)df["Name"];

            idCol.Append(1); nameCol.Append("Alice");
            idCol.Append(2); nameCol.Append(null); // Test null display

            // Act
            string output = df.Inspect();

            // Assert
            // 1. Header & Types
            Assert.Contains("ID", output);
            Assert.Contains("Name", output);
            Assert.Contains("<Int32>", output);
            Assert.Contains("<String>", output);

            // 2. Data content
            Assert.Contains("1", output);
            Assert.Contains("Alice", output);
            Assert.Contains("2", output);
            Assert.Contains("null", output); // Should explicitly show "null"
        }

        [Fact]
        public void Schema_Inspection_API_Works()
        {
            // Arrange: DataFrame with known schema
            var schema = new DataFrameSchema(new[] {
                new ColumnDefinition("Age", typeof(int)),
                new ColumnDefinition("Name", typeof(string))
            });
            var df = DataFrame.Create(schema, 0);

            // 1. HasColumn
            Assert.True(df.HasColumn("Age"));
            Assert.True(df.HasColumn("Name"));
            Assert.False(df.HasColumn("Salary"));
            Assert.False(df.HasColumn(""));

            // 2. GetColumnNames
            var names = df.GetColumnNames();
            Assert.Equal(new[] { "Age", "Name" }, names);

            // 3. GetColumnType
            Assert.Equal(typeof(int), df.GetColumnType("Age"));
            Assert.Equal(typeof(string), df.GetColumnType("Name"));

            // Error Case: Missing Column
            Assert.Throws<ArgumentException>(() => df.GetColumnType("MissingCol"));
        }
    }
}
===== FILE: tests/LeichtFrame.Core.Tests/DataFrames/Operations/AggregationTests.cs =====
namespace LeichtFrame.Core.Tests.DataFrameTests
{
    public class AggregationTests
    {
        [Fact]
        public void Sum_Works_For_Int_And_Double()
        {
            var schema = new DataFrameSchema(new[] {
                new ColumnDefinition("Ints", typeof(int)),
                new ColumnDefinition("Doubles", typeof(double))
            });
            var df = DataFrame.Create(schema, 10);

            var intCol = (IntColumn)df["Ints"];
            var dblCol = (DoubleColumn)df["Doubles"];

            intCol.Append(10); intCol.Append(20);
            dblCol.Append(1.5); dblCol.Append(2.5);

            Assert.Equal(30.0, df.Sum("Ints"));
            Assert.Equal(4.0, df.Sum("Doubles"));
        }

        [Fact]
        public void Sum_Ignores_Nulls()
        {
            var schema = new DataFrameSchema(new[] {
                new ColumnDefinition("Val", typeof(int), IsNullable: true)
            });
            var df = DataFrame.Create(schema, 5);
            var col = (IntColumn)df["Val"];

            col.Append(10);
            col.Append(null);
            col.Append(20);

            // 10 + 0 + 20 = 30
            Assert.Equal(30.0, df.Sum("Val"));
        }

        [Fact]
        public void MinMax_Works_Correctly()
        {
            var schema = new DataFrameSchema(new[] { new ColumnDefinition("Vals", typeof(int)) });
            var df = DataFrame.Create(schema, 5);
            var col = (IntColumn)df["Vals"];

            col.Append(5);
            col.Append(100);
            col.Append(-10);

            Assert.Equal(-10.0, df.Min("Vals"));
            Assert.Equal(100.0, df.Max("Vals"));
        }

        [Fact]
        public void Mean_Calculates_Average_Correctly()
        {
            var schema = new DataFrameSchema(new[] { new ColumnDefinition("A", typeof(double)) });
            var df = DataFrame.Create(schema, 5);
            var col = (DoubleColumn)df["A"];

            col.Append(2.0);
            col.Append(4.0);

            Assert.Equal(3.0, df.Mean("A"));
        }

        [Fact]
        public void Aggregation_Throws_On_String()
        {
            var schema = new DataFrameSchema(new[] { new ColumnDefinition("Str", typeof(string)) });
            var df = DataFrame.Create(schema, 1);
            ((StringColumn)df["Str"]).Append("Hello");

            Assert.Throws<NotSupportedException>(() => df.Sum("Str"));
        }
    }
}
===== FILE: tests/LeichtFrame.Core.Tests/DataFrames/Operations/ArithmeticTests.cs =====
using LeichtFrame.Core;

namespace LeichtFrame.Core.Tests.DataFrames.Operations
{
    public class ArithmeticTests
    {
        [Fact]
        public void Int_Column_Addition_Works()
        {
            using var c1 = new IntColumn("A", 10);
            using var c2 = new IntColumn("B", 10);
            c1.Append(10); c2.Append(5);
            c1.Append(20); c2.Append(5);

            using var res = c1 + c2;

            Assert.Equal(15, res.Get(0));
            Assert.Equal(25, res.Get(1));
        }

        [Fact]
        public void Double_Column_Multiplication_With_Nulls()
        {
            using var c1 = new DoubleColumn("Price", 10, isNullable: true);
            using var c2 = new DoubleColumn("Qty", 10, isNullable: true);

            c1.Append(10.0); c2.Append(2.0); // 20
            c1.Append(10.0); c2.Append(null); // null
            c1.Append(null); c2.Append(5.0); // null

            using var res = c1 * c2;

            Assert.Equal(20.0, res.Get(0));
            Assert.True(res.IsNull(1));
            Assert.True(res.IsNull(2));
        }

        [Fact]
        public void Scalar_Operations_Work()
        {
            using var c1 = new IntColumn("A", 10);
            c1.Append(10);

            using var res = c1 * 2;

            Assert.Equal(20, res.Get(0));
        }
    }
}
===== FILE: tests/LeichtFrame.Core.Tests/DataFrames/Operations/CleaningTests.cs =====
namespace LeichtFrame.Core.Tests.DataFrames.Operations
{
    public class CleaningTests
    {
        [Fact]
        public void DropNulls_Removes_Rows_With_Nulls()
        {
            var schema = new DataFrameSchema(new[] {
                new ColumnDefinition("A", typeof(int), IsNullable: true),
                new ColumnDefinition("B", typeof(string), IsNullable: true)
            });
            var df = DataFrame.Create(schema, 4);
            var a = (IntColumn)df["A"];
            var b = (StringColumn)df["B"];

            // 0: OK
            a.Append(1); b.Append("Hi");
            // 1: Null in A
            a.Append(null); b.Append("Ho");
            // 2: Null in B
            a.Append(2); b.Append(null);
            // 3: OK
            a.Append(3); b.Append("Yi");

            var clean = df.DropNulls();

            Assert.Equal(2, clean.RowCount);
            Assert.Equal(1, clean["A"].Get<int>(0));
            Assert.Equal(3, clean["A"].Get<int>(1));
        }

        [Fact]
        public void DropNulls_Returns_Original_If_No_Nulls()
        {
            var df = DataFrame.Create(new DataFrameSchema(new[] { new ColumnDefinition("A", typeof(int)) }), 2);
            ((IntColumn)df["A"]).Append(1);
            ((IntColumn)df["A"]).Append(2);

            var result = df.DropNulls();

            // Should be reference equal optimization
            Assert.Same(df, result);
        }

        [Fact]
        public void FillNull_Replaces_Values_And_Removes_Nullable_Flag()
        {
            var schema = new DataFrameSchema(new[] {
                new ColumnDefinition("Val", typeof(double), IsNullable: true)
            });
            var df = DataFrame.Create(schema, 3);
            var col = (DoubleColumn)df["Val"];

            col.Append(1.5);
            col.Append(null);
            col.Append(3.5);

            // Act: Fill with 0.0
            var filled = df.FillNull("Val", 0.0);

            // Assert
            Assert.Equal(3, filled.RowCount);
            var newCol = (DoubleColumn)filled["Val"];

            Assert.False(newCol.IsNullable); // Should now be non-nullable
            Assert.Equal(1.5, newCol.Get(0));
            Assert.Equal(0.0, newCol.Get(1));
            Assert.Equal(3.5, newCol.Get(2));
        }

        [Fact]
        public void FillNull_Works_With_Strings()
        {
            var schema = new DataFrameSchema(new[] {
                new ColumnDefinition("Txt", typeof(string), IsNullable: true)
            });
            var df = DataFrame.Create(schema, 2);
            ((StringColumn)df["Txt"]).Append(null);
            ((StringColumn)df["Txt"]).Append("B");

            var filled = df.FillNull("Txt", "Empty");

            Assert.Equal("Empty", filled["Txt"].Get<string>(0));
            Assert.Equal("B", filled["Txt"].Get<string>(1));
        }
    }
}
===== FILE: tests/LeichtFrame.Core.Tests/DataFrames/Operations/DeduplicationTests.cs =====
using LeichtFrame.Core;

namespace LeichtFrame.Core.Tests.DataFrames.Operations
{
    public class DeduplicationTests
    {
        [Fact]
        public void Distinct_Removes_Exact_Duplicates()
        {
            var df = DataFrame.FromObjects(new[]
            {
                new { Id = 1, Name = "A" },
                new { Id = 2, Name = "B" }, // Duplicate follows
                new { Id = 2, Name = "B" },
                new { Id = 3, Name = "C" }
            });

            var unique = df.Distinct();

            Assert.Equal(3, unique.RowCount);
            Assert.Equal(1, unique["Id"].Get<int>(0));
            Assert.Equal(2, unique["Id"].Get<int>(1));
            Assert.Equal(3, unique["Id"].Get<int>(2));
        }

        [Fact]
        public void Distinct_By_Subset_Keeps_First_Occurrence()
        {
            var df = DataFrame.FromObjects(new[]
            {
                new { Group = "X", Val = 10 },
                new { Group = "X", Val = 99 }, // Same group, different val
                new { Group = "Y", Val = 20 }
            });

            // Distinct by Group only -> Should keep row 1 and 3
            var result = df.Distinct("Group");

            Assert.Equal(2, result.RowCount);
            Assert.Equal("X", result["Group"].Get<string>(0));
            Assert.Equal(10, result["Val"].Get<int>(0)); // First one kept
            Assert.Equal("Y", result["Group"].Get<string>(1));
        }

        [Fact]
        public void Distinct_Handles_Nulls()
        {
            var df = DataFrame.Create(new DataFrameSchema(new[] {
                new ColumnDefinition("A", typeof(string), IsNullable: true)
            }), 4);
            var col = (StringColumn)df["A"];

            col.Append("Hi");
            col.Append(null);
            col.Append("Hi");
            col.Append(null);

            var unique = df.Distinct();

            Assert.Equal(2, unique.RowCount);
            // Assuming "Hi" comes first, then null (order of insertion preserved)
            Assert.Equal("Hi", unique["A"].Get<string>(0));
            Assert.True(unique["A"].IsNull(1));
        }

        [Fact]
        public void Distinct_No_Duplicates_Returns_Original_Reference()
        {
            // Optimization Check: If no duplicates found, return same object (if implemented)
            var df = DataFrame.FromObjects(new[] { new { A = 1 }, new { A = 2 } });

            var result = df.Distinct();

            Assert.Same(df, result);
        }
    }
}
===== FILE: tests/LeichtFrame.Core.Tests/DataFrames/Operations/FilterTests.cs =====
namespace LeichtFrame.Core.Tests.DataFrameTests
{
    public class FilterTests
    {
        [Fact]
        public void Where_Filters_Rows_Correctly()
        {
            // Arrange
            var schema = new DataFrameSchema(new[] {
                new ColumnDefinition("Id", typeof(int)),
                new ColumnDefinition("City", typeof(string))
            });
            var df = DataFrame.Create(schema, 10);

            var id = (IntColumn)df["Id"];
            var city = (StringColumn)df["City"];

            // Add Data: 1=Berlin, 2=Munich, 3=Berlin, 4=Hamburg
            id.Append(1); city.Append("Berlin");
            id.Append(2); city.Append("Munich");
            id.Append(3); city.Append("Berlin");
            id.Append(4); city.Append("Hamburg");

            // Act: Filter City == "Berlin"
            var berlinDf = df.Where(row => row.Get<string>("City") == "Berlin");

            // Assert
            Assert.Equal(2, berlinDf.RowCount);
            Assert.Equal(1, berlinDf["Id"].Get<int>(0));
            Assert.Equal(3, berlinDf["Id"].Get<int>(1));
        }

        [Fact]
        public void Where_Handles_Nulls_In_Predicate()
        {
            var df = DataFrame.Create(new DataFrameSchema(new[] {
                new ColumnDefinition("Val", typeof(int), IsNullable: true)
            }), 5);
            var col = (IntColumn)df["Val"];

            col.Append(10);
            col.Append(null);
            col.Append(20);

            // Filter: Not null and > 15
            // We need to check if RowView is null-safe or if the user must check.
            // RowView.Get<int> throws on null if T is struct. 
            // Therefore better: use row.GetValue or row.IsNull?
            // User pattern: check null before access.

            var result = df.Where(row =>
            {
                // We use the untyped GetValue here for the null check or catch exception
                // Cleaner: Get the column and check IsNull? No, RowView abstracts that.
                // Solution: User uses Get<int?> (nullable int) if we support that, 
                // OR checks object value.

                object? val = row.GetValue(0);
                return val != null && (int)val > 15;
            });

            Assert.Equal(1, result.RowCount);
            Assert.Equal(20, result["Val"].Get<int>(0));
        }

        [Fact]
        public void Where_Creates_Deep_Copy()
        {
            // Proof that it is not a view (like Slice), but a real copy
            var df = DataFrame.Create(new DataFrameSchema(new[] { new ColumnDefinition("A", typeof(int)) }), 5);
            ((IntColumn)df["A"]).Append(100);

            var filtered = df.Where(r => true); // Copy all

            // Modify the copy
            ((IntColumn)filtered["A"]).SetValue(0, 999);

            // Original must remain unchanged
            Assert.Equal(100, df["A"].Get<int>(0));
        }
    }
}
===== FILE: tests/LeichtFrame.Core.Tests/DataFrames/Operations/GroupingTests.cs =====
namespace LeichtFrame.Core.Tests.DataFrameTests
{
    public class GroupingTests
    {
        [Fact]
        public void GroupBy_Strings_creates_Correct_Buckets()
        {
            // Arrange
            var schema = new DataFrameSchema(new[] {
                new ColumnDefinition("Dept", typeof(string)),
                new ColumnDefinition("Id", typeof(int))
            });
            var df = DataFrame.Create(schema, 10);

            var dept = (StringColumn)df["Dept"];
            dept.Append("Sales"); // 0
            dept.Append("IT");    // 1
            dept.Append("Sales"); // 2
            dept.Append("HR");    // 3
            dept.Append("IT");    // 4

            // Act
            var grouped = df.GroupBy("Dept");

            // Assert
            Assert.Equal(3, grouped.GroupMap.Count); // Sales, IT, HR

            // Check Sales bucket
            Assert.True(grouped.GroupMap.ContainsKey("Sales"));
            var salesIndices = grouped.GroupMap["Sales"];
            Assert.Equal(new[] { 0, 2 }, salesIndices);

            // Check IT bucket
            var itIndices = grouped.GroupMap["IT"];
            Assert.Equal(new[] { 1, 4 }, itIndices);
        }

        [Fact]
        public void GroupBy_Handles_Nulls_As_Separate_Group()
        {
            var df = DataFrame.Create(new DataFrameSchema(new[] {
                new ColumnDefinition("Cat", typeof(string), IsNullable: true)
            }), 5);
            var col = (StringColumn)df["Cat"];

            col.Append("A");
            col.Append(null);
            col.Append("A");
            col.Append(null);

            var grouped = df.GroupBy("Cat");

            Assert.Equal(2, grouped.GroupMap.Count); // "A" and NullKey

            // We need to check indirectly since NullKey is internal/private.
            // We iterate over keys and find the one that is not "A".
            var nullGroupKey = grouped.GroupMap.Keys.First(k => k is not string);
            var indices = grouped.GroupMap[nullGroupKey];

            Assert.Equal(new[] { 1, 3 }, indices);
        }

        [Fact]
        public void GroupBy_Integers_Works()
        {
            var df = DataFrame.Create(new DataFrameSchema(new[] { new ColumnDefinition("Num", typeof(int)) }), 5);
            var col = (IntColumn)df["Num"];
            col.Append(10);
            col.Append(20);
            col.Append(10);

            var grouped = df.GroupBy("Num");

            Assert.Equal(2, grouped.GroupMap.Count); // 2 Groups overall (10 and 20)
            Assert.Equal(2, grouped.GroupMap[10].Count); // Group 10 has 2 entries
            Assert.Single(grouped.GroupMap[20]); // Group 20 has exactly 1 entry
        }

        [Fact]
        public void Group_Count_Returns_Correct_DataFrame()
        {
            var df = DataFrame.Create(new DataFrameSchema(new[] { new ColumnDefinition("Dept", typeof(string)) }), 10);
            var col = (StringColumn)df["Dept"];
            col.Append("IT");
            col.Append("Sales");
            col.Append("IT");

            var result = df.GroupBy("Dept").Count();

            Assert.Equal(2, result.RowCount);

            // Verify Structure
            Assert.Equal("Dept", result.Columns[0].Name);
            Assert.Equal("Count", result.Columns[1].Name);

            // Verify Data (Order is not guaranteed with HashMap, so we find rows)
            // Simpler check for MVP:
            // "IT" -> 2, "Sales" -> 1

            // Quick workaround to verify content without Order-dependency logic:
            var itRow = result.Where(r => r.Get<string>("Dept") == "IT");
            Assert.Equal(2, itRow["Count"].Get<int>(0));
        }

        [Fact]
        public void Group_Sum_Calculates_Totals()
        {
            var schema = new DataFrameSchema(new[] {
                new ColumnDefinition("Id", typeof(int)),
                new ColumnDefinition("Val", typeof(double))
            });
            var df = DataFrame.Create(schema, 10);

            var id = (IntColumn)df["Id"];
            var val = (DoubleColumn)df["Val"];

            // Group 1: 10 + 20 = 30
            id.Append(1); val.Append(10.0);
            id.Append(1); val.Append(20.0);

            // Group 2: 5 = 5
            id.Append(2); val.Append(5.0);

            var result = df.GroupBy("Id").Sum("Val");

            Assert.Equal(2, result.RowCount);

            // Check Sum for ID 1
            var g1 = result.Where(r => r.Get<int>("Id") == 1);
            Assert.Equal(30.0, g1["Sum_Val"].Get<double>(0));
        }

        [Fact]
        public void Group_Sum_Handles_Null_Values_In_Data()
        {
            var df = DataFrame.Create(new DataFrameSchema(new[] {
                new ColumnDefinition("G", typeof(string)),
                new ColumnDefinition("V", typeof(int), IsNullable: true)
            }), 5);

            var g = (StringColumn)df["G"];
            var v = (IntColumn)df["V"];

            g.Append("A"); v.Append(10);
            g.Append("A"); v.Append(null); // Should be ignored
            g.Append("A"); v.Append(5);

            var result = df.GroupBy("G").Sum("V");

            Assert.Equal(15.0, result["Sum_V"].Get<double>(0));
        }

        [Fact]
        public void GroupBy_Parallel_Path_Works_Correctly_With_Large_Data()
        {
            // Arrange: Generate enough rows to trigger Parallel Path (> 100,000)
            int rowCount = 150_000;
            int distinctGroups = 10;

            using var col = new IntColumn("Val", rowCount);

            // Generate data: 0, 1, 2... 9, 0, 1...
            for (int i = 0; i < rowCount; i++)
            {
                col.Append(i % distinctGroups);
            }

            var df = new DataFrame(new[] { col });

            // Act
            // This implicitly calls GroupByParallel because RowCount >= 100_000
            var grouped = df.GroupBy("Val");
            var result = grouped.Count();

            // Assert
            Assert.Equal(distinctGroups, result.RowCount);

            // Each group should have exactly (150,000 / 10) = 15,000 items
            int expectedCount = rowCount / distinctGroups;

            // Check a few groups
            var countCol = (IntColumn)result["Count"];
            var keyCol = (IntColumn)result["Val"];

            // Since HashMaps don't guarantee order, we iterate or look up
            for (int i = 0; i < result.RowCount; i++)
            {
                Assert.Equal(expectedCount, countCol.Get(i));

                int key = keyCol.Get(i);
                Assert.True(key >= 0 && key < distinctGroups);
            }
        }

        [Fact]
        public void Group_MinMaxMean_Works_Correctly()
        {
            // Arrange
            var schema = new DataFrameSchema(new[] {
                new ColumnDefinition("Group", typeof(string)),
                new ColumnDefinition("Val", typeof(double))
            });
            var df = DataFrame.Create(schema, 10);
            var g = (StringColumn)df["Group"];
            var v = (DoubleColumn)df["Val"];

            // Group A: 10, 20, 30 -> Min: 10, Max: 30, Mean: 20, Sum: 60
            g.Append("A"); v.Append(10.0);
            g.Append("A"); v.Append(20.0);
            g.Append("A"); v.Append(30.0);

            // Group B: 5, 5 -> Min: 5, Max: 5, Mean: 5, Sum: 10
            g.Append("B"); v.Append(5.0);
            g.Append("B"); v.Append(5.0);

            var gdf = df.GroupBy("Group");

            // Act & Assert (Min)
            var minDf = gdf.Min("Val");
            var rowA_Min = minDf.Where(r => r.Get<string>("Group") == "A");
            Assert.Equal(10.0, rowA_Min["Min_Val"].Get<double>(0));

            // Act & Assert (Max)
            var maxDf = gdf.Max("Val");
            var rowA_Max = maxDf.Where(r => r.Get<string>("Group") == "A");
            Assert.Equal(30.0, rowA_Max["Max_Val"].Get<double>(0));

            // Act & Assert (Mean)
            var meanDf = gdf.Mean("Val");
            var rowA_Mean = meanDf.Where(r => r.Get<string>("Group") == "A");
            Assert.Equal(20.0, rowA_Mean["Mean_Val"].Get<double>(0));

            var rowB_Mean = meanDf.Where(r => r.Get<string>("Group") == "B");
            Assert.Equal(5.0, rowB_Mean["Mean_Val"].Get<double>(0));
        }

        [Fact]
        public void Group_Aggregations_Ignore_Nulls()
        {
            var df = DataFrame.Create(new DataFrameSchema(new[] {
                new ColumnDefinition("Id", typeof(int)),
                new ColumnDefinition("Val", typeof(int), IsNullable: true)
            }), 5);

            var id = (IntColumn)df["Id"];
            var val = (IntColumn)df["Val"];

            // Group 1: 10, null, 20 -> Sum: 30, Count: 3 (rows) or 2 (values)?
            // Count() counts rows in group. 
            // Mean() should be 30 / 2 = 15.

            id.Append(1); val.Append(10);
            id.Append(1); val.Append(null);
            id.Append(1); val.Append(20);

            var gdf = df.GroupBy("Id");

            // Test Sum
            var sumDf = gdf.Sum("Val");
            Assert.Equal(30.0, sumDf["Sum_Val"].Get<double>(0));

            // Test Mean
            var meanDf = gdf.Mean("Val");
            Assert.Equal(15.0, meanDf["Mean_Val"].Get<double>(0));
        }
    }
}
===== FILE: tests/LeichtFrame.Core.Tests/DataFrames/Operations/JoinTests.cs =====
namespace LeichtFrame.Core.Tests.DataFrameTests
{
    public class JoinTests
    {
        [Fact]
        public void InnerJoin_Integers_Matches_Correctly()
        {
            // Left: Employees
            var left = DataFrame.Create(new DataFrameSchema(new[] {
                new ColumnDefinition("EmpId", typeof(int)),
                new ColumnDefinition("DeptId", typeof(int))
            }), 10);
            ((IntColumn)left["EmpId"]).Append(1); ((IntColumn)left["DeptId"]).Append(100);
            ((IntColumn)left["EmpId"]).Append(2); ((IntColumn)left["DeptId"]).Append(200);
            ((IntColumn)left["EmpId"]).Append(3); ((IntColumn)left["DeptId"]).Append(100);

            // Right: Departments
            var right = DataFrame.Create(new DataFrameSchema(new[] {
                new ColumnDefinition("DeptId", typeof(int)),
                new ColumnDefinition("DeptName", typeof(string))
            }), 10);
            ((IntColumn)right["DeptId"]).Append(100); ((StringColumn)right["DeptName"]).Append("IT");
            ((IntColumn)right["DeptId"]).Append(300); ((StringColumn)right["DeptName"]).Append("HR");

            // Join on DeptId
            var joined = left.Join(right, on: "DeptId", JoinType.Inner);

            // Expect 2 rows (Emp 1 and 3 match Dept 100)
            Assert.Equal(2, joined.RowCount);

            // Check Data
            Assert.Equal("IT", joined["DeptName"].Get<string>(0));
            Assert.Equal(1, joined["EmpId"].Get<int>(0));
            Assert.Equal(3, joined["EmpId"].Get<int>(1));
        }

        [Fact]
        public void InnerJoin_Strings_Matches_Correctly()
        {
            var left = DataFrame.Create(new DataFrameSchema(new[] { new ColumnDefinition("Key", typeof(string)) }), 5);
            ((StringColumn)left["Key"]).Append("A");
            ((StringColumn)left["Key"]).Append("B");

            var right = DataFrame.Create(new DataFrameSchema(new[] {
                new ColumnDefinition("Key", typeof(string)),
                new ColumnDefinition("Val", typeof(int))
            }), 5);
            ((StringColumn)right["Key"]).Append("A"); ((IntColumn)right["Val"]).Append(99);

            var joined = left.Join(right, on: "Key");

            Assert.Equal(1, joined.RowCount);
            Assert.Equal("A", joined["Key"].Get<string>(0));
            Assert.Equal(99, joined["Val"].Get<int>(0));
        }

        [Fact]
        public void InnerJoin_1_to_N_Explodes_Rows()
        {
            // Left: 1 Row with Key 1
            var left = DataFrame.Create(new DataFrameSchema(new[] { new ColumnDefinition("K", typeof(int)) }), 5);
            ((IntColumn)left["K"]).Append(1);

            // Right: 2 Rows with Key 1
            var right = DataFrame.Create(new DataFrameSchema(new[] {
                new ColumnDefinition("K", typeof(int)),
                new ColumnDefinition("V", typeof(string))
            }), 5);

            ((IntColumn)right["K"]).Append(1); ((StringColumn)right["V"]).Append("M1");
            ((IntColumn)right["K"]).Append(1); ((StringColumn)right["V"]).Append("M2");

            var joined = left.Join(right, on: "K");

            Assert.Equal(2, joined.RowCount);
            Assert.Equal("M1", joined["V"].Get<string>(0));
            Assert.Equal("M2", joined["V"].Get<string>(1));
        }
    }
}
===== FILE: tests/LeichtFrame.Core.Tests/DataFrames/Operations/LeftJoinTests.cs =====
using LeichtFrame.Core;

namespace LeichtFrame.Core.Tests.DataFrames.Operations
{
    public class LeftJoinTests
    {
        [Fact]
        public void LeftJoin_Preserves_Unmatched_Left_Rows()
        {
            // Left: Users (1, 2, 3)
            var left = DataFrame.FromObjects(new[]
            {
                new { Id = 1, Name = "Alice" },
                new { Id = 2, Name = "Bob" },
                new { Id = 3, Name = "Charlie" }
            });

            // Right: Orders (Only User 1 and 3 bought something)
            var right = DataFrame.FromObjects(new[]
            {
                new { Id = 1, Product = "Book" },
                new { Id = 3, Product = "Car" }
            });

            // Act
            var result = left.Join(right, "Id", JoinType.Left);

            // Assert
            Assert.Equal(3, result.RowCount); // All 3 users must be there

            // Check Alice (Match)
            Assert.Equal("Alice", result["Name"].Get<string>(0));
            Assert.Equal("Book", result["Product"].Get<string>(0));

            // Check Bob (No Match) - Product should be null
            Assert.Equal("Bob", result["Name"].Get<string>(1));
            Assert.True(result["Product"].IsNull(1));

            // Check Charlie (Match)
            Assert.Equal("Charlie", result["Name"].Get<string>(2));
            Assert.Equal("Car", result["Product"].Get<string>(2));
        }

        [Fact]
        public void LeftJoin_Converts_Right_IntColumn_To_Nullable()
        {
            // Left
            var left = DataFrame.Create(new DataFrameSchema(new[] { new ColumnDefinition("K", typeof(int)) }), 2);
            ((IntColumn)left["K"]).Append(1);
            ((IntColumn)left["K"]).Append(2);

            // Right: Has INT Value (Non-Nullable initially)
            // But after Left Join, it must support nulls for the missing row.
            var right = DataFrame.Create(new DataFrameSchema(new[]{
                new ColumnDefinition("K", typeof(int)),
                new ColumnDefinition("Val", typeof(int), IsNullable: false)
            }), 1);

            ((IntColumn)right["K"]).Append(1);
            ((IntColumn)right["Val"]).Append(100);

            // Act
            var result = left.Join(right, "K", JoinType.Left);

            // Assert
            Assert.Equal(2, result.RowCount);

            var valCol = result["Val"];
            Assert.True(valCol.IsNullable, "Right column must become nullable");

            // Row 1 (Match): 100
            Assert.Equal(100, valCol.Get<int>(0));

            // Row 2 (No Match): Null
            Assert.True(valCol.IsNull(1));
        }

        [Fact]
        public void LeftJoin_Handles_Duplicates_On_Right()
        {
            // 1:N Relationship
            var left = DataFrame.FromObjects(new[] { new { K = 1 } });
            var right = DataFrame.FromObjects(new[]
            {
                new { K = 1, V = "A" },
                new { K = 1, V = "B" }
            });

            var result = left.Join(right, "K", JoinType.Left);

            Assert.Equal(2, result.RowCount);
            Assert.Equal("A", result["V"].Get<string>(0));
            Assert.Equal("B", result["V"].Get<string>(1));
        }
    }
}
===== FILE: tests/LeichtFrame.Core.Tests/DataFrames/Operations/OrderTests.cs =====
using LeichtFrame.Core;

namespace LeichtFrame.Core.Tests.DataFrames.Operations
{
    public class OrderTests
    {
        [Fact]
        public void OrderBy_Integers_Sorts_Correctly()
        {
            // Schema: ID (Int), Name (String)
            var schema = new DataFrameSchema(new[] {
                new ColumnDefinition("Id", typeof(int)),
                new ColumnDefinition("Name", typeof(string))
            });
            var df = DataFrame.Create(schema, 5);

            var id = (IntColumn)df["Id"];
            var name = (StringColumn)df["Name"];

            // Unsorted Data
            id.Append(3); name.Append("C");
            id.Append(1); name.Append("A");
            id.Append(2); name.Append("B");

            // Act
            var sorted = df.OrderBy("Id");

            // Assert
            Assert.Equal(3, sorted.RowCount);

            // Check order of ID
            Assert.Equal(1, sorted["Id"].Get<int>(0));
            Assert.Equal(2, sorted["Id"].Get<int>(1));
            Assert.Equal(3, sorted["Id"].Get<int>(2));

            // Check if Name moved with ID (Integrity check)
            Assert.Equal("A", sorted["Name"].Get<string>(0));
            Assert.Equal("B", sorted["Name"].Get<string>(1));
            Assert.Equal("C", sorted["Name"].Get<string>(2));
        }

        [Fact]
        public void OrderByDescending_Strings_Sorts_Correctly()
        {
            var df = DataFrame.FromObjects(new[]
            {
                new { Name = "Alice", Score = 10 },
                new { Name = "Charlie", Score = 30 },
                new { Name = "Bob", Score = 20 }
            });

            // Act
            var sorted = df.OrderByDescending("Name");

            // Assert: Charlie -> Bob -> Alice
            Assert.Equal("Charlie", sorted["Name"].Get<string>(0));
            Assert.Equal("Bob", sorted["Name"].Get<string>(1));
            Assert.Equal("Alice", sorted["Name"].Get<string>(2));

            // Check Score integrity
            Assert.Equal(30, sorted["Score"].Get<int>(0));
        }

        [Fact]
        public void OrderBy_Handles_Nulls_First()
        {
            var df = DataFrame.Create(new DataFrameSchema(new[] {
                new ColumnDefinition("Val", typeof(int), IsNullable: true)
            }), 3);

            var col = (IntColumn)df["Val"];
            col.Append(10);
            col.Append(null);
            col.Append(5);

            var sorted = df.OrderBy("Val");

            // Null -> 5 -> 10
            Assert.True(sorted["Val"].IsNull(0));
            Assert.Equal(5, sorted["Val"].Get<int>(1));
            Assert.Equal(10, sorted["Val"].Get<int>(2));
        }

        [Fact]
        public void OrderBy_Chaining_With_Head_Works()
        {
            // Scenario: "Get Top 2 Lowest Prices"
            var df = DataFrame.FromObjects(new[]
            {
                new { Price = 100 },
                new { Price = 50 },
                new { Price = 10 },
                new { Price = 500 }
            });

            var result = df.OrderBy("Price").Head(2);

            Assert.Equal(2, result.RowCount);
            Assert.Equal(10, result["Price"].Get<int>(0));
            Assert.Equal(50, result["Price"].Get<int>(1));
        }
    }
}
===== FILE: tests/LeichtFrame.Core.Tests/DataFrames/Operations/SelectionTests.cs =====
namespace LeichtFrame.Core.Tests.DataFrames.Operations
{
    public class SelectionTests
    {
        [Fact]
        public void Select_Returns_Subset_Of_Columns()
        {
            // Arrange
            var schema = new DataFrameSchema(new[] {
                new ColumnDefinition("A", typeof(int)),
                new ColumnDefinition("B", typeof(int)),
                new ColumnDefinition("C", typeof(int))
            });
            var df = DataFrame.Create(schema, 10);

            // Act
            var selected = df.Select("A", "C");

            // Assert
            Assert.Equal(2, selected.ColumnCount);
            Assert.Equal("A", selected.Columns[0].Name);
            Assert.Equal("C", selected.Columns[1].Name);

            // Verify B is gone
            Assert.False(selected.TryGetColumn("B", out _));
        }

        [Fact]
        public void Select_Is_ZeroCopy_And_SharedReference()
        {
            // Arrange
            var df = DataFrame.Create(new DataFrameSchema(new[] { new ColumnDefinition("Val", typeof(int)) }), 5);
            var colOriginal = (IntColumn)df["Val"];
            colOriginal.Append(100);

            // Act
            var dfSelection = df.Select("Val");
            var colSelected = (IntColumn)dfSelection["Val"];

            // Assert 1: They are physically the same objects
            Assert.Same(colOriginal, colSelected);

            // Assert 2: Changes in the original are visible in the selection
            colOriginal.SetValue(0, 999);
            Assert.Equal(999, colSelected.Get(0));

            // Assert 3: Changes in the selection are visible in the original
            colSelected.SetValue(0, 555);
            Assert.Equal(555, colOriginal.Get(0));
        }

        [Fact]
        public void Select_Respects_Order()
        {
            var schema = new DataFrameSchema(new[] {
                new ColumnDefinition("A", typeof(int)),
                new ColumnDefinition("B", typeof(int))
            });
            var df = DataFrame.Create(schema, 10);

            // Select B first, then A
            var selected = df.Select("B", "A");

            Assert.Equal("B", selected.Columns[0].Name);
            Assert.Equal("A", selected.Columns[1].Name);
        }

        [Fact]
        public void Select_Throws_On_Missing_Column()
        {
            var df = DataFrame.Create(new DataFrameSchema(new[] { new ColumnDefinition("A", typeof(int)) }), 5);

            Assert.Throws<ArgumentException>(() => df.Select("Z"));
        }
    }
}
===== FILE: tests/LeichtFrame.Core.Tests/DataFrames/Operations/SlicingTests.cs =====
namespace LeichtFrame.Core.Tests.DataFrames.Operations
{
    public class SlicingTests
    {
        [Fact]
        public void Slice_Creates_Correct_Window_On_Data()
        {
            var df = DataFrame.Create(new DataFrameSchema(new[] { new ColumnDefinition("Num", typeof(int)) }), 10);
            var col = (IntColumn)df["Num"];
            for (int i = 0; i < 5; i++) col.Append(i * 10); // 0, 10, 20, 30, 40

            // Slice middle: index 1 to 3 (Length 2) -> [10, 20]
            var slice = df.Slice(1, 2);

            Assert.Equal(2, slice.RowCount);
            Assert.Equal(10, slice["Num"].Get<int>(0)); // Original Index 1
            Assert.Equal(20, slice["Num"].Get<int>(1)); // Original Index 2
        }

        [Fact]
        public void Slice_Is_ZeroCopy_WriteThrough()
        {
            var df = DataFrame.Create(new DataFrameSchema(new[] { new ColumnDefinition("Num", typeof(int)) }), 5);
            ((IntColumn)df["Num"]).Append(100);
            ((IntColumn)df["Num"]).Append(200);

            var slice = df.Slice(1, 1); // View on row 1 (Value 200)

            // Change value via Slice
            var sliceCol = (IColumn<int>)slice["Num"];
            sliceCol.SetValue(0, 999);

            // Verify Change in Original
            Assert.Equal(999, df["Num"].Get<int>(1));
        }

        [Fact]
        public void Head_And_Tail_Work_As_Expected()
        {
            var df = DataFrame.Create(new DataFrameSchema(new[] { new ColumnDefinition("Id", typeof(int)) }), 10);
            for (int i = 0; i < 10; i++) ((IntColumn)df["Id"]).Append(i);

            var head = df.Head(3);
            Assert.Equal(3, head.RowCount);
            Assert.Equal(0, head["Id"].Get<int>(0));
            Assert.Equal(2, head["Id"].Get<int>(2));

            var tail = df.Tail(2);
            Assert.Equal(2, tail.RowCount);
            Assert.Equal(8, tail["Id"].Get<int>(0));
            Assert.Equal(9, tail["Id"].Get<int>(1));
        }

        [Fact]
        public void Slice_Handles_Out_Of_Bounds_Gracefully()
        {
            var df = DataFrame.Create(new DataFrameSchema(new[] { new ColumnDefinition("A", typeof(int)) }), 5);
            ((IntColumn)df["A"]).Append(1); // 1 Row total

            var safeSlice = df.Slice(0, 100); // Request more than exists
            Assert.Equal(1, safeSlice.RowCount); // Should clamp to real count

            var emptySlice = df.Slice(100, 5); // Start way after end
            Assert.Equal(0, emptySlice.RowCount);
        }
    }
}
===== FILE: tests/LeichtFrame.Core.Tests/DataFrames/Operations/SortingTests.cs =====
using LeichtFrame.Core;

namespace LeichtFrame.Core.Tests.DataFrames.Operations
{
    public class SortingTests
    {
        [Fact]
        public void GetSortedIndices_Sorts_Integers_Ascending()
        {
            using var col = new IntColumn("Data", 5);
            col.Append(10); // 0
            col.Append(50); // 1
            col.Append(5);  // 2
            col.Append(20); // 3

            // Expected Order Values: 5, 10, 20, 50
            // Expected Order Indices: 2, 0, 3, 1

            var indices = col.GetSortedIndices(ascending: true);

            Assert.Equal(4, indices.Length);
            Assert.Equal(2, indices[0]);
            Assert.Equal(0, indices[1]);
            Assert.Equal(3, indices[2]);
            Assert.Equal(1, indices[3]);
        }

        [Fact]
        public void GetSortedIndices_Sorts_Integers_Descending()
        {
            using var col = new IntColumn("Data", 5);
            col.Append(10); // 0
            col.Append(50); // 1
            col.Append(5);  // 2

            // Expected Order Values: 50, 10, 5
            // Expected Order Indices: 1, 0, 2

            var indices = col.GetSortedIndices(ascending: false);

            Assert.Equal(1, indices[0]);
            Assert.Equal(0, indices[1]);
            Assert.Equal(2, indices[2]);
        }

        [Fact]
        public void GetSortedIndices_Handles_Nulls_First()
        {
            using var col = new StringColumn("Text", 5, isNullable: true);
            col.Append("B");    // 0
            col.Append(null);   // 1
            col.Append("A");    // 2

            // Standard: Nulls are smallest -> Null, A, B
            // Indices: 1, 2, 0

            var indices = col.GetSortedIndices(ascending: true);

            Assert.Equal(1, indices[0]);
            Assert.Equal(2, indices[1]);
            Assert.Equal(0, indices[2]);
        }

        [Fact]
        public void GetSortedIndices_Doubles_Correctness()
        {
            using var col = new DoubleColumn("Vals", 5);
            col.Append(1.1); // 0
            col.Append(0.9); // 1
            col.Append(1.1); // 2 (Duplicate)

            var indices = col.GetSortedIndices(ascending: true);

            // 0.9 comes first
            Assert.Equal(1, indices[0]);

            // For duplicates, order is not guaranteed (unstable sort), 
            // but indices must be valid (either 0 then 2, or 2 then 0).
            bool validOrder = (indices[1] == 0 && indices[2] == 2) || (indices[1] == 2 && indices[2] == 0);
            Assert.True(validOrder);
        }
    }
}
===== FILE: tests/LeichtFrame.Core.Tests/DataFrames/Operations/TopNTests.cs =====
namespace LeichtFrame.Core.Tests.DataFrames.Operations
{
    public class TopNTests
    {
        [Fact]
        public void Smallest_Returns_Correct_Items_Sorted()
        {
            var df = DataFrame.FromObjects(new[]
            {
                new { Val = 50 },
                new { Val = 10 },
                new { Val = 100 },
                new { Val = 5 },
                new { Val = 20 }
            });

            // Smallest 3: 5, 10, 20
            var result = df.Smallest(3, "Val");

            Assert.Equal(3, result.RowCount);
            Assert.Equal(5, result["Val"].Get<int>(0));
            Assert.Equal(10, result["Val"].Get<int>(1));
            Assert.Equal(20, result["Val"].Get<int>(2));
        }

        [Fact]
        public void Largest_Returns_Correct_Items_Sorted_Descending()
        {
            var df = DataFrame.FromObjects(new[]
            {
                new { Val = 1 },
                new { Val = 99 },
                new { Val = 2 },
                new { Val = 100 },
                new { Val = 3 }
            });

            // Largest 2: 100, 99
            var result = df.Largest(2, "Val");

            Assert.Equal(2, result.RowCount);
            Assert.Equal(100, result["Val"].Get<int>(0));
            Assert.Equal(99, result["Val"].Get<int>(1));
        }

        [Fact]
        public void Smallest_LargerThanRowCount_Returns_FullSort()
        {
            var df = DataFrame.Create(new DataFrameSchema(new[] { new ColumnDefinition("A", typeof(int)) }), 2);
            ((IntColumn)df["A"]).Append(20);
            ((IntColumn)df["A"]).Append(10);

            var result = df.Smallest(10, "A"); // Request 10, have 2

            Assert.Equal(2, result.RowCount);
            Assert.Equal(10, result["A"].Get<int>(0));
            Assert.Equal(20, result["A"].Get<int>(1));
        }

        [Fact]
        public void Largest_Strings_Works()
        {
            var df = DataFrame.FromObjects(new[]
            {
                new { Name = "A" },
                new { Name = "Z" },
                new { Name = "C" }
            });

            var result = df.Largest(1, "Name");

            Assert.Equal(1, result.RowCount);
            Assert.Equal("Z", result["Name"].Get<string>(0));
        }
    }
}
===== FILE: tests/LeichtFrame.Core.Tests/DataFrames/Operations/TransformationTests.cs =====
namespace LeichtFrame.Core.Tests.DataFrames.Operations
{
    public class TransformationTests
    {
        [Fact]
        public void AddColumn_Calculates_Simple_Math()
        {
            // Schema: Item, Price, Qty
            var df = DataFrame.FromObjects(new[]
            {
                new { Item = "A", Price = 10.0, Qty = 2 },
                new { Item = "B", Price = 5.5, Qty = 4 }
            });

            // Act: Total = Price * Qty
            var result = df.AddColumn("Total", row =>
                row.Get<double>("Price") * row.Get<int>("Qty")
            );

            // Assert
            Assert.Equal(4, result.ColumnCount); // 3 old + 1 new
            Assert.True(result.HasColumn("Total"));

            Assert.Equal(20.0, result["Total"].Get<double>(0));
            Assert.Equal(22.0, result["Total"].Get<double>(1));
        }

        [Fact]
        public void AddColumn_Works_With_Strings()
        {
            var df = DataFrame.FromObjects(new[]
            {
                new { First = "Hans", Last = "M√ºller" },
                new { First = "Alice", Last = "Wonder" }
            });

            // Act: FullName = First + " " + Last
            var result = df.AddColumn("FullName", row =>
                $"{row.Get<string>("First")} {row.Get<string>("Last")}"
            );

            Assert.Equal("Hans M√ºller", result["FullName"].Get<string>(0));
            Assert.Equal("Alice Wonder", result["FullName"].Get<string>(1));
        }

        [Fact]
        public void AddColumn_Supports_Nullable_Result()
        {
            var df = DataFrame.Create(new DataFrameSchema(new[] { new ColumnDefinition("Val", typeof(int)) }), 2);
            ((IntColumn)df["Val"]).Append(10);
            ((IntColumn)df["Val"]).Append(0); // Div by zero potential?

            // Act: Add nullable double column
            // Logic: If Val > 5 return Val/2, else null
            var result = df.AddColumn<double?>("Half", row =>
            {
                int v = row.Get<int>("Val");
                return v > 5 ? v / 2.0 : null;
            });

            Assert.True(result["Half"].IsNullable);
            Assert.Equal(5.0, result["Half"].Get<double>(0));
            Assert.True(result["Half"].IsNull(1));
        }

        [Fact]
        public void AddColumn_Throws_If_Name_Exists()
        {
            var df = DataFrame.FromObjects(new[] { new { Id = 1 } });

            Assert.Throws<ArgumentException>(() =>
                df.AddColumn("Id", r => r.Get<int>("Id") + 1)
            );
        }
    }
}
===== FILE: tests/LeichtFrame.Core.Tests/DataFrames/Operations/VectorizedFilterTests.cs =====
namespace LeichtFrame.Core.Tests.DataFrames.Operations
{
    public class VectorizedFilterTests
    {
        [Fact]
        public void WhereVec_Int_GreaterThan_Works()
        {
            var schema = new DataFrameSchema(new[] { new ColumnDefinition("Val", typeof(int)) });
            var df = DataFrame.Create(schema, 100);
            var col = (IntColumn)df["Val"];

            for (int i = 0; i < 100; i++) col.Append(i);

            var result = df.WhereVec("Val", CompareOp.GreaterThan, 90);

            Assert.Equal(9, result.RowCount);
            Assert.Equal(91, result["Val"].Get<int>(0));
            Assert.Equal(99, result["Val"].Get<int>(8));
        }

        [Fact]
        public void WhereVec_Double_LessThanOrEqual_Works()
        {
            var schema = new DataFrameSchema(new[] { new ColumnDefinition("Num", typeof(double)) });
            var df = DataFrame.Create(schema, 10);
            var col = (DoubleColumn)df["Num"];

            col.Append(1.5);
            col.Append(10.0);
            col.Append(2.5);
            col.Append(3.0);

            var result = df.WhereVec("Num", CompareOp.LessThanOrEqual, 3.0);

            Assert.Equal(3, result.RowCount);
            for (int i = 0; i < result.RowCount; i++)
            {
                Assert.True(result["Num"].Get<double>(i) <= 3.0);
            }
        }

        [Fact]
        public void WhereVec_Ignores_Null_Values()
        {
            var schema = new DataFrameSchema(new[] {
                new ColumnDefinition("Id", typeof(int), IsNullable: true)
            });
            var df = DataFrame.Create(schema, 5);
            var col = (IntColumn)df["Id"];

            col.Append(10);
            col.Append(null);
            col.Append(20);

            var result = df.WhereVec("Id", CompareOp.NotEqual, 5);

            Assert.Equal(2, result.RowCount);
            Assert.Equal(10, result["Id"].Get<int>(0));
            Assert.Equal(20, result["Id"].Get<int>(1));
        }

        [Fact]
        public void WhereVec_Handles_Sparse_Matches_Correctly()
        {
            var schema = new DataFrameSchema(new[] { new ColumnDefinition("A", typeof(int)) });
            var df = DataFrame.Create(schema, 1000);
            var col = (IntColumn)df["A"];

            for (int i = 0; i < 1000; i++) col.Append(0);

            col.SetValue(999, 100);

            var result = df.WhereVec("A", CompareOp.Equal, 100);

            Assert.Equal(1, result.RowCount);
            Assert.Equal(100, result["A"].Get<int>(0));
        }
    }
}
===== FILE: tests/LeichtFrame.Core.Tests/DataFrames/RowViewTests.cs =====
namespace LeichtFrame.Core.Tests.DataFrames
{
    public class RowViewTests
    {
        [Fact]
        public void RowView_Access_Works_Typed_And_Untyped()
        {
            // Setup
            using var intCol = new IntColumn("Age", 10);
            intCol.Append(42);

            using var strCol = new StringColumn("Name", 10);
            strCol.Append("Alice");

            var schema = new DataFrameSchema(new[] {
                new ColumnDefinition("Age", typeof(int)),
                new ColumnDefinition("Name", typeof(string))
            });

            var columns = new IColumn[] { intCol, strCol };
            var row = new RowView(0, columns, schema);

            // 1. Typed Access (via IColumn<T>.GetValue)
            Assert.Equal(42, row.Get<int>(0));
            Assert.Equal("Alice", row.Get<string>("Name"));

            // 2. Untyped Access (via IColumn.GetValue)
            Assert.Equal(42, row.GetValue(0));     // GetValue methode
            Assert.Equal("Alice", row["Name"]);    // Indexer
        }
    }
}
===== FILE: tests/LeichtFrame.Core.Tests/DataFrames/SchemaTests.cs =====
namespace LeichtFrame.Core.Tests.DataFrames;

public class SchemaTests
{
    [Fact]
    public void Can_Create_Schema_And_Lookup_Columns()
    {
        // Arrange
        var defs = new List<ColumnDefinition>
        {
            new("Id", typeof(int)),
            new("Name", typeof(string), IsNullable: true),
            new("Price", typeof(double))
        };

        // Act
        var schema = new DataFrameSchema(defs);

        // Assert
        Assert.Equal(3, schema.Columns.Count);

        Assert.True(schema.HasColumn("Id"));
        Assert.True(schema.HasColumn("Name"));
        Assert.False(schema.HasColumn("Address")); // Should not exist

        Assert.Equal(0, schema.GetColumnIndex("Id"));
        Assert.Equal(1, schema.GetColumnIndex("Name"));
    }

    [Fact]
    public void Duplicate_Column_Names_Should_Throw()
    {
        var defs = new List<ColumnDefinition>
        {
            new("Id", typeof(int)),
            new("Id", typeof(string)) // Duplicate
        };

        Assert.Throws<ArgumentException>(() => new DataFrameSchema(defs));
    }

    [Fact]
    public void Json_Serialization_Roundtrip_Works()
    {
        // Arrange
        var originalDefs = new List<ColumnDefinition>
        {
            new("Count", typeof(int)),
            new("IsActive", typeof(bool), IsNullable: true)
        };
        var originalSchema = new DataFrameSchema(originalDefs);

        // Act
        string json = originalSchema.ToJson();
        var loadedSchema = DataFrameSchema.FromJson(json);

        // Assert
        Assert.Equal(2, loadedSchema.Columns.Count);

        // Check first column
        Assert.Equal("Count", loadedSchema.Columns[0].Name);
        Assert.Equal(typeof(int), loadedSchema.Columns[0].DataType);
        Assert.False(loadedSchema.Columns[0].IsNullable);

        // Check second column
        Assert.Equal("IsActive", loadedSchema.Columns[1].Name);
        Assert.Equal(typeof(bool), loadedSchema.Columns[1].DataType);
        Assert.True(loadedSchema.Columns[1].IsNullable);
    }

    private class TestPoco
    {
        public int Id { get; set; }
        public string? Name { get; set; }
        public double Score { get; set; }
        public bool IsActive { get; set; }
    }

    [Fact]
    public void FromType_Generates_Correct_Schema_From_POCO()
    {
        // Act
        var schema = DataFrameSchema.FromType<TestPoco>();

        // Assert
        Assert.Equal(4, schema.Columns.Count);

        // Check Types & Names
        Assert.Equal(typeof(int), schema.GetColumnType("Id"));
        Assert.Equal(typeof(string), schema.GetColumnType("Name"));
        Assert.Equal(typeof(double), schema.GetColumnType("Score"));
        Assert.Equal(typeof(bool), schema.GetColumnType("IsActive"));

        // Check Nullability
        // Name is string? -> Nullable
        var nameCol = schema.Columns.First(c => c.Name == "Name");
        Assert.True(nameCol.IsNullable);

        // Id is int -> Not Nullable
        var idCol = schema.Columns.First(c => c.Name == "Id");
        Assert.False(idCol.IsNullable);
    }
}
===== FILE: tests/LeichtFrame.Core.Tests/Extensions/EnumerableDataFrameExtensionsTests.cs =====
using LeichtFrame.Core;

namespace LeichtFrame.Core.Tests.Extensions
{
    public class EnumerableDataFrameExtensionsTests
    {
        private class TestItem
        {
            public int Id { get; set; }
            public string Name { get; set; } = "";
        }

        [Fact]
        public void ToDataFrameBatches_Splits_Collection_Correctly()
        {
            // Arrange: Generate 10 items
            var source = Enumerable.Range(0, 10).Select(i => new TestItem
            {
                Id = i,
                Name = $"Item {i}"
            });

            // Act: Batch size 3 -> Expecting 4 batches (3, 3, 3, 1)
            var batches = source.ToDataFrameBatches(batchSize: 3).ToList();

            // Assert
            Assert.Equal(4, batches.Count);

            // Check Schema Consistency
            foreach (var b in batches)
            {
                Assert.Equal(2, b.ColumnCount);
                Assert.True(b.HasColumn("Id"));
                Assert.True(b.HasColumn("Name"));
            }

            // Check Batch Sizes
            Assert.Equal(3, batches[0].RowCount);
            Assert.Equal(3, batches[1].RowCount);
            Assert.Equal(3, batches[2].RowCount);
            Assert.Equal(1, batches[3].RowCount);

            // Check Data Integrity (First and Last)
            Assert.Equal(0, batches[0]["Id"].Get<int>(0));
            Assert.Equal(9, batches[3]["Id"].Get<int>(0));
        }

        [Fact]
        public void ToDataFrameBatches_Handles_Empty_Source()
        {
            var source = Enumerable.Empty<TestItem>();

            var batches = source.ToDataFrameBatches(10).ToList();

            Assert.Empty(batches);
        }

        [Fact]
        public void ToDataFrameBatches_Uses_Cached_Schema_For_Performance()
        {
            // Logic verification: Ensure that we can process types correctly
            var source = new[] { new { Val = 10.5 } };

            var batch = source.ToDataFrameBatches(1).First();

            Assert.Equal(typeof(double), batch.GetColumnType("Val"));
            Assert.Equal(10.5, batch["Val"].Get<double>(0));
        }
    }
}
===== FILE: tests/LeichtFrame.Core.Tests/GlobalUsings.cs =====
global using Xunit;
===== FILE: tests/LeichtFrame.Core.Tests/LeichtFrame.Core.Tests.csproj =====
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net8.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>

    <IsPackable>false</IsPackable>
    <IsTestProject>true</IsTestProject>

    <GenerateDocumentationFile>false</GenerateDocumentationFile>
    <NoWarn>$(NoWarn);CS1591</NoWarn>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.NET.Test.Sdk" Version="17.6.0" />
    <PackageReference Include="xunit" Version="2.4.2" />
    <PackageReference Include="xunit.runner.visualstudio" Version="2.4.5">
      <IncludeAssets>runtime; build; native; contentfiles; analyzers; buildtransitive</IncludeAssets>
      <PrivateAssets>all</PrivateAssets>
    </PackageReference>
    <PackageReference Include="coverlet.collector" Version="6.0.0">
      <IncludeAssets>runtime; build; native; contentfiles; analyzers; buildtransitive</IncludeAssets>
      <PrivateAssets>all</PrivateAssets>
    </PackageReference>
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\..\src\LeichtFrame.Core\LeichtFrame.Core.csproj" />
  </ItemGroup>

</Project>

===== FILE: tests/LeichtFrame.Core.Tests/Memory/GrowthStrategyTests.cs =====
namespace LeichtFrame.Core.Tests.Memory
{
    public class GrowthStrategyTests
    {
        [Fact]
        public void IntColumn_Grows_From_Small_To_Large_Without_DataLoss()
        {
            // Start extremely small (Capacity 2)
            using var col = new IntColumn("Growth", 2);
            int count = 10_000;

            // Loop Insert
            for (int i = 0; i < count; i++)
            {
                col.Append(i);
            }

            // Assert: Everything still there?
            Assert.Equal(count, col.Length);

            // Check samples
            Assert.Equal(0, col.Get(0));
            Assert.Equal(5000, col.Get(5000));
            Assert.Equal(9999, col.Get(9999));
        }

        [Fact]
        public void StringColumn_Grows_And_Preserves_Nulls()
        {
            // Start small
            using var col = new StringColumn("StrGrowth", 4, isNullable: true);
            int count = 1000;

            for (int i = 0; i < count; i++)
            {
                if (i % 2 == 0)
                    col.Append($"Item {i}");
                else
                    col.Append(null);
            }

            Assert.Equal(count, col.Length);

            // Verify Integrity after multiple resizes
            for (int i = 0; i < count; i++)
            {
                if (i % 2 == 0)
                {
                    Assert.False(col.IsNull(i));
                    Assert.Equal($"Item {i}", col.Get(i));
                }
                else
                {
                    Assert.True(col.IsNull(i));
                    Assert.Null(col.Get(i));
                }
            }
        }

        [Fact]
        public void Explicit_EnsureCapacity_Triggering()
        {
            using var col = new DoubleColumn("Explicit", 10);

            // Manually increase capacity
            col.EnsureCapacity(1000);

            // Check without exposing internal fields:
            // If we now add 1000 items, no further resize should be necessary 
            // (hard to test black-box, but we test that it doesn't crash and retains data)

            col.Append(3.14);
            Assert.Equal(3.14, col.Get(0));
        }

        [Fact]
        public void BoolColumn_BitPacking_Survives_Growth()
        {
            // BoolColumn is special (bit manipulation)
            using var col = new BoolColumn("Bits", 8); // 1 byte

            // Fill 1000 bits (crossing many byte boundaries)
            for (int i = 0; i < 1000; i++)
            {
                col.Append(true);
            }

            Assert.Equal(1000, col.Length);
            Assert.True(col.AllTrue()); // Must still be true
        }
    }
}
===== FILE: tests/LeichtFrame.Core.Tests/Memory/NullBitmapTests.cs =====
namespace LeichtFrame.Core.Tests.Memory
{
    public class NullBitmapTests
    {
        [Fact]
        public void SetNull_SetsBit_Correctly()
        {
            using var bitmap = new NullBitmap(100);

            bitmap.SetNull(10);

            Assert.True(bitmap.IsNull(10));
            Assert.False(bitmap.IsNull(9));
            Assert.False(bitmap.IsNull(11));
        }

        [Fact]
        public void SetNotNull_ClearsBit_Correctly()
        {
            using var bitmap = new NullBitmap(100);
            bitmap.SetNull(50);
            Assert.True(bitmap.IsNull(50));

            bitmap.SetNotNull(50);
            Assert.False(bitmap.IsNull(50));
        }

        [Fact]
        public void BitLogic_Works_Across_WordBoundaries()
        {
            // A ulong has 64 bits. We test the transition from ulong[0] to ulong[1].
            using var bitmap = new NullBitmap(128);

            bitmap.SetNull(63); // Last bit in the first word
            bitmap.SetNull(64); // First bit in the second word

            Assert.True(bitmap.IsNull(63), "Index 63 failure");
            Assert.True(bitmap.IsNull(64), "Index 64 failure");
            Assert.False(bitmap.IsNull(62));
            Assert.False(bitmap.IsNull(65));
        }

        [Fact]
        public void Resize_Preserves_Existing_Bits()
        {
            using var bitmap = new NullBitmap(64);
            bitmap.SetNull(10);
            bitmap.SetNull(63);

            // Resize to something that requires a new ulong array
            bitmap.Resize(128);

            Assert.True(bitmap.IsNull(10));
            Assert.True(bitmap.IsNull(63));
            Assert.False(bitmap.IsNull(64)); // New area should be empty
        }

        [Fact]
        public void Supports_Large_Indexes_Without_Error()
        {
            // Criteria: "Bitmap behaves correctly for large indexes (e.g., 1 million entries)"
            int largeIndex = 1_000_000;

            // Start small
            using var bitmap = new NullBitmap(16);

            // Resize to large
            bitmap.Resize(largeIndex + 1);

            // Test bit at the end of the large range
            bitmap.SetNull(largeIndex);

            Assert.True(bitmap.IsNull(largeIndex));
            Assert.False(bitmap.IsNull(largeIndex - 1));
        }
    }
}
===== FILE: tests/LeichtFrame.Core.Tests/Mocks/SimpleMockColumn.cs =====
namespace LeichtFrame.Core.Tests.Mocks;

public class SimpleMockColumn<T> : Column<T>
{
    private T[] _data;
    private bool[] _nulls;
    private int _count;

    public SimpleMockColumn(string name, int length, bool isNullable = true)
        : base(name, isNullable)
    {
        if (length < 0) throw new ArgumentOutOfRangeException(nameof(length));
        _data = new T[length];
        _nulls = new bool[length];
        _count = length;
    }

    public override int Length => _count;

    public override ReadOnlyMemory<T> Values => _data.AsMemory(0, _count);

    public override T Get(int index)
    {
        if ((uint)index >= (uint)_count) throw new IndexOutOfRangeException(nameof(index));
        return _data[index];
    }

    public override void SetValue(int index, T value)
    {
        if (index < 0) throw new IndexOutOfRangeException(nameof(index));
        if (index >= _data.Length) EnsureCapacity(index + 1);
        _data[index] = value;
        _nulls[index] = false;
        if (index >= _count) _count = index + 1;
    }

    public override bool IsNull(int index)
    {
        if ((uint)index >= (uint)_count) throw new IndexOutOfRangeException(nameof(index));
        return _nulls[index];
    }

    public override void SetNull(int index)
    {
        if (index < 0) throw new IndexOutOfRangeException(nameof(index));
        if (index >= _data.Length) EnsureCapacity(index + 1);
        _nulls[index] = true;
        if (index >= _count) _count = index + 1;
    }

    public override void SetNotNull(int index)
    {
        if ((uint)index >= (uint)_count) throw new IndexOutOfRangeException(nameof(index));
        _nulls[index] = false;
    }

    public override void EnsureCapacity(int capacity)
    {
        if (capacity <= _data.Length) return;
        int newSize = Math.Max(capacity, Math.Max(4, _data.Length * 2));
        Array.Resize(ref _data, newSize);
        Array.Resize(ref _nulls, newSize);
    }

    public override void Append(T value)
    {
        if (_count >= _data.Length)
            EnsureCapacity(_count + 1);

        _data[_count] = value;
        _nulls[_count] = false;
        _count++;
    }

    public override IColumn CloneSubset(IReadOnlyList<int> indices)
    {
        var newCol = new SimpleMockColumn<T>(Name, indices.Count, IsNullable);

        for (int i = 0; i < indices.Count; i++)
        {
            int sourceIndex = indices[i];

            if (IsNullable && IsNull(sourceIndex))
            {
                newCol.SetNull(i);
                newCol.SetValue(i, default!);
            }
            else
            {
                newCol.SetValue(i, Get(sourceIndex));
            }
        }

        return newCol;
    }
}

===== FILE: tests/LeichtFrame.Core.Tests/Safety/GroupByFuzzTests.cs =====
using LeichtFrame.Core;

namespace LeichtFrame.Core.Tests.Safety
{
    public class GroupByFuzzTests
    {
        [Fact]
        public void Fuzz_GroupBy_Parallel_Correctness_Against_LINQ()
        {
            // Wir testen explizit um die Grenze von 100.000 herum und weit dar√ºber
            int[] sizes = { 90_000, 100_000, 100_001, 150_000, 500_000 };
            var rnd = new Random(12345);

            foreach (var size in sizes)
            {
                // 1. Generate Random Data
                // Wir erzeugen absichtlich "Cluster" (wenige Gruppen) und "Scatter" (viele Gruppen)
                int groupCardinality = rnd.Next(1, size / 10); // Zuf√§llige Anzahl an Gruppen

                int[] data = new int[size];
                for (int i = 0; i < size; i++)
                {
                    data[i] = rnd.Next(0, groupCardinality);
                }

                // 2. Run LeichtFrame (Candidate)
                using var col = new IntColumn("Val", size);
                foreach (var val in data) col.Append(val);

                var df = new DataFrame(new[] { col });

                // Trigger Count Aggregation
                var lfResult = df.GroupBy("Val").Count();

                // 3. Run LINQ (Oracle / Truth)
                var linqResult = data
                    .GroupBy(x => x)
                    .ToDictionary(g => g.Key, g => g.Count());

                // 4. Compare
                Assert.Equal(linqResult.Count, lfResult.RowCount);

                var keyCol = (IntColumn)lfResult["Val"];
                var countCol = (IntColumn)lfResult["Count"];

                for (int i = 0; i < lfResult.RowCount; i++)
                {
                    int key = keyCol.Get(i);
                    int count = countCol.Get(i);

                    // Pr√ºfen, ob der Schl√ºssel im Orakel existiert
                    Assert.True(linqResult.ContainsKey(key), $"LeichtFrame found key {key} which LINQ did not find (Size: {size}).");

                    // Pr√ºfen, ob die Anzahl √ºbereinstimmt
                    Assert.Equal(linqResult[key], count);
                }
            }
        }
    }
}
===== FILE: tests/LeichtFrame.Core.Tests/Safety/SimdFuzzTests.cs =====
using LeichtFrame.Core;

namespace LeichtFrame.Core.Tests.Safety
{
    public class SimdFuzzTests
    {
        private const int ITERATIONS = 100;

        public static IEnumerable<object[]> RaggedLengths()
        {
            var lengths = new List<int> {
                0, 1, 3, 4, 5,
                7, 8, 9,
                15, 16, 17,
                31, 32, 33,
                127, 128, 129,
                1000
            };

            foreach (var l in lengths) yield return new object[] { l };
        }

        [Theory]
        [MemberData(nameof(RaggedLengths))]
        public void Fuzz_Int_Aggregations_SumMinMax(int length)
        {
            var rnd = new Random(42);

            for (int i = 0; i < ITERATIONS; i++)
            {
                int[] data = new int[length];
                for (int j = 0; j < length; j++)
                {

                    double r = rnd.NextDouble();
                    if (r < 0.1) data[j] = 0;
                    else if (r < 0.2) data[j] = int.MaxValue;
                    else if (r < 0.3) data[j] = int.MinValue;
                    else if (r < 0.4) data[j] = rnd.Next(-100, 100);
                    else data[j] = rnd.Next();
                }

                using var col = new IntColumn("Fuzz", length);
                foreach (var val in data) col.Append(val);

                if (length > 0)
                {
                    int expectedMin = data.Min();
                    int actualMin = col.Min();
                    Assert.Equal(expectedMin, actualMin);

                    int expectedMax = data.Max();
                    int actualMax = col.Max();
                    Assert.Equal(expectedMax, actualMax);
                }

                long expectedSum = data.Select(x => (long)x).Sum();
                long actualSum = col.Sum();

                Assert.Equal(expectedSum, actualSum);
            }
        }

        [Theory]
        [MemberData(nameof(RaggedLengths))]
        public void Fuzz_Double_Aggregations_With_NaN(int length)
        {
            var rnd = new Random(123);

            for (int i = 0; i < ITERATIONS; i++)
            {
                double[] data = new double[length];
                for (int j = 0; j < length; j++)
                {
                    double r = rnd.NextDouble();
                    if (r < 0.05) data[j] = double.NaN;
                    else if (r < 0.1) data[j] = double.PositiveInfinity;
                    else if (r < 0.15) data[j] = 0.0;
                    else data[j] = (rnd.NextDouble() * 10000) - 5000;
                }

                using var col = new DoubleColumn("FuzzDbl", length);
                foreach (var val in data) col.Append(val);

                if (length > 0)
                {
                    double expectedSum = data.Sum();

                    double actualSum = col.Sum();

                    if (double.IsNaN(expectedSum))
                    {
                        Assert.True(double.IsNaN(actualSum), "Sum should be NaN if input contains NaN");
                    }
                    else
                    {
                        Assert.Equal(expectedSum, actualSum, precision: 2);
                    }
                }
            }
        }

        [Fact]
        public void Fuzz_WhereVec_Int_Filter()
        {
            var rnd = new Random(999);
            int N = 1000;

            for (int k = 0; k < 50; k++)
            {
                int[] data = new int[N];
                for (int i = 0; i < N; i++) data[i] = rnd.Next(-100, 100);

                var schema = new DataFrameSchema(new[] { new ColumnDefinition("Val", typeof(int)) });
                var df = DataFrame.Create(schema, N);
                var col = (IntColumn)df["Val"];
                foreach (var v in data) col.Append(v);

                int threshold = rnd.Next(-50, 50);

                var expectedIndices = data
                    .Select((val, idx) => new { val, idx })
                    .Where(x => x.val > threshold)
                    .Select(x => x.idx)
                    .ToList();

                var resultDf = df.WhereVec("Val", CompareOp.GreaterThan, threshold);

                Assert.Equal(expectedIndices.Count, resultDf.RowCount);

                var resCol = (IntColumn)resultDf["Val"];
                for (int r = 0; r < resultDf.RowCount; r++)
                {
                    int originalVal = data[expectedIndices[r]];
                    Assert.Equal(originalVal, resCol.Get(r));
                }
            }
        }

        [Fact]
        public void Fuzz_Arithmetic_Int_Add()
        {
            var rnd = new Random(555);
            int len = 130;

            for (int k = 0; k < 20; k++)
            {
                int[] arrA = new int[len];
                int[] arrB = new int[len];

                for (int i = 0; i < len; i++)
                {
                    arrA[i] = rnd.Next(-1000, 1000);
                    arrB[i] = rnd.Next(-1000, 1000);
                }

                using var cA = new IntColumn("A", len);
                using var cB = new IntColumn("B", len);
                foreach (var v in arrA) cA.Append(v);
                foreach (var v in arrB) cB.Append(v);

                using var res = cA + cB;

                for (int i = 0; i < len; i++)
                {
                    Assert.Equal(arrA[i] + arrB[i], res.Get(i));
                }
            }
        }

        [Fact]
        public void Boundary_Check_Allocated_Memory()
        {
            using var c1 = new IntColumn("C1", 7);
            for (int i = 0; i < 7; i++) c1.Append(i);

            var sum = c1.Sum();
            Assert.Equal(21, sum);
        }
    }
}
===== FILE: tests/LeichtFrame.IO.Tests/Arrow/ArrowConverterTests.cs =====
using Apache.Arrow;
using Apache.Arrow.Types;
using LeichtFrame.Core;

namespace LeichtFrame.IO.Tests
{
    public class ArrowConverterTests
    {
        [Fact]
        public void ToDataFrame_Converts_RecordBatch_Correctly()
        {
            // 1. Build Arrow RecordBatch manually
            var schema = new Schema.Builder()
                .Field(f => f.Name("Id").DataType(Int32Type.Default))
                .Field(f => f.Name("Score").DataType(DoubleType.Default))
                .Field(f => f.Name("Name").DataType(StringType.Default))
                .Build();

            int length = 2;

            // Build Arrays
            var idBuilder = new Int32Array.Builder().Append(1).Append(2);
            var scoreBuilder = new DoubleArray.Builder().Append(10.5).AppendNull(); // Contains Null
            var nameBuilder = new StringArray.Builder().Append("Alice").Append("Bob");

            var batch = new RecordBatch(schema, new IArrowArray[]
            {
                idBuilder.Build(),
                scoreBuilder.Build(),
                nameBuilder.Build()
            }, length);

            // 2. Act: Convert to LeichtFrame
            var df = batch.ToDataFrame(); // Extension Method usage

            // 3. Assert
            Assert.Equal(2, df.RowCount);
            Assert.Equal(3, df.ColumnCount);

            // Check Int
            Assert.Equal(1, df["Id"].Get<int>(0));
            Assert.Equal(2, df["Id"].Get<int>(1));

            // Check Double (Nullable)
            Assert.Equal(10.5, df["Score"].Get<double>(0));
            Assert.True(df["Score"].IsNull(1));

            // Check String
            Assert.Equal("Alice", df["Name"].Get<string>(0));
            Assert.Equal("Bob", df["Name"].Get<string>(1));
        }

        [Fact]
        public void Roundtrip_DataFrame_ToArrow_ToDataFrame_Preserves_Data()
        {
            // Arrange
            var schema = new DataFrameSchema(new[] {
                new ColumnDefinition("Id", typeof(int)),
                new ColumnDefinition("Val", typeof(double), IsNullable: true),
                new ColumnDefinition("Flag", typeof(bool)),
                new ColumnDefinition("Text", typeof(string))
            });

            var original = DataFrame.Create(schema, 2);

            var cId = (IntColumn)original["Id"];
            var cVal = (DoubleColumn)original["Val"];
            var cFlag = (BoolColumn)original["Flag"];
            var cText = (StringColumn)original["Text"];

            cId.Append(1); cVal.Append(1.1); cFlag.Append(true); cText.Append("A");
            cId.Append(2); cVal.Append(null); cFlag.Append(false); cText.Append("B");

            // Act 1: Export to Arrow
            var batch = original.ToArrow();

            // Assert Arrow Structure (Basic check)
            Assert.Equal(2, batch.Length);
            Assert.Equal(4, batch.ColumnCount);
            Assert.IsType<Int32Array>(batch.Column("Id"));
            Assert.IsType<DoubleArray>(batch.Column("Val"));

            // Act 2: Import back to DataFrame
            var loaded = batch.ToDataFrame();

            // Assert Data Integrity
            Assert.Equal(1, loaded["Id"].Get<int>(0));
            Assert.Equal(1.1, loaded["Val"].Get<double>(0));
            Assert.True(loaded["Flag"].Get<bool>(0));
            Assert.Equal("A", loaded["Text"].Get<string>(0));

            Assert.True(loaded["Val"].IsNull(1)); // Check Null preservation
            Assert.False(loaded["Flag"].Get<bool>(1));
        }
    }
}
===== FILE: tests/LeichtFrame.IO.Tests/Csv/CsvFuzzTests.cs =====
using System.Text;
using LeichtFrame.Core;

namespace LeichtFrame.IO.Tests.Csv
{
    public class CsvFuzzTests
    {
        [Fact]
        public void Fuzz_Csv_Parallel_And_Batching_Consistency()
        {
            var rnd = new Random(42);
            int iterations = 10;

            for (int i = 0; i < iterations; i++)
            {
                // 1. Random Parameters
                int rowCount = rnd.Next(100, 100_000);
                int batchSize = rnd.Next(1, rowCount * 2);
                bool hasHeader = rnd.NextDouble() > 0.5;

                // 2. Generate CSV File
                string file = Path.GetTempFileName();
                try
                {
                    var sb = new StringBuilder();
                    if (hasHeader) sb.AppendLine("Id,Val,Comment");

                    long expectedSumId = 0;

                    for (int r = 0; r < rowCount; r++)
                    {
                        int id = r;
                        double val = rnd.NextDouble();
                        string comment = $"Text {r}, with \"quotes\"";

                        comment = "\"" + comment.Replace("\"", "\"\"") + "\"";

                        sb.AppendLine($"{id},{val:F4},{comment}");
                        expectedSumId += id;
                    }
                    File.WriteAllText(file, sb.ToString());

                    var options = new CsvReadOptions { HasHeader = hasHeader };
                    var schema = new DataFrameSchema(new[] {
                        new ColumnDefinition("Id", typeof(int)),
                        new ColumnDefinition("Val", typeof(double)),
                        new ColumnDefinition("Comment", typeof(string))
                    });

                    // 3. Test A: Parallel Read (Full Load)
                    var dfFull = CsvReader.Read(file, schema, options);

                    Assert.Equal(rowCount, dfFull.RowCount);

                    Assert.Equal(expectedSumId, ((IntColumn)dfFull["Id"]).Sum());

                    // 4. Test B: Batch Read (Streaming)
                    long batchRowTotal = 0;
                    long batchSumId = 0;
                    int batchCount = 0;

                    foreach (var batch in CsvReader.ReadBatches(file, schema, batchSize, options))
                    {
                        batchRowTotal += batch.RowCount;

                        batchSumId += ((IntColumn)batch["Id"]).Sum();

                        batchCount++;

                        Assert.True(batch.RowCount <= batchSize);
                    }

                    Assert.Equal(rowCount, batchRowTotal);
                    Assert.Equal(expectedSumId, batchSumId);
                }
                finally
                {
                    if (File.Exists(file)) File.Delete(file);
                }
            }
        }
    }
}
===== FILE: tests/LeichtFrame.IO.Tests/Csv/CsvReaderTests.cs =====
using System.Text;
using LeichtFrame.Core;

namespace LeichtFrame.IO.Tests
{
    public class CsvReaderTests
    {
        [Fact]
        public void Read_Parses_Simple_Csv_With_Header()
        {
            var csv = "Id,Name,Score\n1,Alice,99.5\n2,Bob,80.0";
            using var stream = new MemoryStream(Encoding.UTF8.GetBytes(csv));

            var schema = new DataFrameSchema(new[] {
                new ColumnDefinition("Id", typeof(int)),
                new ColumnDefinition("Name", typeof(string)),
                new ColumnDefinition("Score", typeof(double))
            });

            var df = CsvReader.Read(stream, schema);

            Assert.Equal(2, df.RowCount);
            Assert.Equal(1, df["Id"].Get<int>(0));
            Assert.Equal("Alice", df["Name"].Get<string>(0));
            Assert.Equal(99.5, df["Score"].Get<double>(0));
        }

        [Fact]
        public void Read_Handles_Nulls()
        {
            var csv = "Val\n100\n\n200";
            using var stream = new MemoryStream(Encoding.UTF8.GetBytes(csv));

            var schema = new DataFrameSchema(new[] {
                new ColumnDefinition("Val", typeof(int), IsNullable: true)
            });

            var df = CsvReader.Read(stream, schema);

            Assert.Equal(3, df.RowCount);
            Assert.Equal(100, df["Val"].Get<int>(0));
            Assert.True(df["Val"].IsNull(1));
            Assert.Equal(200, df["Val"].Get<int>(2));
        }

        [Fact]
        public void InferSchema_Detects_Int_Double_And_String()
        {
            string csvFile = Path.GetTempFileName();
            File.WriteAllText(csvFile, "Age,Weight,Name\n25,80.5,Alice\n30,90,Bob"); // 90 is int, 80.5 double

            try
            {
                var schema = CsvReader.InferSchema(csvFile);

                Assert.Equal(3, schema.Columns.Count);

                // Age: Only ints -> int
                Assert.Equal(typeof(int), schema.GetColumnType("Age"));

                // Weight: Mixed double and int -> double (Promotion)
                Assert.Equal(typeof(double), schema.GetColumnType("Weight"));

                // Name: String
                Assert.Equal(typeof(string), schema.GetColumnType("Name"));
            }
            finally
            {
                File.Delete(csvFile);
            }
        }

        [Fact]
        public void InferSchema_Detects_Nullability()
        {
            string csvFile = Path.GetTempFileName();
            File.WriteAllText(csvFile, "Val\n100\n\n200");

            try
            {
                var schema = CsvReader.InferSchema(csvFile);
                Assert.Equal(typeof(int), schema.GetColumnType("Val"));
                Assert.True(schema.Columns[0].IsNullable);
            }
            finally
            {
                File.Delete(csvFile);
            }
        }

        [Fact]
        public void InferSchema_Fallbacks_To_String_On_Conflict()
        {
            string csvFile = Path.GetTempFileName();
            File.WriteAllText(csvFile, "Mixed\n100\nHello"); // Int then String

            try
            {
                var schema = CsvReader.InferSchema(csvFile);
                Assert.Equal(typeof(string), schema.GetColumnType("Mixed"));
            }
            finally
            {
                File.Delete(csvFile);
            }
        }

        private class ProductCsv
        {
            public int Id { get; set; }
            public string Name { get; set; } = "";
            public double Price { get; set; }
        }

        [Fact]
        public void Read_Generic_Map_To_POCO_Schema_Correctly()
        {
            // Arrange
            var csv = "Id,Name,Price\n10,Laptop,999.99\n20,Mouse,19.50";
            using var stream = new MemoryStream(System.Text.Encoding.UTF8.GetBytes(csv));

            // Act: The "Gold Standard" Call
            var df = CsvReader.Read<ProductCsv>(stream);

            // Assert
            Assert.Equal(2, df.RowCount);

            // Verify Schema was inferred from POCO
            Assert.Equal(typeof(int), df.GetColumnType("Id"));
            Assert.Equal(typeof(string), df.GetColumnType("Name"));
            Assert.Equal(typeof(double), df.GetColumnType("Price"));

            // Verify Data
            Assert.Equal(10, df["Id"].Get<int>(0));
            Assert.Equal("Laptop", df["Name"].Get<string>(0));
            Assert.Equal(999.99, df["Price"].Get<double>(0));
        }

        [Fact]
        public void ReadBatches_Splits_Data_Correctly()
        {
            // Arrange: Create CSV with 10 rows
            var sb = new StringBuilder();
            sb.AppendLine("Id,Val");
            for (int i = 0; i < 10; i++)
            {
                sb.AppendLine($"{i},{i * 10}");
            }

            string tempFile = Path.GetTempFileName();
            File.WriteAllText(tempFile, sb.ToString());

            var schema = new DataFrameSchema(new[] {
                new ColumnDefinition("Id", typeof(int)),
                new ColumnDefinition("Val", typeof(int))
            });

            try
            {
                // Act: Read in batches of size 3
                // Expectation: 4 Batches (3, 3, 3, 1 rows)
                var batches = CsvReader.ReadBatches(tempFile, schema, batchSize: 3).ToList();

                // Assert
                Assert.Equal(4, batches.Count);

                // Verify Batch 1
                Assert.Equal(3, batches[0].RowCount);
                Assert.Equal(0, batches[0]["Id"].Get<int>(0));
                Assert.Equal(2, batches[0]["Id"].Get<int>(2));

                // Verify Batch 4 (Last one containing remainder)
                Assert.Equal(1, batches[3].RowCount);
                Assert.Equal(9, batches[3]["Id"].Get<int>(0));
            }
            finally
            {
                if (File.Exists(tempFile)) File.Delete(tempFile);
            }
        }

        [Fact]
        public void Read_Process_Large_File_Correctly_Using_Parallel_Logic()
        {
            // The logic switches to Parallel processing if chunk size (50k) is reached.
            // We generate 55,000 rows to force at least one chunk + remainder.
            int rows = 55_000;
            var sb = new StringBuilder();
            sb.AppendLine("Id,Value");
            for (int i = 0; i < rows; i++)
            {
                sb.AppendLine($"{i},{i * 0.5}");
            }

            string path = Path.GetTempFileName();
            File.WriteAllText(path, sb.ToString());

            var schema = new DataFrameSchema(new[] {
                new ColumnDefinition("Id", typeof(int)),
                new ColumnDefinition("Value", typeof(double))
            });

            try
            {
                // Act: This will internally use ProcessChunkParallel
                var df = CsvReader.Read(path, schema);

                // Assert
                Assert.Equal(rows, df.RowCount);

                // Spot check first, boundary, last
                Assert.Equal(0, df["Id"].Get<int>(0));
                Assert.Equal(50_000, df["Id"].Get<int>(50_000));
                Assert.Equal(54_999, df["Id"].Get<int>(54_999));

                Assert.Equal(0.0, df["Value"].Get<double>(0));
            }
            finally
            {
                if (File.Exists(path)) File.Delete(path);
            }
        }
    }
}
===== FILE: tests/LeichtFrame.IO.Tests/Csv/CsvWriterTests.cs =====
using System.Text;
using LeichtFrame.Core;

namespace LeichtFrame.IO.Tests
{
    public class CsvWriterTests
    {
        [Fact]
        public void Write_Produces_Valid_String_Format()
        {
            // Arrange
            var schema = new DataFrameSchema(new[] {
                new ColumnDefinition("Id", typeof(int)),
                new ColumnDefinition("Price", typeof(double))
            });
            var df = DataFrame.Create(schema, 2);
            ((IntColumn)df["Id"]).Append(1); ((DoubleColumn)df["Price"]).Append(12.5);
            ((IntColumn)df["Id"]).Append(2); ((DoubleColumn)df["Price"]).Append(99.99);

            using var stream = new MemoryStream();

            // Act
            df.WriteCsv(stream);

            // Assert
            string csv = Encoding.UTF8.GetString(stream.ToArray());
            string[] lines = csv.Trim().Split(new[] { "\r\n", "\n" }, StringSplitOptions.None);

            Assert.Equal("Id,Price", lines[0]);
            Assert.Equal("1,12.5", lines[1]); // Verify Invariant Culture (Dot)
            Assert.Equal("2,99.99", lines[2]);
        }

        [Fact]
        public void Roundtrip_Write_Then_Read_Restores_Data()
        {
            // Arrange: Complex Data (Dates, Special Chars needing escaping)
            var original = DataFrame.Create(new DataFrameSchema(new[] {
                new ColumnDefinition("Date", typeof(DateTime)),
                new ColumnDefinition("Note", typeof(string))
            }), 1);

            var now = new DateTime(2023, 10, 05, 12, 30, 00);
            ((DateTimeColumn)original["Date"]).Append(now);
            ((StringColumn)original["Note"]).Append("Hello, World"); // Comma needs escaping!

            string tempFile = Path.GetTempFileName();
            try
            {
                // Act 1: Write
                original.WriteCsv(tempFile);

                // Act 2: Read Back
                var loaded = CsvReader.Read(tempFile, original.Schema);

                // Assert
                Assert.Equal(1, loaded.RowCount);
                Assert.Equal(now, loaded["Date"].Get<DateTime>(0));
                Assert.Equal("Hello, World", loaded["Note"].Get<string>(0)); // Quotes should be gone
            }
            finally
            {
                if (File.Exists(tempFile)) File.Delete(tempFile);
            }
        }
    }
}
===== FILE: tests/LeichtFrame.IO.Tests/GlobalUsings.cs =====
global using Xunit;
===== FILE: tests/LeichtFrame.IO.Tests/LeichtFrame.IO.Tests.csproj =====
<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net8.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>

    <IsPackable>false</IsPackable>
    <IsTestProject>true</IsTestProject>

    <GenerateDocumentationFile>false</GenerateDocumentationFile>
    <NoWarn>$(NoWarn);CS1591</NoWarn>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.NET.Test.Sdk" Version="17.6.0" />
    <PackageReference Include="xunit" Version="2.4.2" />
    <PackageReference Include="xunit.runner.visualstudio" Version="2.4.5">
      <IncludeAssets>runtime; build; native; contentfiles; analyzers; buildtransitive</IncludeAssets>
      <PrivateAssets>all</PrivateAssets>
    </PackageReference>
    <PackageReference Include="coverlet.collector" Version="6.0.0">
      <IncludeAssets>runtime; build; native; contentfiles; analyzers; buildtransitive</IncludeAssets>
      <PrivateAssets>all</PrivateAssets>
    </PackageReference>
  </ItemGroup>

  <ItemGroup>
    <ProjectReference Include="..\..\src\LeichtFrame.IO\LeichtFrame.IO.csproj" />
    <ProjectReference Include="..\..\src\LeichtFrame.Core\LeichtFrame.Core.csproj" />
  </ItemGroup>

</Project>

===== FILE: tests/LeichtFrame.IO.Tests/Parquet/ParquetReaderTests.cs =====
using LeichtFrame.Core;
using Parquet;
using Parquet.Schema;
using Parquet.Data;

namespace LeichtFrame.IO.Tests
{
    public class ParquetReaderTests
    {
        private async Task<string> CreateTempParquetFile()
        {
            string path = Path.GetTempFileName();

            // Define Parquet Schema manually
            var schema = new ParquetSchema(
                new DataField<int>("Id"),
                new DataField<double?>("Value"), // Nullable
                new DataField<string>("Name")
            );

            // Columns
            var ids = new int[] { 1, 2 };
            var values = new double?[] { 10.5, null };
            var names = new string[] { "Alice", "Bob" };

            using var stream = File.OpenWrite(path);
            using var writer = await Parquet.ParquetWriter.CreateAsync(schema, stream);
            using var groupWriter = writer.CreateRowGroup();

            await groupWriter.WriteColumnAsync(new DataColumn(schema.DataFields[0], ids));
            await groupWriter.WriteColumnAsync(new DataColumn(schema.DataFields[1], values));
            await groupWriter.WriteColumnAsync(new DataColumn(schema.DataFields[2], names));

            return path;
        }

        [Fact]
        public async Task Read_Loads_Parquet_File_Correctly()
        {
            string path = await CreateTempParquetFile();

            try
            {
                // Act
                var df = ParquetReader.Read(path);

                // Assert Schema
                Assert.Equal(2, df.RowCount);
                Assert.Equal(3, df.ColumnCount);
                Assert.True(df.HasColumn("Id"));
                Assert.True(df.HasColumn("Value"));

                // Assert Data
                Assert.Equal(1, df["Id"].Get<int>(0));
                Assert.Equal(10.5, df["Value"].Get<double>(0));
                Assert.Equal("Alice", df["Name"].Get<string>(0));

                // Assert Null Handling
                Assert.Equal(2, df["Id"].Get<int>(1));
                Assert.True(df["Value"].IsNull(1)); // Should be null
                Assert.Equal("Bob", df["Name"].Get<string>(1));
            }
            finally
            {
                File.Delete(path);
            }
        }

        [Fact]
        public async Task ReadBatches_Splits_RowGroups_Correctly()
        {
            // Arrange: Create a Parquet file with 2 distinct RowGroups
            string path = Path.GetTempFileName();
            var schema = new ParquetSchema(new DataField<int>("Id"));

            using (var stream = File.OpenWrite(path))
            {
                using var writer = await Parquet.ParquetWriter.CreateAsync(schema, stream);

                // RowGroup 1: IDs 1, 2
                using (var gw1 = writer.CreateRowGroup())
                {
                    await gw1.WriteColumnAsync(new DataColumn(schema.DataFields[0], new int[] { 1, 2 }));
                }

                // RowGroup 2: IDs 3, 4, 5
                using (var gw2 = writer.CreateRowGroup())
                {
                    await gw2.WriteColumnAsync(new DataColumn(schema.DataFields[0], new int[] { 3, 4, 5 }));
                }
            }

            try
            {
                // Act
                // ReadBatches returns IEnumerable<DataFrame>
                var batches = ParquetReader.ReadBatches(path).ToList();

                // Assert
                Assert.Equal(2, batches.Count);

                // Check Batch 1
                Assert.Equal(2, batches[0].RowCount);
                Assert.Equal(1, batches[0]["Id"].Get<int>(0));
                Assert.Equal(2, batches[0]["Id"].Get<int>(1));

                // Check Batch 2
                Assert.Equal(3, batches[1].RowCount);
                Assert.Equal(3, batches[1]["Id"].Get<int>(0));
                Assert.Equal(5, batches[1]["Id"].Get<int>(2));
            }
            finally
            {
                if (File.Exists(path)) File.Delete(path);
            }
        }
    }
}
===== FILE: tests/LeichtFrame.IO.Tests/Parquet/ParquetWriterTests.cs =====
using LeichtFrame.Core;

namespace LeichtFrame.IO.Tests
{
    public class ParquetWriterTests
    {
        [Fact]
        public void Roundtrip_Write_Then_Read_Preserves_Data()
        {
            // Arrange
            var schema = new DataFrameSchema(new[] {
                new ColumnDefinition("Id", typeof(int)),
                new ColumnDefinition("Value", typeof(double), IsNullable: true),
                new ColumnDefinition("Name", typeof(string))
            });

            var original = DataFrame.Create(schema, 2);
            ((IntColumn)original["Id"]).Append(1);
            ((DoubleColumn)original["Value"]).Append(12.34);
            ((StringColumn)original["Name"]).Append("Test");

            ((IntColumn)original["Id"]).Append(2);
            ((DoubleColumn)original["Value"]).Append(null); // Check Nullable
            ((StringColumn)original["Name"]).Append("NullRow");

            string path = Path.GetTempFileName();

            try
            {
                // Act: Write
                original.WriteParquet(path);

                // Act: Read Back (using the Reader we built in C.2.1)
                // Note: Parquet might not preserve IsNullable=false for Int if not specified carefully, 
                // but logic maps nullable based on Parquet schema.
                var loaded = ParquetReader.Read(path);

                // Assert
                Assert.Equal(2, loaded.RowCount);

                Assert.Equal(1, loaded["Id"].Get<int>(0));
                Assert.Equal(12.34, loaded["Value"].Get<double>(0));
                Assert.Equal("Test", loaded["Name"].Get<string>(0));

                Assert.Equal(2, loaded["Id"].Get<int>(1));
                Assert.True(loaded["Value"].IsNull(1));
            }
            finally
            {
                File.Delete(path);
            }
        }
    }
}
